* _2016-12-15 10:31:00_> @U04DFTZ7D: <@U04DFTZ7D> has joined the channel
* _2016-12-15 10:31:02_> @U04DFTZ7D: <@U04DFTZ7D> set the channel purpose: Dedicated channel to discuss and develop embedded system.
* _2016-12-15 10:31:02_> @U38HVMZ6K: <@U38HVMZ6K> has joined the channel
* _2016-12-15 10:31:02_> @U0B47KC3S: <@U0B47KC3S> has joined the channel
* _2016-12-16 00:25:13_> @U0AAL4W13: <@U0AAL4W13> has joined the channel
* _2016-12-16 13:09:00_> @U38HVMZ6K: Hi, just created the repo on github (<https://github.com/echopen/PRJ-medtech_embsys>)
* _2016-12-16 13:09:32_> @U38HVMZ6K: still no content but repo is here and added the BSD 3-clauses standard license proposed by github
* _2016-12-16 13:09:50_> @U38HVMZ6K: <@U0B47KC3S> change the LICENSE file if you have another template
* _2016-12-16 13:11:57_> @U0B47KC3S: great <@U38HVMZ6K> ! <@U04DFTZ7D> what do you think ?
* _2016-12-16 13:15:02_> @U04DFTZ7D: Well, the license is fine though ;)
* _2016-12-16 13:15:16_> @U38HVMZ6K: great
* _2016-12-16 13:15:36_> @U38HVMZ6K: if we can rely on the standard templates proposed by github it's great
* _2016-12-16 13:16:08_> @U38HVMZ6K: just say "choose BSD-3 clauses" when creating the project and github does all the stuff itself!
* _2016-12-16 13:16:34_> @U38HVMZ6K: put the copyright to echopen, creates the LICENSE file at the root directory
* _2016-12-16 13:31:23_> @U04DFTZ7D: Yes and we using it this way for code repo
* _2016-12-16 14:01:22_> @U0AAL4W13: For the copyright, in the absence of other agreements, should mention "echopen and it's contributors"  ;) cf <http://ben.balter.com/2015/06/03/copyright-notices-for-websites-and-open-source-projects/> ^^
* _2016-12-17 15:19:00_> @U3GQS8JTZ: <@U3GQS8JTZ> has joined the channel
* _2016-12-19 14:27:59_> @U3GHS132Q: <@U3GHS132Q> has joined the channel
* _2016-12-19 14:29:00_> @U04DFTZ7D: <@U3GHS132Q>: discussion about embedded system are here ;)
* _2016-12-19 14:29:28_> @U3GHS132Q: Hello ! Thank you <@U04DFTZ7D> :slightly_smiling_face:
* _2016-12-19 14:31:44_> @U3GHS132Q: The last time I came to Hôtel-Dieu we discussed about the probes : * Which board will be used ? * Will the probe will embed a Linux ? * If so how does the DSP and Linux will communicate ?  And another question : if the board embed an ARM can we use <https://fr.wikipedia.org/wiki/Single_instruction_multiple_data> ?
* _2016-12-19 14:35:22_> @U38HVMZ6K: Hello <@U3GHS132Q> , I don't know about the discussions you had but from what I got from <@U3GQS8JTZ> , the probes would be based on Texas Instruments OMAP L138 MCU
* _2016-12-19 14:36:21_> @U38HVMZ6K: There would be an embedded Linux on board. 
* _2016-12-19 14:37:43_> @U38HVMZ6K: On OMAP-L138 the DSP and MCU cores are in the same chip, TI provides libraries for inter-cores communication.
* _2016-12-19 14:38:19_> @U38HVMZ6K: Syslink or TI-link, no longer remember the exact name.
* _2016-12-19 14:38:58_> @U3GHS132Q: Ok, all is clear now :stuck_out_tongue_winking_eye: ! Thank you :slightly_smiling_face:
* _2016-12-19 14:40:43_> @U38HVMZ6K: We would still need to discuss together with <@U0B47KC3S>  and <@U3GQS8JTZ> . I just had a single discussion with them. 
* _2016-12-19 14:41:14_> @U38HVMZ6K: The idea was to start with eval boards : Board OMAP: <http://www.ti.com/tool/tmdslcdk138> Eval kit ADC: <http://www.ti.com/tool/ads6142evm>
* _2016-12-19 14:44:54_> @U3GHS132Q: Woh they are not cheaper :s And what about the software development environment ? What are the tools needed to put the program on this board ?
* _2016-12-19 14:45:57_> @U3GHS132Q: Oh and also what are the licences of TI components (like the libraries) ?
* _2016-12-19 14:48:31_> @U3GHS132Q: It seems Sys-Link library is BSD licensed ;D
* _2016-12-19 14:56:09_> @U38HVMZ6K: For the development environment, for the ARM core on the board we can use whatever we want. Open-source cross-toolchain (Linaro cross-toolcchains are quite good and easy to use).
* _2016-12-19 14:56:51_> @U38HVMZ6K: For the DSP side, I don't know but we are probably stuck at TI tools (Code Composer and debugger).
* _2016-12-19 15:04:59_> @U3GHS132Q: That's cool for the ARM side :slightly_smiling_face:
* _2016-12-19 15:06:36_> @U3GHS132Q: That's less cool for the DSP side, but it seems that Code Composer can be easily installed on Ubuntu
* _2016-12-19 15:07:29_> @U3GHS132Q: Is it possible to just got the DSP-compiler and DSP-debugger and not all the IDE xD ?
* _2016-12-19 15:13:00_> @U38HVMZ6K: Don't know. I didn't do any DSP development for long and at that time everything was really bound to TI tools.
* _2016-12-19 15:13:49_> @U38HVMZ6K: Code Composer in itself is not that bad (standard eclipse with a few plugins)
* _2016-12-19 15:15:50_> @U3GHS132Q: It seems there are emulators, during the holidays I will try to install this components and try to compile the "helloworld" program to familiarize me with the tools
* _2016-12-19 15:52:58_> @U3GHS132Q: I have to go, I will be here tomorrow. Good bye and thank you for the informations :slightly_smiling_face:
* _2016-12-20 12:08:02_> @U2PFHNN3C: <@U2PFHNN3C> has joined the channel
* _2016-12-21 15:09:51_> @U3HH0CEAW: <@U3HH0CEAW> has joined the channel
* _2016-12-22 00:25:21_> @U3GHS132Q: Just (an other) question : will we have to develop a linux driver ???
* _2016-12-22 06:56:50_> @U38HVMZ6K: <@U3GHS132Q> , no idea for now. It will depend on many aspects like existing drivers on the platform we will use, performance needs/real-time processing.  My general rule is: avoid to develop specific drivers as far as you can and try all other possibilities before going into driver/kernel development.
* _2016-12-22 07:07:36_> @U38HVMZ6K: It is much easier and comfortable to develop in user space than in kernel (drivers). Few examples: in user mode you can crash your application/process without any impact on other applications/processes which can go on, detect the crash and take actions. In the kernel, if you crash... you crash! :wink: with a bit chance a nice kernel panic with a stack trace helping you a bit to track down the issue but not so much more. (reactions: @U20C8CKTL)
* _2016-12-22 07:08:06_> @U38HVMZ6K: Debugging is also much easier in user space than in the kernel.
* _2016-12-22 07:10:47_> @U38HVMZ6K: At the end of the day we often had a compromise solution in the projects I worked on: 1) a minimal, dumbest possible kernel driver acquiring the raw data 2) a user space application processing the raw data into more elaborated useful format
* _2016-12-22 07:11:22_> @U38HVMZ6K: The limit of scope between the 2 is always a trade-off.
* _2016-12-22 07:12:38_> @U38HVMZ6K: Sometimes it's still necessary to perform some pre-processing in the kernel/driver to limit the amount of data and load on user processes.
* _2016-12-22 07:14:40_> @U38HVMZ6K: The approach we took was always "go user space first" then you can evaluate the performance, try first optimizations, identify bottlenecks,... 
* _2016-12-22 09:27:49_> @U0AAL4W13: That's in that sense that I love working with the beaglebone prudaq: the 40msps adc is a /dev/prudaq and you play within directly in userspace 
* _2016-12-22 09:27:53_> @U0AAL4W13: Very convenient 
* _2016-12-22 09:28:45_> @U0AAL4W13: It also gives you a ram buffer,  it's always great to have 300Mo+ buffer of continuous acquisition 
* _2016-12-22 15:07:59_> @U3J40RUDT: <@U3J40RUDT> has joined the channel
* _2016-12-22 15:19:15_> @U37GZRZU6: <@U37GZRZU6> has joined the channel
* _2016-12-22 15:19:15_> @U0KLG7CP8: <@U0KLG7CP8> has joined the channel
* _2016-12-22 15:19:15_> @U1PKXQVDW: <@U1PKXQVDW> has joined the channel
* _2016-12-22 15:19:15_> @U3FCS2UP3: <@U3FCS2UP3> has joined the channel
* _2016-12-22 15:19:16_> @U0GMX7QUB: <@U0GMX7QUB> has joined the channel
* _2016-12-22 15:19:16_> @U34N7NQNR: <@U34N7NQNR> has joined the channel
* _2016-12-22 15:19:16_> @U20C8CKTL: <@U20C8CKTL> has joined the channel
* _2016-12-22 15:19:16_> @U07UEJC2H: <@U07UEJC2H> has joined the channel
* _2016-12-22 15:19:16_> @U32FZ0QLX: <@U32FZ0QLX> has joined the channel
* _2016-12-22 15:19:17_> @U3210MXC5: <@U3210MXC5> has joined the channel
* _2016-12-22 15:19:17_> @U34231VFH: <@U34231VFH> has joined the channel
* _2016-12-22 15:19:17_> @U31UCUFPW: <@U31UCUFPW> has joined the channel
* _2016-12-22 15:19:17_> @U32AR6TED: <@U32AR6TED> has joined the channel
* _2016-12-22 15:19:17_> @U32UWGGN9: <@U32UWGGN9> has joined the channel
* _2016-12-22 15:19:18_> @U0FN1B8KD: <@U0FN1B8KD> has joined the channel
* _2016-12-22 15:19:18_> @U33817K25: <@U33817K25> has joined the channel
* _2016-12-22 15:19:18_> @U38JDLY2E: <@U38JDLY2E> has joined the channel
* _2016-12-22 15:19:18_> @U2XLJS5L0: <@U2XLJS5L0> has joined the channel
* _2016-12-22 15:19:18_> @U2X419KJS: <@U2X419KJS> has joined the channel
* _2016-12-22 15:19:19_> @U2Y7FPEUB: <@U2Y7FPEUB> has joined the channel
* _2016-12-22 15:19:20_> @U2YN8FREG: <@U2YN8FREG> has joined the channel
* _2016-12-22 15:19:20_> @U2X7189QR: <@U2X7189QR> has joined the channel
* _2016-12-22 15:19:20_> @U3GV4N878: <@U3GV4N878> has joined the channel
* _2016-12-22 15:19:20_> @U352MKG4V: <@U352MKG4V> has joined the channel
* _2016-12-22 15:19:20_> @U32V2JWFJ: <@U32V2JWFJ> has joined the channel
* _2016-12-22 15:19:20_> @U394HRZ1B: <@U394HRZ1B> has joined the channel
* _2016-12-22 15:19:20_> @U336DPZV4: <@U336DPZV4> has joined the channel
* _2016-12-22 15:19:20_> @U2UU194RZ: <@U2UU194RZ> has joined the channel
* _2016-12-22 15:19:20_> @U2V03QR8E: <@U2V03QR8E> has joined the channel
* _2016-12-22 15:19:21_> @U3BAH0X62: <@U3BAH0X62> has joined the channel
* _2016-12-22 15:19:21_> @U3B1RKVSP: <@U3B1RKVSP> has joined the channel
* _2016-12-22 15:19:21_> @U0DRKLMS4: <@U0DRKLMS4> has joined the channel
* _2016-12-22 15:19:21_> @U2Q4137LL: <@U2Q4137LL> has joined the channel
* _2016-12-22 15:19:21_> @U1PAGSKGU: <@U1PAGSKGU> has joined the channel
* _2016-12-22 15:19:21_> @U2404BG5N: <@U2404BG5N> has joined the channel
* _2016-12-22 15:19:21_> @U0GN7EB32: <@U0GN7EB32> has joined the channel
* _2016-12-22 15:19:22_> @U0HF2S3QX: <@U0HF2S3QX> has joined the channel
* _2016-12-22 15:19:22_> @U33389FRA: <@U33389FRA> has joined the channel
* _2016-12-22 15:19:22_> @U2NAWHM9N: <@U2NAWHM9N> has joined the channel
* _2016-12-22 15:19:22_> @U1N5Q9334: <@U1N5Q9334> has joined the channel
* _2016-12-22 15:19:22_> @U2M9XDS5N: <@U2M9XDS5N> has joined the channel
* _2016-12-22 15:19:23_> @U2PTWF6SX: <@U2PTWF6SX> has joined the channel
* _2016-12-22 15:26:07_> @U0B47KC3S: joined
* _2016-12-22 16:15:10_> @U38HVMZ6K: Yeahhh so many people interested in embedded systems great!
* _2016-12-22 21:31:22_> @U3GHS132Q: <@U38HVMZ6K> I totally agree with you, it is just that I have a few knowledge in kernel programming and I want to improve them ^^
* _2016-12-22 21:33:58_> @U3GHS132Q: <@U0AAL4W13> I never play with a beaglebone so what is a prudaq ? And how do you play with it in user land ? With `cat /dev/prudaq` and `echo "pen" &gt; /dev/prudaq` ???
* _2016-12-22 21:35:20_> @U38HVMZ6K: We will have plenty of stuff to explore for sure and you'll have the opportunity to play at the kernel level if you wish :wink: 
* _2016-12-22 21:35:45_> @U3GHS132Q: YES :smile:
* _2016-12-22 21:36:50_> @U38HVMZ6K: For PRUDAQ see <https://github.com/google/prudaq/wiki>
* _2016-12-22 21:39:41_> @U3GHS132Q: It seems interesting :slightly_smiling_face:
* _2016-12-22 21:40:05_> @U3GHS132Q: Also what is Eagle I already saw it in another git repo, is it a language like Verilog or VHDL ?
* _2016-12-22 21:43:47_> @U38HVMZ6K: No, a CAD software for designing PCBs, schematics,... like Altium, OrCad or open-source kiCad
* _2016-12-22 21:44:32_> @U38HVMZ6K: Eagle is a commercial (but affordable) CAD: <https://cadsoft.io>
* _2016-12-22 21:45:20_> @U3GHS132Q: Ok I understand more, I will speak about this with the electronicians of my promo :slightly_smiling_face:
* _2016-12-22 21:45:38_> @U3GHS132Q: I have to go, I will read more about the prudaq, good bye
* _2016-12-22 23:12:43_> @U0B47KC3S: <@U38HVMZ6K> bouncing on your chat with <@U3GHS132Q> : just for my culture, we are ok that kernel/module programming on a VM is safe ? Btw, thinking about performance : in the design you have in mind, you think we will first program in user space and then wrap into modules ?
* _2016-12-23 08:28:48_> @U0AAL4W13: <@U3GHS132Q>: the prudaq is the best integration of a high speed adc in a Linux 
* _2016-12-23 08:31:08_> @U0AAL4W13: Some notes on it: <https://kelu124.gitbooks.io/echomods/content/Chapter2/toadkiller.html>
* _2016-12-23 09:01:39_> @U38HVMZ6K: The prudaq is using the PRU (programmable realtime unit) of the Texas Instruments AM335x micro-controller. The PRU is a co-processor/subsystem with a separate core optimized for real-time operations in different areas like data acquisition, real-time industrial communication protocols or motor control. (reactions: @U0AAL4W13)
* _2016-12-23 09:08:35_> @U0AAL4W13: There are two per beaglebone, each running at 200mhz. The guy who did the prudaq started with a 100Mhz logic analyser 
* _2016-12-23 09:15:02_> @U0AAL4W13: Now its doing a great job a programming and exposing the adc is userspace 
* _2016-12-23 13:25:06_> @U3GHS132Q: <@U0B47KC3S> Yes, kernel debuging/testing through a virtual machine is safe. I always use qemu to test the driver I coded. In fact, if you test your driver directly on your computer if it crashes then your computer crashes and in some case you can lose data. Kernel programming is not really about performance, of course in the kernel we are, I think, a bit more performing that in user land because we do not have to do a syscall to get information from a device.  A little definition about kernel is that it is a software that handle access to peripheral. In our cases if we have to develop a driver it will just get the data from the probe and then send it in user land.  I hope that I was clear, I can explain this better with a schema which show the relations between user and kernel land. (reactions: @U0B47KC3S)
* _2016-12-23 13:26:31_> @U3GHS132Q: <@U38HVMZ6K> this PRU seems very interesting :slightly_smiling_face: I do not know that there are real time specific processor
* _2016-12-23 13:30:11_> @U0AAL4W13: <@U3GHS132Q> @Rbo - let me know if you want to play with those, I have a spare bbb and a spare prudaq ;)
* _2016-12-23 13:31:39_> @U3GHS132Q: <@U0AAL4W13> I never played with something like that but if we need to use it in our project it will be with pleasure :slightly_smiling_face:
* _2016-12-23 13:59:50_> @U38HVMZ6K: I must still have a BBB laying somewhere in my mess :thinking_face: don't have time to play with the PRUDAQ right now but I keep the info in case I want to start sth with it thanks 
* _2016-12-26 21:59:14_> @U24BZF8UR: <@U24BZF8UR> has joined the channel
* _2016-12-26 22:07:59_> @Hyacinthe: @rbo used `/poll`! Each person can vote for multiple items. 
* _2016-12-28 00:47:03_> @U3GHS132Q: I think it is a good idea :slightly_smiling_face: But which technology will we use for the virtual meetup ?
* _2016-12-28 01:03:18_> @U0B47KC3S: <@U3GHS132Q> I think skype or hangout will be ok - btw, seems the 4th is winning :wink:
* _2016-12-28 07:33:02_> @U38HVMZ6K: Ok let's book the 4th! <@U0B47KC3S> can you check with <@U3GQS8JTZ>  if it's also OK with him? It's important to have it in the discussions. I'll prepare a small agenda and will share it before the meeting.
* _2016-12-28 09:12:46_> @U0B47KC3S: yes <@U38HVMZ6K> ! will let you know this morning
* _2016-12-28 11:30:13_> @U3GHS132Q: For those we are in Paris maybe we can physically meet to speak virtually with those who are remote ? About the technology I will be boring but maybe we can use <https://framatalk.org/accueil/> ? I am not really on the same wave length with GAFAM tools and it does not need any installation or registration ^^"""
* _2016-12-28 11:46:44_> @U0B47KC3S: sure <@U3GHS132Q>
* _2016-12-28 12:03:59_> @U38HVMZ6K: If it doesn't need any installation we can give it a try this time and can take it as a reference tool for future meetups.
* _2016-12-28 23:04:45_> @U3GHS132Q: <@U38HVMZ6K> That is a good idea, to be honest I never used this ^^"""" but I think that the basics are presents ^^ <@U0B47KC3S> So we meet Wednesday at Hôtel-Dieu ?
* _2016-12-29 01:22:31_> @U0B47KC3S: <@U3GHS132Q> yes !
* _2016-12-29 10:44:27_> @U3GHS132Q: <@U0B47KC3S> Ok perfect :slightly_smiling_face:
* _2016-12-30 01:38:25_> @U3J40RUDT: Have we decided on which software to chat with?
* _2016-12-30 09:09:47_> @U38HVMZ6K: We'll give a try to framatalk as proposed by <@U3GHS132Q> . I'll send the link and a proposal for the agenda tomorrow.
* _2017-01-01 16:42:13_> @U38HVMZ6K: Hi all! All the best for 2017 !!! I created a first wiki page for the Embedded System part: <http://wiki.echopen.org/index.php/Embedded_System> (reactions: @U0B47KC3S)
* _2017-01-01 16:43:59_> @U38HVMZ6K: I also created a "Meetup" page for collecting links to the individual meetings/sessions on the embedded system: <http://wiki.echopen.org/index.php/Embedded_System:Meetups> with a first session next Wednesday (<http://wiki.echopen.org/index.php/January_4,_2017>).
* _2017-01-01 16:45:33_> @U38HVMZ6K: We will try jitsi (<https://jitsi.org/>) for this first session. This the mainline open-source project behind Framatalk suggested by <@U3GHS132Q>.
* _2017-01-01 16:51:10_> @U38HVMZ6K: I don't know if the wiki and the structure is the good one (concurrent editing solutions like GDoc or open-source alternative Etherpad may be better) but let's give a first shot with this in place.
* _2017-01-02 11:09:41_> @U38HVMZ6K: set up a reminder to “join 1st Embbedded System meetup at Hôtel-Dieu or online (https://meet.jit.si/echopenEmbedded)” in this channel at 8pm tomorrow, Central European Time.
* _2017-01-02 11:11:37_> @U38HVMZ6K: Remind <#C3F765DT7>)” at 20:00 January 4
* _2017-01-02 11:12:38_> @U38HVMZ6K: set up a reminder to “Join 1st Embbedded System meetup on January 4 at Hôtel-Dieu or online (https://meet.jit.si/echopenEmbedded)” in this channel at 6pm Wednesday, January 4th, Central European Time.
* _2017-01-02 11:13:42_> @U38HVMZ6K: sorry for spam... playing with /remind function for the 1st time :wink:
* _2017-01-02 11:19:28_> @U0AAL4W13: :)
* _2017-01-02 16:16:30_> @U38HVMZ6K: as suggested by <@U04DFTZ7D> I created a markdown doc in PRJ-medtech_embsys repo for holding the agenda and minutes of Wednesday's meeting (reactions: @U04DFTZ7D)
* _2017-01-02 16:16:34_> @U38HVMZ6K: <https://github.com/echopen/PRJ-medtech_embsys/blob/master/meetups/2017-01-04-meetup.md>
* _2017-01-04 18:00:00_> @USLACKBOT: Reminder: Join 1st Embbedded System meetup on January 4 at Hôtel-Dieu or online (<https://meet.jit.si/echopenEmbedded>)
* _2017-01-05 08:49:43_> @U38HVMZ6K: Thanks to all of you who participated to the first Embedded System meetup yesterday ! It was great to meet you all, even remotely, and to discuss the basics of the embedded system platform. I'll try to publish my notes of the meeting today evening and put in place the Framapad/Framindmap to think about the desired features of the embedded platform as well. Let's keep in touch and make this channel a living one with many contributions ! Have a nice day :boom: (reactions: @U0AAL4W13,@U37GZRZU6,@U3GHS132Q,@U0B47KC3S)
* _2017-01-05 15:56:25_> @U3ML4L01Z: <@U3ML4L01Z> has joined the channel
* _2017-01-05 23:19:29_> @U3GHS132Q: I am just thinking that I always speak about SIMD but I just remembered that GCC can use it on this own with -O3 or -ftree-vectorize. I tested it on Intel computer and it worked but I do not know if it is used on ARM. Here is the link for more information on this compiler's optimization <https://gcc.gnu.org/projects/tree-ssa/vectorization.html>
* _2017-01-05 23:25:51_> @U3GHS132Q: Moreover I can not determine if ARM9 has SIMD...
* _2017-01-05 23:27:44_> @U38HVMZ6K: Hi all, I pushed my minutes of yesterday's meeting on github: <https://github.com/echopen/PRJ-medtech_embsys/blob/master/meetups/2017-01-04-meetup.md>
* _2017-01-05 23:28:46_> @U38HVMZ6K: And the Framapad for brainstorming on features of the embedded system is on air: <https://annuel.framapad.org/p/embsysBrainstorm>
* _2017-01-05 23:29:04_> @U3GHS132Q: That is perfect <@U38HVMZ6K> :slightly_smiling_face:
* _2017-01-05 23:29:51_> @U38HVMZ6K: don't hesitate to complete the doc and put all your ideas (even the craziest ones) ! We will select the doable ones and prioritize them later
* _2017-01-05 23:30:30_> @U38HVMZ6K: Just put what you would like to see in your dream echOpen probe :wink:
* _2017-01-05 23:31:25_> @U38HVMZ6K: <@U3GHS132Q> SIMD on ARM is implemented by the NEON engine (<https://www.arm.com/products/processors/technologies/neon.php>)
* _2017-01-05 23:32:12_> @U38HVMZ6K: NEON is not available on ARM9 processors like the one in OMAP-L138 but only in more recent ARM MCUs of the Cortex-A family
* _2017-01-05 23:34:26_> @U3GHS132Q: It seems to be available on A7 <http://infocenter.arm.com/help/topic/com.arm.doc.ddi0462f/DDI0462F_cortex_a7_neon_mpe_r0p5_trm.pdf> I just saw that you suggest a card from NXP with an A7 core. So if we use this card we can use SIMD to "replace" the DSP (maybe the compiler can help us, I do not know)
* _2017-01-05 23:35:15_> @U3GHS132Q: Honestly I am not very familiar with ARM CPU "organization", what is ARM9 compared to Cortex A ?
* _2017-01-05 23:36:48_> @U3GHS132Q: Moreover an other advantage for the card you suggest is that there is a 2 core version so we can use multithreading like pthread or openMP :slightly_smiling_face:
* _2017-01-05 23:37:21_> @U38HVMZ6K: ARM9 is an older family of processor which include ARM926 CPUs
* _2017-01-05 23:38:12_> @U38HVMZ6K: Cortex-A family is a newer family which include newer 32-bits and 64-bits cores
* _2017-01-05 23:39:35_> @U3GHS132Q: Ok it is clearer now, thank you :slightly_smiling_face:
* _2017-01-05 23:44:18_> @U38HVMZ6K: To add more to the confusion every ARM generation implements a newer version of the instruction set... ARM9 family implement the ARMv4 and ARMv5 instruction set ARM11 family implements the ARMv6 instruction set ARM Cortex-A 32bits family implements ARMv7 instruction set And finally, the most recent generation ARM Cortex-A 64 bits implement the ARMv8 instruction set :joy: :joy: :joy: 
* _2017-01-05 23:45:30_> @U3GHS132Q: Oh i confounded the family name ARMnumber with the ISA name ARMvnumber !
* _2017-01-05 23:46:46_> @U38HVMZ6K: My proposal for iMX7 is to handle with care! The DSP is an important piece in the OMAP-L138 and I'm not sure that the Cortex-M4 core on the iMX7 can perform as well as the DSP core
* _2017-01-05 23:48:08_> @U38HVMZ6K: Moreover, an important feature of the L138 is it's uPP port to interface with the ADC. Not sure that we have an equivalent on the iMX7 and can interface or ADC in a similar fashion.
* _2017-01-05 23:48:27_> @U38HVMZ6K: This will have to be discussed with <@U3GQS8JTZ> 
* _2017-01-05 23:48:50_> @U3GHS132Q: Yes it seems that the ADC is an important thing. I think that it is wiser to discuss it tomorrow. It is always hard to choose the good hardware, they are all interesting and powerful (fpga, gpu, dsp, cpu) !
* _2017-01-05 23:48:53_> @U38HVMZ6K: But don't focus on SIMD-capable CPUs only
* _2017-01-05 23:49:28_> @U38HVMZ6K: It's only one part of the equation and not the most important one in my opinion
* _2017-01-05 23:49:45_> @U38HVMZ6K: So now... :sleeping: :zzz: 
* _2017-01-05 23:49:55_> @U38HVMZ6K: See you tomorrow
* _2017-01-05 23:50:00_> @U3GHS132Q: Good bye :slightly_smiling_face:
* _2017-01-06 00:45:13_> @U0AAL4W13: <@U38HVMZ6K> a couple of thoughts / inputs in parallel of your minutes :
* _2017-01-06 00:49:15_> @U0AAL4W13: - do we need to send raw signal or image from probe to smartphone? If you have 200 lines at 15cm, 15cm means 200us of acquisition, that's 12k points at 60msps.  If you have 20fps, that's 200 x 12000 x 20 bytes x (12 bits depending on your adc) per sec to transmit. If you have the image, that'd be say 5 to 10 times smaller. Need to think of the relevance as well of the need to have a raw-signal on the smartphone vs having it on a set dsp/fpga.
* _2017-01-06 00:51:23_> @U0AAL4W13: - Second point is scan conversion. I trust the SC is done one the smartphone as of today, not on the red pitaya ?
* _2017-01-06 00:51:38_> @U0AAL4W13: Anyhow, thanks for the notes, have a good night ;)
* _2017-01-06 07:07:35_> @U38HVMZ6K: Thanks for the comment <@U0AAL4W13> I asked <@U0B47KC3S> to confirm my current understanding of the current setup since I am still ramping up to speed on the topic and you did it before. :+1::skin-tone-2: 
* _2017-01-06 12:05:42_> @U38HVMZ6K: Hi guys. I have some hold-up for today's evening meetup and can only start at 8:30 PM. Hope this is OK for those of you who planned to attend. I updated the open_calendar accordingly. :alarm_clock:
* _2017-01-06 18:34:54_> @U0B47KC3S: <@U38HVMZ6K> <@U37GZRZU6> <@U3GHS132Q> <@U3J40RUDT>  hey there, I am quite troubled, I don’t have any news from Jean-Christophe, hope nothing wrong. I propose we cancel our tonight meeting, what do you think ?
* _2017-01-06 18:34:57_> @U0B47KC3S: I tell you as soon as we have news from him, so that we can schedule an other moment. Anyway, we maintain the meeting of next wednesday
* _2017-01-06 19:12:32_> @U0B47KC3S: hi there <@U38HVMZ6K> <@U37GZRZU6> <@U3GHS132Q> <@U3J40RUDT>, I roolbak the information :grinning:
* _2017-01-06 19:13:08_> @U0B47KC3S: jean-christophe is back !
* _2017-01-06 19:15:43_> @U0B47KC3S: so Jean-Christophe does not have skype, but has a phone
* _2017-01-06 19:16:25_> @U0B47KC3S: so I am going to organize a conf call - I’ll give you all the informations asap
* _2017-01-06 19:16:53_> @U3J40RUDT: Ok! The meeting is at 8:30 yes ?  (reactions: @U37GZRZU6)
* _2017-01-06 19:16:59_> @U0B47KC3S: yes
* _2017-01-06 19:17:42_> @U3J40RUDT: Ok see you guys then! 
* _2017-01-06 19:18:23_> @U38HVMZ6K: :+1::skin-tone-2: 
* _2017-01-06 19:39:18_> @U0B47KC3S: dear fellows, here’s what I suggest -&gt; first we’ll try to skype if JC has gets a connectoin, which is not sure. If not, we can go reach the meeting, call -&gt; +33 1 70 94 60 22 and the conf no is 164807. However, if it is not free, it is about 0.10€/mn, so around 6€ for an hour. So what I suggest, is that this can be on supported by the association. What you think ?
* _2017-01-06 19:46:34_> @U38HVMZ6K: Ok for me.
* _2017-01-06 19:47:30_> @U3J40RUDT: That's fine for me too 
* _2017-01-06 19:49:25_> @U3J40RUDT: How would the skype call work? Do you need my username ? 
* _2017-01-06 19:51:13_> @U0B47KC3S: yes please :wink:
* _2017-01-06 19:55:24_> @U3J40RUDT: It's omaciu
* _2017-01-06 19:57:34_> @U0B47KC3S: great
* _2017-01-06 20:00:27_> @U0B47KC3S: we have perhaps an option suggested by <@U37GZRZU6> ! I got some Skype credits to make a call on phone. Overall it seem to be less costy and we can pay without having to refill you;) Btw, I have tried it, it seems to work :wink: thks <@U37GZRZU6>
* _2017-01-06 20:01:53_> @U3J40RUDT: great!
* _2017-01-06 20:11:33_> @U38HVMZ6K: I also have free credits in case you get short
* _2017-01-06 20:26:08_> @U37GZRZU6: :slightly_smiling_face: my username is aurelie.mutschler
* _2017-01-06 20:35:17_> @U3GHS132Q: Hello, my skype username is silverlankaiz. I hope I can use it through my web browser
* _2017-01-06 20:35:27_> @U38HVMZ6K: mine is <mailto:r.bornet@outlook.com>
* _2017-01-06 20:39:08_> @U0B47KC3S: JC is available in 5 mns,I call you then because I have to add him first
* _2017-01-06 20:39:34_> @U37GZRZU6: <@U0B47KC3S> ok :slightly_smiling_face:
* _2017-01-06 20:39:50_> @U38HVMZ6K: just the time for my dessert :wink: (reactions: @U37GZRZU6)
* _2017-01-06 20:40:06_> @U0B47KC3S: ok :wink:
* _2017-01-06 20:40:43_> @U3GHS132Q: It seems that I can not call the button is not available hum :disappointed:
* _2017-01-06 20:41:17_> @U38HVMZ6K: Mehdi will call you
* _2017-01-06 20:42:30_> @U0B47KC3S: ok <@U3GHS132Q> I am going to try
* _2017-01-06 20:43:32_> @U3GHS132Q: I will install it on my phone, I think that I miss some javascript or something like this
* _2017-01-06 20:43:46_> @U3GHS132Q: You can begin without me of course ^^
* _2017-01-06 20:43:51_> @U0B47KC3S: <@U3GHS132Q>  I can’t reach you
* _2017-01-06 20:44:07_> @U0B47KC3S: but I see you connected
* _2017-01-06 20:44:15_> @U0B47KC3S: do you see something ringing
* _2017-01-06 20:44:32_> @U3GHS132Q: I just see the missed call but nothing is ringing
* _2017-01-06 20:45:23_> @U0B47KC3S: I sent you a text message, you received it ?
* _2017-01-06 20:48:55_> @U0B47KC3S: ok <@U3GHS132Q> misses some button, he s going to connect through his andoird interface
* _2017-01-06 20:50:03_> @U3GHS132Q: I think it will take some time, so begin without me ^^"""
* _2017-01-06 20:52:54_> @U38HVMZ6K: <https://www.youtube.com/watch?v=DYu_bGbZiiQ> ... (reactions: @U37GZRZU6)
* _2017-01-06 20:54:19_> @U3J40RUDT: :laughing:
* _2017-01-06 20:54:26_> @U3GHS132Q: xD
* _2017-01-06 20:54:46_> @U0AAL4W13: Lolz (reactions: @U37GZRZU6)
* _2017-01-06 21:02:57_> @U0B47KC3S: hey ther it does not seem to work, let’s switch to call conf : +33 1 70 94 60 22 and the conf no is 164807
* _2017-01-06 21:04:15_> @U3J40RUDT: So i have terrible cell service in the apartment, let’s hope it works :smile:
* _2017-01-06 21:04:29_> @U0B47KC3S: for french people the no call 0821 616 111 (reactions: @U37GZRZU6)
* _2017-01-06 21:05:16_> @U3GHS132Q: Does we change because of me ? Because the skype app is ready for me lol
* _2017-01-06 21:05:54_> @U38HVMZ6K: no because of J-C not having a connection
* _2017-01-06 21:06:12_> @U3GHS132Q: Ok ^^
* _2017-01-06 21:33:44_> @U3GHS132Q: Basically what is SysLink ? Is it a kernel shared buffer between the OMAP and the ARM ?
* _2017-01-06 21:36:15_> @U38HVMZ6K: it's more than a simple shared buffer...
* _2017-01-06 21:36:55_> @U38HVMZ6K: it's a whole framework with services and abstraction for interprocessors communication
* _2017-01-06 21:37:18_> @U38HVMZ6K: have a look at Syslink overview here to get an idea: <http://processors.wiki.ti.com/index.php/SysLink_Overview>
* _2017-01-06 21:40:08_> @U3GHS132Q: If i find the source code for this I think I will read it, it seems interessting
* _2017-01-06 21:44:50_> @U3GHS132Q: But before I will have to eat xD ! For those who did not eat : enjoy your meal ! And for those who ate : enjoy your digestion :stuck_out_tongue: (reactions: @U0B47KC3S)
* _2017-01-09 09:19:19_> @U38HVMZ6K: Hi all, I'll be in Germany for work the whole week and will probably not be able to join the weekly embedded system meetup. You can nevertheless hold the meeting. On <http://jit.si>) for remote attendees.
* _2017-01-09 09:22:14_> @U38HVMZ6K: For me the important points this week would be: - Create a first block schema (OMAP-L138, ADC, acquisition chain) to have everyone almost up to date on the basics - Set the first specifications on performance (acquisition frequency, data rate, frames per seconds,...) in brief, all parts where numbers may be frightening ... :wink: :scream: (reactions: @U0B47KC3S)
* _2017-01-09 11:53:12_> @U3NT8G2BC: <@U3NT8G2BC> has joined the channel
* _2017-01-10 21:07:42_> @U3GHS132Q: Hello <@U3NT8G2BC> Have a good trip <@U38HVMZ6K> :slightly_smiling_face:
* _2017-01-11 00:02:44_> @U0AAL4W13: Hey embsys guys, a quick message for plenty of links... First, a veerrryyy interesting HN post on hardware, and "raw comments" on it. Extremely interesting: <https://news.ycombinator.com/item?id=13230741> (the post itself isn't that great).  An answer was published at <http://liesandstartuppr.blogspot.fr/2016/12/why-are-medical-ultrasound-systems-so.html> (by someone I know, yeayyy) he's recommending a book, which I'll try to find as a PDF :slightly_smiling_face: ( <https://www.amazon.com/Diagnostic-Ultrasound-Imaging-Biomedical-Engineering/dp/0123964873> ). (reactions: @U38HVMZ6K)
* _2017-01-11 00:03:35_> @U0AAL4W13: Lots of reading, but in a nutshell:  * HN post is great for comments * the blogspot post has a very good critical view on the overall design * let's try to find the book :wink:
* _2017-01-11 00:28:26_> @U0AAL4W13: there's no channel for overall design/architecture of the probe, so I'm posting a last link too : <http://liesandstartuppr.blogspot.fr/2016/12/medical-ultrasound-systems-pt-ii-where.html> -- very interesting take on the point :smiley:
* _2017-01-11 00:36:02_> @U0AAL4W13: and.. discussion goes on at : <https://news.ycombinator.com/item?id=13241295> - in the comments. Not that all points of view are valid of course, but at least shows that people are thinking about background/core issues :smiley:
* _2017-01-11 01:23:00_> @U0B47KC3S: I read quickly the `liesandstartuppr` article but NB, I didn’t read the comments yet. It is indeed interesting, however Sodini, MIT world specialist of ultrasound, who was in the VScan conception loop, told us that we were wright targeting less than 100$. For him the 2 bottlenecks are transducer and sample rate ! so now I am going to read the comments asap :wink:
* _2017-01-11 09:11:48_> @U38HVMZ6K: great !!! I put the links in my "read later" list!
* _2017-01-11 09:12:41_> @U38HVMZ6K: what is the target price for echOpen ? production or selling price ?
* _2017-01-11 09:20:02_> @U0B47KC3S: <@U38HVMZ6K> it is not definitely fixed but we think to target, for a first round of product, less than 400, selling price !
* _2017-01-11 09:21:41_> @U38HVMZ6K: yes clear that this is not frozen but just to have a rough idea...
* _2017-01-11 09:23:41_> @U38HVMZ6K: and do we have a target manufacturing price (components, PCBs, manufacturing) and quantities (1k, 10k 100k pieces ?)
* _2017-01-11 10:18:11_> @U0B47KC3S: <@U04DFTZ7D> do you have an idea about that ?
* _2017-01-11 11:14:40_> @U04DFTZ7D: Well, not yet...
* _2017-01-11 15:09:01_> @U3J40RUDT: Hey guys, unfortunately I won't be able to make tonight's meeting as I will be working late! 
* _2017-01-11 17:15:53_> @U0B47KC3S: <@U3J40RUDT> no worry, anyway have a nice working time !
* _2017-01-11 18:58:41_> @U0B47KC3S: ok I think we can reprogram the meeting. <@U38HVMZ6K> with regards to the question you asked, we had a talk with JC, and I have informations !
* _2017-01-11 19:56:53_> @U0AAL4W13: <@U38HVMZ6K> : I've done the exercise in the past, I guess from back-of-a-napkin computation would be (very optimistic) as follows (when at scale): (piezo: 70$, electronics: 150$ (parts+fab), materials+motors: 50$) -- add a 1.25 multiplier for a factory to assemble, add 1.3 factor for distributor (very optimistic for the distributor). You're at ~450$ in terms of costs
* _2017-01-11 19:58:08_> @U0AAL4W13: Then, it depends on the commercial strategy (Any margin? What about the certification costs? What about the patents - if any - costs? do we factor r&amp;d costs in?  Do we add any salaries / overheads? Do we include a license to use the echOpen name?) -- you add your other factors.
* _2017-01-11 19:58:32_> @U0AAL4W13: but that's only a very rough, and optimistic figure
* _2017-01-11 20:05:25_> @U38HVMZ6K: Thanks <@U0AAL4W13> for the input. This is something in the range I had expected. So rough estimation is 400-500$ costs for raw material and production. This does not take into account R&amp;D and other aspects you mentioned.
* _2017-01-11 20:05:57_> @U0AAL4W13: indeed
* _2017-01-11 20:06:52_> @U0AAL4W13: the benchmark in terms of price I have is that of a chinese probe, 3.5MHz mechanical scanning, which is sold at ~850$
* _2017-01-11 20:07:23_> @U0AAL4W13: so that would be a lower-bracket price, including some (but I guess not all) overheads
* _2017-01-11 20:07:55_> @U38HVMZ6K: Even if we are not targeting to manufacture ourselves the device and this is a task to be undertaken by a commercial manufacturer we should have realistic figures when we communicate out...
* _2017-01-11 20:08:40_> @U0AAL4W13: especially if we don't manufacture ourselves and we don't distribute -- these guys can take some liberties with their costs and margin, and that would influence the final selling price
* _2017-01-11 20:08:48_> @U0AAL4W13: (Ooops and I forgot the 20% VAT :wink: )
* _2017-01-11 20:09:35_> @U38HVMZ6K: I'm a bit reluctant when we speak about a target selling price of 400$ when we see that we have a 400-500$ BOM+manufacturing expense
* _2017-01-11 20:10:04_> @U0AAL4W13: Disclaimer: this is only back-of-the-napkin figures
* _2017-01-11 20:10:17_> @U0AAL4W13: we may have variations IRL ^^
* _2017-01-11 20:13:04_> @U38HVMZ6K: Yes sure and I would not commit to any cost/selling price as well without having a deeper analysis of the whole but your approximation converges with what I could imagine... Reason why I asked about the target selling price.
* _2017-01-12 12:52:08_> @U3QGT3Q74: <@U3QGT3Q74> has joined the channel
* _2017-01-14 11:07:01_> @U3RKUJHHS: <@U3RKUJHHS> has joined the channel
* _2017-01-15 22:57:51_> @U0AAL4W13: just for info -- found some info on the insides of a vscan - compiled here -&gt; <https://github.com/kelu124/echomods/blob/master/include/vscan/Readme.md> (reactions: @U0B47KC3S,@U38HVMZ6K)
* _2017-01-16 08:45:36_> @U38HVMZ6K: Great ! Thanks a lot <@U0AAL4W13> ! Very instructive !
* _2017-01-16 08:57:31_> @U38HVMZ6K: 999$ le report complet :cold_sweat:
* _2017-01-16 09:01:05_> @U38HVMZ6K: Mais y a déjà des infos intéressantes... Un DSP Texas DM6446 (<http://www.ti.com/product/TMS320DM6446>) une grosse FPGA,...
* _2017-01-16 09:04:34_> @U38HVMZ6K: 477-834$ piece for the FPGA alone... (back to English sorry...)
* _2017-01-16 09:05:30_> @U38HVMZ6K: <http://www.digikey.com/products/en?newproducts=0&amp;keywords=xc5vsx35t>
* _2017-01-16 12:40:03_> @U0AAL4W13: Electronics wise, it has only one AFE5851 (16 channels), with ADCs at 65Msps -- plus HV738 on the probe board (not depicted in the free access)
* _2017-01-17 15:45:10_> @U3T7KBEMV: <@U3T7KBEMV> has joined the channel
* _2017-01-17 19:09:40_> @U3PLYAJPJ: <@U3PLYAJPJ> has joined the channel
* _2017-01-17 19:10:20_> @U3PLYAJPJ: I wish I had seen this channel earlier
* _2017-01-17 19:10:51_> @U3PLYAJPJ: I share my personal notes  about embedded/dsp platforms and SoCs <https://docs.google.com/document/d/127PLITWRWDvm3vC3mLTwFvNJEo_imAp6XLYlTrRXE24/edit?usp=sharing>
* _2017-01-17 19:11:00_> @U3PLYAJPJ: I am sure you are aware of them
* _2017-01-17 19:12:07_> @U38HVMZ6K: :wink: this is the channel in which I am most active. Looking forward to discuss these topics with you tomorrow.
* _2017-01-17 19:12:35_> @U38HVMZ6K: Thanks for sharing your doc!
* _2017-01-17 19:15:07_> @U38HVMZ6K: I had similar ideas and components in mind. Zynq or Altera SoC (<https://www.altera.com/products/soc/overview.html>)
* _2017-01-17 19:16:46_> @U38HVMZ6K: Or some TI DSPs you mentioned, Parallela or others.
* _2017-01-17 19:17:46_> @U38HVMZ6K: The major issue is the ADC parallel interface for which only few MCUs/SoC provide a good interface.
* _2017-01-17 19:18:14_> @U3PLYAJPJ: AM5728 seems very promising pros: Quad Cortex/DSP/GPU/PRU/MCU
* _2017-01-17 19:18:41_> @U38HVMZ6K: And the price target of the system is also a limitation towards high-end CPUs/FPGAs....
* _2017-01-17 19:18:47_> @U3PLYAJPJ: also there is an open design based on beagleboar x15
* _2017-01-17 19:19:01_> @U38HVMZ6K: Let's discuss live tomorrow
* _2017-01-17 19:19:37_> @U3PLYAJPJ: definitley
* _2017-01-17 19:19:48_> @U3J40RUDT: Is there an online meeting tomorrow? 
* _2017-01-17 19:20:34_> @U38HVMZ6K: Yep. Online and Masoud and I will be both together from. Lausanne/Switzerland.
* _2017-01-17 19:20:53_> @U3J40RUDT: Ok cool! 
* _2017-01-17 19:21:19_> @U38HVMZ6K: Online will be at the same address: <https://meet.jit.si/echopenEmbedded>
* _2017-01-17 19:56:06_> @U0AAL4W13: Beagleboneblack + prudaq ^^ gives up to 40msps accessible as a /dev/adc/ device (OK, I'm out, need to stop hustling the bbb)
* _2017-01-18 08:19:45_> @U38HVMZ6K: Hi all! Today evening 20:00 CET, we'll have our weekly embedded system meeting. To follow up with the discussion we had 2 weeks ago, you can put your inputs/ideas in the shared Framapad here: <https://annuel.framapad.org/p/embsysBrainstorm> So far only <@U3GHS132Q> added a short remark (reactions: @U0B47KC3S)
* _2017-01-18 14:17:55_> @U3GHS132Q: About FPGA there is the Lattice Ice40 which has a totally open source toolchain (<http://www.clifford.at/icestorm/>). I do not really know this FPGA in term of power, some products can be found here <http://www.latticestore.com/default.aspx?tabid=417&amp;categoryid=9&amp;searchid=1&amp;searchvalue=ice40> There is a "cheap" dev kit <http://www.latticestore.com/products/tabid/417/categoryid/59/productid/258/searchid/1/searchvalue/ice40/default.aspx>  We can discuss the idea of FPGA tonight.
* _2017-01-18 14:24:15_> @U38HVMZ6K: these Ice40 FPGAs are indeed cheap but really low-end (few I/Os, no DSP blocks, no high-speed interfaces,...)
* _2017-01-18 14:27:14_> @U38HVMZ6K: the open-source toolchain is a nice initiative but... 1. it supports Verilog only. In Europe VHDL is generally preferred. 2. I fear that the tools are usable for small DIY projects but do not provide the functionality of commercial products.
* _2017-01-18 14:28:14_> @U38HVMZ6K: by experience, even the most advanced tools from chip manufacturers  (Xilinx, Altera) who know perfectly well their architectures are buggy...
* _2017-01-18 14:30:42_> @U38HVMZ6K: in the computer engineering GCC has established as one of the best and most used compilers and it is open source. In the EDA tools field, open source is (unfortunately) still way behind the state-of-the-art and thinks won't change so much as long as chip designs and architectures stay closed and proprietary
* _2017-01-18 14:32:01_> @U38HVMZ6K: I know this is not an answer you like but this is the state of current world...
* _2017-01-18 14:34:15_> @U38HVMZ6K: And even if some interesting initiatives start to get thrust (RISC-V and other open-hardware cores) we are still light years behind current technologies (Zynq, high-end FPGAs, heterogeneous CPUs,...)
* _2017-01-18 16:43:38_> @U3PLYAJPJ: I have the lattice Ice40 and tried the open tool-chain before It seems relatively stable
* _2017-01-19 20:17:51_> @U3TUWV3SQ: <@U3TUWV3SQ> has joined the channel
* _2017-01-21 18:11:37_> @U38HVMZ6K: Clarius user manual released 2 days ago! Good manual with many technicals details (ISO,IEC standards, performance figures...) <https://www.clarius.me/wp-content/uploads/2017/01/UltrasoundUserManual.pdf> (reactions: @U0B47KC3S,@U3PLYAJPJ,@U0AAL4W13)
* _2017-01-21 19:48:16_> @U0FN1B8KD: Top
* _2017-01-23 22:26:38_> @U3GHS132Q: Hello everyone I am sorry but I will not be able to come this and next Wednesday because I have to study for my exams
* _2017-01-23 22:28:15_> @U0B47KC3S: good  luck <@U3GHS132Q> !
* _2017-01-24 20:00:42_> @U37GZRZU6: I won't be able to stay for the embsys meeting either this week
* _2017-01-24 20:01:10_> @U37GZRZU6: (but will be at echOpen at 6:30 for sigproc)
* _2017-01-24 20:13:05_> @U0AAL4W13: won't be there neither, will be at work :confused: (stupid consulting job :stuck_out_tongue: )
* _2017-01-24 20:21:59_> @U38HVMZ6K: OK then with most of us busy somewhere else and me at "homespital" I suggest we cancel tomorrow.
* _2017-01-25 20:18:08_> @U38HVMZ6K: :heart_eyes::open_mouth: OMG what a beast! 4x ARM Cortex-A53 64bits cores 2x ARM Cortex-R5 real-time and safety specialized cores 1x Mali GPU DDR4 memory FPGA logic fabric for custom processing And all this already integrated !!! <http://linuxgizmos.com/com-duo-expands-upon-quad-a53fpga-zynq-ultrascale/>
* _2017-01-25 20:19:16_> @U20C8CKTL: I prefer mine  ! <http://www.nvidia.com/object/jetson-tx1-module.html>
* _2017-01-25 20:19:24_> @U20C8CKTL: :P
* _2017-01-25 20:20:58_> @U38HVMZ6K: Nice as well! A bit more powerful for real image processing (better GPU, CUDA,...) but a bit less flexible towards industrial applications.
* _2017-01-25 20:21:38_> @U38HVMZ6K: And I definitely hate Nvidia for their lack of documentation and support.
* _2017-01-25 20:24:53_> @U38HVMZ6K: Unless you are a manufacturer producing in the millions pieces/year they just don't care about you.
* _2017-01-25 20:29:05_> @U38HVMZ6K: On my current project I'm working with an Nvidia Tegra3 (older than K1/X1) and documentation and support is just dramatically poor. Compared to other manufacturers who provide full documentation (TI, NXP/Freescale, ST, Xilinx,...) you are just let alone in the dark...
* _2017-01-25 20:30:55_> @U38HVMZ6K: And their commitment to open source community is not so good as well. With our Tegra3 we are stuck with an oooold 3.1.10 kernel, the one and only supported by Nvidia if you want graphics acceleration with their proprietary drivers.
* _2017-01-25 20:32:31_> @U38HVMZ6K: If you move to mainline/up to date kernel, it works but you loose all compatibility with graphics acceleration --&gt; no way for any application involving strong processing
* _2017-01-25 20:53:34_> @U38HVMZ6K: And I'm not alone... :joy:  <https://youtu.be/i_kk4MCd4wU> (reactions: @U3PLYAJPJ,@U0B47KC3S)
* _2017-01-25 22:00:42_> @U0B47KC3S: <@U38HVMZ6K> great and cheap ! question : how large is FPGA community vs DSP ?
* _2017-01-25 22:27:09_> @U38HVMZ6K: Cheap it depends...  &gt; starting at $157, tiering down to $112 in 10K+ volume for the 1GB commercial range SKU. The Mercury+ XU3 will start at $800 with 2GB RAM, dropping down to $520 at 10K. 
* _2017-01-25 22:29:21_> @U38HVMZ6K: FPGA community is much smaller I would say and more difficult to "jump in" than DSP programming.
* _2017-01-25 22:31:53_> @U38HVMZ6K: DSP programming is open to any developer with a good background in C and some awareness on limited resources implied by an embedded system. Advanced features of DSPs still require deep expertise and experience but such kind of experience is easier to acquire.
* _2017-01-25 22:32:05_> @U0AAL4W13: I guess as well you don't do the same thing with FPGA and DSP ?
* _2017-01-25 22:32:37_> @U0AAL4W13: for example, can you connect a DSP to a wifi chip without microcontroler in between ?
* _2017-01-25 22:32:58_> @U0AAL4W13: (out of curiosity of course)
* _2017-01-25 22:34:31_> @U38HVMZ6K: As always it depends on the DSP... Today most DSP chips have internal peripherals (UARTs, SPI, I2C, SDIO or even USB)
* _2017-01-25 22:34:56_> @U38HVMZ6K: Most of the wifi chip I know use one of these interfaces
* _2017-01-25 22:37:02_> @U0AAL4W13: sweet !
* _2017-01-25 22:37:17_> @U38HVMZ6K: For a raw FPGA, connecting it to a wifi chip is somehow more challenging. You'll have to integrate a controller in the "hardware"/programmable logic of the FPGA.
* _2017-01-25 22:38:42_> @U0AAL4W13: true
* _2017-01-25 22:39:27_> @U38HVMZ6K: The real benefit of architectures like the Zynq, Zynq UltraScale or Altera Aria is that you combine standard microcontroller cores (ARM Cortex) with "FPGA-style" programmable logic in the same silicium chip.
* _2017-01-25 22:41:00_> @U38HVMZ6K: And the second advantage is that you have high bandwidth buses between the FPGA side and the ARM side which is otherwise often problematic if you use 2 chips (1 ARM processor and 1 FPGA)
* _2017-01-25 22:41:47_> @U38HVMZ6K: The bottleneck is often the interface between the 2 (PCI Express or other local bus)
* _2017-01-25 22:42:34_> @U38HVMZ6K: Difficult to use and difficult to design (high-speed buses on PCBs are a nightmare)
* _2017-01-25 22:43:43_> @U38HVMZ6K: I don't speak by experience, I'm absolutely a noob in hardware design but from experience and feedback from colleagues and high-level HW designers.
* _2017-01-26 13:27:24_> @U38HVMZ6K: hi team, I sent a e-mail to Enclustra to ask them about availability of their different modules since they are are "in development" or coming soon. I got an answer within 30 minutes :open_mouth:
* _2017-01-26 13:27:53_> @U38HVMZ6K: the first one to be released will be the expensive Mercury+-XU1
* _2017-01-26 13:28:02_> @U38HVMZ6K: with others following on
* _2017-01-26 13:28:47_> @U38HVMZ6K: <@U38HVMZ6K>
* _2017-01-26 13:30:09_> @U38HVMZ6K: <@U38HVMZ6K> and commented: XU1 manual
* _2017-01-26 13:31:35_> @U38HVMZ6K: <@U38HVMZ6K> and commented: E-mail with roadmap
* _2017-01-26 17:16:30_> @U3WRNP30B: <@U3WRNP30B> has joined the channel
* _2017-01-30 11:53:54_> @U3Y2FPGBV: <@U3Y2FPGBV> has joined the channel
* _2017-01-30 16:49:01_> @U3XHSAQHE: <@U3XHSAQHE> has joined the channel
* _2017-02-01 16:22:11_> @U38HVMZ6K: Hi everyone. I have some family issues and will not be able to attend today evening. You can still have the meeting on <https://meet.jit.si/echopenEmbedded>
* _2017-02-01 16:23:56_> @U3PLYAJPJ: Thanks for the link and I hope everything is fine
* _2017-02-01 16:34:40_> @U38HVMZ6K: You can discuss the following block diagram which was sent to me by <@U0B47KC3S> 
* _2017-02-01 16:35:03_> @U38HVMZ6K: <@U38HVMZ6K>
* _2017-02-01 16:36:03_> @U38HVMZ6K: This is the block diagram of the demonstrator provided by J-C Billard
* _2017-02-01 17:15:52_> @U0B47KC3S: thank you <@U38HVMZ6K>, do you have something in mind you want to treat 4 tonight’s session ?
* _2017-02-01 17:16:09_> @U0B47KC3S: hope everything is fine on your side
* _2017-02-01 17:17:06_> @U38HVMZ6K: no worry, everything is fine just some organization issues and a bit trouble but nothing serious
* _2017-02-01 17:18:03_> @U38HVMZ6K: for tonight session, if people are joining, it would be good to discuss the block diagram above sent by J-C and to think about the signal pulse detector and echo-AFE blocks
* _2017-02-01 17:18:42_> @U38HVMZ6K: it would be good also to do some summary/listing of the different solutions we discussed (FPGA, CPUs, ...)
* _2017-02-01 17:18:52_> @U38HVMZ6K: <@U3PLYAJPJ> has some inputs on this
* _2017-02-01 17:21:58_> @U0B47KC3S: ok ! cc <@U37GZRZU6> <@U3PLYAJPJ> <@U3J40RUDT> <@U3GHS132Q>
* _2017-02-01 17:26:09_> @U3PLYAJPJ: I will be available (reactions: @U38HVMZ6K,@U0B47KC3S)
* _2017-02-01 17:41:59_> @U3J40RUDT: Hey, I can't make it tonight, another day working late, I have a deadline for a chip (tapeout) so I'm pulling long hours! It's possible that will be the case next week too but after that I will be more free... I'll keep following the discussion here! 
* _2017-02-01 17:49:55_> @U0B47KC3S: ok <@U3J40RUDT> thanks for the update
* _2017-02-04 13:49:51_> @U41049CQ2: <@U41049CQ2> has joined the channel
* _2017-02-07 14:20:16_> @U41ATL4EM: <@U41ATL4EM> has joined the channel
* _2017-02-07 14:21:49_> @U421EN2RG: <@U421EN2RG> has joined the channel
* _2017-02-07 14:32:26_> @U04DFTZ7D: <@U38HVMZ6K>, please meet <@U41ATL4EM> and <@U421EN2RG> from UPMC and with 3 others students will work on removing the Redpitaya and other topics :wink:
* _2017-02-07 14:39:55_> @U38HVMZ6K: hi <@U41ATL4EM> and <@U421EN2RG> ! welcome aboard !
* _2017-02-07 14:40:25_> @U41B4HNU9: <@U41B4HNU9> has joined the channel
* _2017-02-07 14:41:50_> @U38HVMZ6K: the embedded system Slack channel (<#C3F765DT7>) and team is working on the future hardware implementation.
* _2017-02-07 14:42:32_> @U41AB163S: <@U41AB163S> has joined the channel
* _2017-02-07 14:43:22_> @U38HVMZ6K: Things and the team are still being put in place and the roadmap, architecture, ... are still being discussed
* _2017-02-07 14:43:39_> @U424835JR: <@U424835JR> has joined the channel
* _2017-02-07 14:44:03_> @U41ATL4EM: Hi, thank you !
* _2017-02-07 14:44:47_> @U38HVMZ6K: we generally meet on Wednesday evening (8:00-9:00PM) either at echOpen headquarters in Paris for those being in the area and otherwise online through videoconference
* _2017-02-07 14:45:33_> @U38HVMZ6K: I'm myself based in Switzerland and still never met the team except <@U0B47KC3S> and  <@U04DFTZ7D> when they presented echOpen in Lausanne last year
* _2017-02-07 14:45:43_> @U0AAL4W13: on the maker/modular approach, there's also lots of room to investigate  (sorry <@U38HVMZ6K> I'm not including embdsys in analog hardware ^^)
* _2017-02-07 14:46:01_> @U04DFTZ7D: Great, thanks <@U38HVMZ6K> for the detail. The polytech team is currently working on their design brief and will still work on it for the next 2 weeks. But i will let them give you more detail about what they are going to work on.
* _2017-02-07 14:46:33_> @U38HVMZ6K: yep sure <@U0AAL4W13>, no problem and I'm more than happy with that :wink: I'm definitely a noob in analog
* _2017-02-07 14:49:02_> @U38HVMZ6K: I'm quite busy these days/weeks at job, family, ... and cannot commit to any available time window but I'll stay reachable over Slack and will do my best to assist where I can
* _2017-02-07 15:53:42_> @U42P4AT7Z: <@U42P4AT7Z> has joined the channel
* _2017-02-08 09:50:44_> @U38HVMZ6K: hi <#C3F765DT7> channel ! I should be able to join today evening and I think we should sync up and discuss on following topics. Feel free to make proposals and changes to this agenda:  1) Status of new BM demonstrator (<@U3GHS132Q> , <@U0B47KC3S> any update on that point ?). Current status, when do we expect to have code, schematics, documentation,... handed over to the community ? 2) Polytech guys presentations: who they are, what are their tasks/objectives, for how long are they planned on the project,... 3) Miscellaneous: status on parallel tasks,developments,... (reactions: @U0AAL4W13)
* _2017-02-08 09:53:35_> @U38HVMZ6K: We'll meet as usual at echOpen headquarters for those being there and online on <https://meet.jit.si/echopenEmbedded> for remote participants at 8PM.
* _2017-02-08 09:54:07_> @U38HVMZ6K: @polytech- guys, will you be able to join ?
* _2017-02-08 19:37:08_> @U424835JR: Hi, I will be at the echOpen headquarters for the meeting this week. 
* _2017-02-08 19:38:21_> @U0AAL4W13: <@U38HVMZ6K> looking forward to reading your minutes
* _2017-02-08 19:52:04_> @U41B4HNU9: Hello, I will be there too
* _2017-02-08 19:59:32_> @U41AB163S: I cannot be there today, sorry 
* _2017-02-08 20:02:10_> @U41ATL4EM: Hi, I'll join you online
* _2017-02-08 20:02:47_> @U38HVMZ6K: 2 minutes and I'm here...
* _2017-02-11 14:05:44_> @U0AAL4W13: <@U38HVMZ6K> : we may need you wednesday evening, 1830, online, can you be there?
* _2017-02-11 14:35:40_> @U38HVMZ6K: <@U0AAL4W13> just need to check that I don't have a late call with our partners in US that day but should be OK
* _2017-02-12 20:58:51_> @U38HVMZ6K: <http://linuxgizmos.com/linux-driven-dev-board-harnesses-sitara-pru-icss/>
* _2017-02-12 20:59:51_> @U38HVMZ6K: New board based on TI AM437x with quad-PRU... <@U0AAL4W13> will love it :wink:
* _2017-02-12 21:01:57_> @U0AAL4W13: :smiley:
* _2017-02-14 21:23:24_> @U38HVMZ6K: Hi all! How is tomorrow's meeting planned? Are the sigproc and embsys meetings already merged?
* _2017-02-14 21:27:51_> @U0B47KC3S: yes indeed, the idea is too do merge the meetings. We begin @ 18H30 !
* _2017-02-14 21:28:53_> @U0B47KC3S: Btw, part of the team will be working in the afternoon on some caracterization of the actual state of the device and some docs, to prepare the meeting in the best way
* _2017-02-14 21:30:36_> @U38HVMZ6K: :+1::skin-tone-2: 
* _2017-02-14 21:30:58_> @U3J40RUDT: I'm back too for this one!  (reactions: @U0B47KC3S,@U37GZRZU6,@U04DFTZ7D)
* _2017-02-14 21:31:15_> @U38HVMZ6K: I'll be available between 18:30 and 20:30 (reactions: @U0B47KC3S,@U37GZRZU6,@U04DFTZ7D)
* _2017-02-14 21:47:38_> @U37GZRZU6: See you tomorrow EmbSys fellows :smiley:  (reactions: @U04DFTZ7D,@U38HVMZ6K)
* _2017-02-15 18:54:04_> @U04DFTZ7D: <@U04DFTZ7D>
* _2017-02-15 18:55:10_> @U04DFTZ7D: <@U04DFTZ7D> and commented: Details about colors linked to the functional analysis !
* _2017-02-15 19:11:16_> @U38HVMZ6K: suggestion pour le budget 2017 echopen: de la bande passante et un micro-omnidirectionel :slightly_smiling_face: (reactions: @U37GZRZU6,@U3QGT3Q74)
* _2017-02-15 19:11:43_> @U38HVMZ6K: on vous perd par intermittance et entend très mal
* _2017-02-15 20:34:11_> @U3J40RUDT: Just to add a quick thing to the discussion... From what I gather, I think the FPGA approach is the best, especially at this early stage. It gives us more flexibility. I think the transition to more custom, dedicated hardware if needed is easier if we start from a working FPGA-based system.
* _2017-02-15 20:35:46_> @U3J40RUDT: (I also have a lot of experience with Altera FPGAs…so I can help there)
* _2017-02-15 22:51:39_> @U3PLYAJPJ: Today, we could hardly hear and understand the discussion which was frustrating. In our company we use Jabra Speak 410 (<http://www.jabra.com/business/speakerphones/jabra-speak-series/jabra-speak-410>). We are very satisfied with it especially when multiple people speak from different directions. If you send an address I can donate one so we can have an effective communication. (reactions: @U38HVMZ6K,@U37GZRZU6,@U0B47KC3S)
* _2017-02-15 23:44:41_> @U38HVMZ6K: Some interesting reading about acquisition of 40-50MSPS ADCs by DSPs... They all go through an FPGA for acquisition. For LIDAR, Radar and other applications.  <https://www.dsprelated.com/showthread/comp.dsp/5409-1.php>
* _2017-02-15 23:47:47_> @U38HVMZ6K: The most interesting section in the replies is: "If you want the DSP to bother with the ADC's handshake or so,this will overload your DSP, even at 13MS/s: the DSP won't have enough spare time to do the real signal processing. A basic guideline which I learnt is that a DSP is good for  algorithmic signal processing, but is is usually the wrong device  to deal with bit/pin oriented controller stuff."
* _2017-02-16 10:04:26_> @U0AAL4W13: <@U3PLYAJPJ> we're using the same "spider" at work, it's an excellent one indeed (reactions: @U3PLYAJPJ,@U38HVMZ6K)
* _2017-02-16 10:15:16_> @U0B47KC3S: thank you <@U38HVMZ6K>, check <@U07UEJC2H> <@U0GMX7QUB> <@U37GZRZU6> for yesterday’s discussion
* _2017-02-16 10:18:18_> @U38HVMZ6K: hi <@U0B47KC3S> sorry for leaving early yesterday, I had another appointment at 21:00. Was just on time :slightly_smiling_face:
* _2017-02-16 10:18:54_> @U38HVMZ6K: did you manage to get the information and roadmap you wanted for preparing the presentation to Altran ?
* _2017-02-16 10:21:21_> @U38HVMZ6K: besides the fact it was quite difficult to follow the discussion for technical reasons I think it is still quite difficult to draw some highlevel roadmap and needs from discussion we had.
* _2017-02-16 10:22:29_> @U38HVMZ6K: As promised I'll prepare a short recap' of my ideas and points we discussed offline. Hopefully it will help a bit.
* _2017-02-16 11:10:00_> @U0B47KC3S: thanks <@U38HVMZ6K>. I think we have a lot of stuff now that we can synthetise. From what was said, the report of our meeting, the global schema of main configurations and bottlenecks <@U07UEJC2H> is on and your recap, we will synthetize this on a single doc, and discuss it before the 22.02 meeting ! (reactions: @U38HVMZ6K,@U37GZRZU6)
* _2017-02-16 11:10:29_> @U38HVMZ6K: great!
* _2017-02-16 11:38:10_> @U07UEJC2H: <@U38HVMZ6K>, yep, some guys of isep also said it one time that FPGA can be used to interface high speed ADC with DSP juste as a pipe. It can be intresting hybrid solution
* _2017-02-16 11:42:50_> @U38HVMZ6K: I see following possible configurations 1) ADC -&gt; low-end (=cheap) FPGA -&gt; DSP 2) ADC -&gt; Hybrid SoC (Xilinx Zynq or Altera SoC)
* _2017-02-16 11:43:30_> @U38HVMZ6K: it's what I will put in my proposal/description with pros and cons for both
* _2017-02-16 11:58:20_> @U07UEJC2H: <@U38HVMZ6K>, at echopen with have a board (<http://knjn.com/FPGA-RS232.html>) with a small cheap FPGA (aletra acex ep1k10) which can drive 60Msps ADC. I don't know if it is a good solution but maybe a lead
* _2017-02-16 12:00:49_> @U07UEJC2H: PS: just saw that they are end of life....
* _2017-02-16 12:02:56_> @U3J40RUDT: That fpga is no longer supported by the design software, would have to use a really old version
* _2017-02-21 15:44:28_> @U41AB163S: <@U41AB163S> Here is the specification of the project
* _2017-02-21 15:45:04_> @U04DFTZ7D: Thanks <@U41AB163S>
* _2017-02-24 11:22:57_> @U492PCSE9: <@U492PCSE9> has joined the channel
* _2017-02-25 00:19:31_> @U3GHS132Q: Good document <@U41AB163S>  :slightly_smiling_face:
* _2017-03-01 18:51:16_> @U0B47KC3S: hi one word to tell you the <#C3F765DT7> meeting will begin as usual at 8pm ! (reactions: @U3J40RUDT,@U3PLYAJPJ)
* _2017-03-01 19:57:27_> @U3J40RUDT: jitsi as usual?
* _2017-03-01 20:03:54_> @U0B47KC3S: yes !
* _2017-03-02 00:31:14_> @U3GHS132Q: A **small** report of today meetup can be edited here : <https://mensuel.framapad.org/p/CR_embsys_01_03_17> (reactions: @U0B47KC3S,@U38HVMZ6K)
* _2017-03-02 06:38:26_> @U38HVMZ6K: Thx!
* _2017-03-02 11:39:07_> @U37GZRZU6: <@U3GHS132Q> I've translated the minutes and changed some formulations. Can you review it and tell me if I understood what was said yesterday? trying hard to include myself in the embsys team :sweat_smile:
* _2017-03-02 13:05:43_> @U3GHS132Q: <@U37GZRZU6> What you did is perfect :slightly_smiling_face: I did not know that minutes have to be in english, I will translate them the next time I take them  <@U07UEJC2H> How do you actually implement the double FFT ? Do you write a FFT algorithm in C or do you use Red Pitaya's libs ? Moreover can you remind me what is the minimum frequency for ADC to get a good image ?
* _2017-03-02 13:11:52_> @U07UEJC2H: <@U3GHS132Q>, I use an algorithm in C (not on the RedPitaya but on PC) based on the fft algorithm found on rosettacode, I can send it to you if you want to see. Minimum sampling rate is around 6 times the central frequency of the transducer (forget Shannon criterion)
* _2017-03-02 14:28:24_> @U37GZRZU6: <@U07UEJC2H> what is the reason for this factor 6 ?
* _2017-03-02 14:51:39_> @U07UEJC2H: I took this factor from numerical consideration, if you do finite element you must at least have 6 points per period to have coherent numerical result (to be sure you have to make convergent study). It is my own criterion, everybody can say something else. In fact the minimum factor is 3, but you will be very sensitive to noise with this sampling rate. The more your sampling rate is high, the less you will be sensitive to noise moreover you will have preciser results on phase and amplitude
* _2017-03-02 16:02:59_> @U07UEJC2H: I am quite puzzled about what I read in the report.... Indeed, it can be very interesting to access the full power of the RedPitaya with adapted soft, but the RedPitaya is very expensive! Moreover it is apparently very difficult to implement Hilbert transform of fft in FPGA (<@U38HVMZ6K> are you agree?).
* _2017-03-02 16:05:04_> @U07UEJC2H: And the PIC32MZ can be a good option for a lab prototype (not enough for a medical device) cause it can go up to 28 Msps and I have good result with 16 Msps with the RedPitaya. And it more than half the price of the RedPitaya
* _2017-03-02 16:06:01_> @U07UEJC2H: * Hilbert transform of fft
* _2017-03-02 16:07:01_> @U37GZRZU6: <@U07UEJC2H> what do you mean by "good results"? we won't be able to reach the desired framerate (15fps) with those sampling rates, am I wrong ?
* _2017-03-02 16:07:45_> @U07UEJC2H: The last images (have you seen them?) which are the bests images we had so far
* _2017-03-02 16:08:18_> @U07UEJC2H: and sampling rate is decoralated from frame rate
* _2017-03-02 16:09:14_> @U07UEJC2H: It is enought for 3.5 MHz transducer not for 7.5 MHz
* _2017-03-02 16:11:13_> @U37GZRZU6: <@U07UEJC2H> indeed it's decorrelated you're right, my bad :sweat_smile:
* _2017-03-02 16:13:10_> @U38HVMZ6K: &gt; PIC32MZ can be a good option for a lab prototype (not enough for a medical device) cause it can go up to 28 Msps What is the CPU load when doing such an acquisition ?
* _2017-03-02 16:13:48_> @U38HVMZ6K: I fear that the PIC will be fully loaded with acquisition with no spare time for processing, communicating,...
* _2017-03-02 16:15:19_> @U38HVMZ6K: FFT on FPGAs is not so difficult. It's often implemented and good implementations exists
* _2017-03-02 16:15:48_> @U38HVMZ6K: there are even many open source implementations in VHDL/Verilog available. For example: <https://opencores.org/project,versatile_fft> (reactions: @U37GZRZU6,@U0AAL4W13)
* _2017-03-02 16:19:00_> @U38HVMZ6K: still on opencores, a Hilbert Transformer for FPGA implementation: <https://opencores.org/project,hilbert_transformer>
* _2017-03-02 16:23:40_> @U38HVMZ6K: regarding the price of RedPitaya, I agree that it is not cheap
* _2017-03-02 16:24:29_> @U38HVMZ6K: in my opinion it can be used for development as eval-kit and for the final design we should focus on ready made System-on-Module (SoM) (reactions: @U3GHS132Q)
* _2017-03-02 16:30:40_> @U07UEJC2H: <@U38HVMZ6K>, I have not an idea of the CPU load cause I have never used it for the moment
* _2017-03-02 16:32:31_> @U38HVMZ6K: OK
* _2017-03-02 16:32:48_> @U38HVMZ6K: is the PIC32 the "Le micro-contrôleur possède des ADC à 18 MHz ce qui semble insuffissant pour une acquisition de qualité." mentioned in the report of <@U3GHS132Q> ?
* _2017-03-02 16:33:06_> @U38HVMZ6K: I could not attend the meeting yesterday and so I'm a bit disconnected
* _2017-03-02 16:35:23_> @U0B47KC3S: <@U38HVMZ6K>. Yes I think so. Besides, I remember you discouraged the use of PIC 32 because not fitted for our purpose
* _2017-03-02 16:53:55_> @U0AAL4W13: <@U38HVMZ6K> I guess you don't do continuous acquisition, as you shoot lines, and listen  to them  coming back - you still have some time between each line 
* _2017-03-02 16:54:33_> @U0AAL4W13: plus if you have 3 piezo for 60 degree imaging, it leaves you half of the time in non imaging
* _2017-03-02 16:54:57_> @U0AAL4W13: (unless you sweep)
* _2017-03-02 16:55:42_> @U0AAL4W13: my point being that you have breathing points, depending on your acquisition strategy :)
* _2017-03-02 16:56:47_> @U0AAL4W13: a point though : if your lines are not spaced enough, you may have echoes from the end of previous line at the beginning of your currebt
* _2017-03-02 16:57:13_> @U37GZRZU6: <@U0AAL4W13> as regards the three piezos, that's if we constantly acquire the signal from each piezo, right? is this necessary, as in the end the user selects only one ?
* _2017-03-02 16:58:57_> @U37GZRZU6: <@U0AAL4W13> (is that what you meant by "unless you sweep" ?)
* _2017-03-02 17:03:09_> @U0AAL4W13: nope. even with three, only one is active. and that's on 60 degree out of 360.
* _2017-03-02 17:03:35_> @U0AAL4W13: so what you need to listen to is at max 180 degree out of 360 
* _2017-03-02 17:04:52_> @U37GZRZU6: yes that's what I'm saying : if only one is active, actually the imaging is only 1/6 of the time. and we won't have a situation where we are using the three piezos at the same time, right ? (reactions: @U0AAL4W13)
* _2017-03-02 17:05:02_> @U0AAL4W13: then for 20cm you have to listen 200us for a line - but you can space your lines by more than 200us, giving you leeway
* _2017-03-02 17:05:06_> @U0AAL4W13: yep! (reactions: @U37GZRZU6)
* _2017-03-02 17:07:53_> @U0AAL4W13: then your real constraints is the fps and your number of lines : if you have 128 lines at 15 fps that's 1920 lines per second, with this half time dead that gives you max 0.5*(1/1920) that's 260us per line, you have 60 us left between two lines
* _2017-03-02 17:10:50_> @U0AAL4W13: and 500ms per second where there's no acquisition and you can do some processing
* _2017-03-02 17:11:16_> @U0AAL4W13: that's reduced of course if you image on 80 degrees and not 60 :)
* _2017-03-02 19:43:32_> @U38HVMZ6K: Thx for all these figures <@U0AAL4W13>. It helps much in understanding the needs, the constraints and the challenges.  (reactions: @U0AAL4W13)
* _2017-03-02 23:00:50_> @U3GHS132Q: Interessting discussion here :slightly_smiling_face:
* _2017-03-02 23:01:55_> @U3GHS132Q: <@U07UEJC2H> If I can I would like to see your code and algorithm :slightly_smiling_face: I hope I will learn from it (I never implemented fft lol)
* _2017-03-02 23:58:56_> @U4DFR8RN3: <@U4DFR8RN3> has joined the channel
* _2017-03-03 00:58:17_> @U4CAG5ZFW: <@U4CAG5ZFW> has joined the channel
* _2017-03-03 00:58:21_> @U20C8CKTL: <@U3GHS132Q>  <https://rosettacode.org/wiki/Fast_Fourier_transform> , various fft implementation : the scala version is really fun( functional, concurent and OO).
* _2017-03-03 08:32:42_> @U38HVMZ6K: <@U3GHS132Q> and al. for software implementations of FFT I can only recommend THE open source reference library FFTW (<http://www.fftw.org/>) (reactions: @U0AAL4W13)
* _2017-03-03 08:33:40_> @U38HVMZ6K: it's a well curated library supported by a huge community and real gurus
* _2017-03-03 08:35:14_> @U38HVMZ6K: it has built-in optimizations using SIMD implementations on different architectures Altivec on PowerPC, NEON on ARM, SSE/SSE2 on x86
* _2017-03-03 08:35:47_> @U38HVMZ6K: parallel processing with threading or MPI
* _2017-03-03 08:51:12_> @U38HVMZ6K: FFTw project also provide an exhaustive list of other FFT implementations: <http://www.fftw.org/benchfft/ffts.html> and benchmarks of them (accuracy and speed) compared to FFTw. List is here (<http://www.fftw.org/benchfft/ffts.html>) and benchmarks are there (<http://www.fftw.org/speed/> and <http://www.fftw.org/accuracy/>)
* _2017-03-03 09:07:52_> @U0B47KC3S: yes <@U38HVMZ6K> anyway the implementation of fftw on android is still a little tricky because I had an issue when compiling some lib, seemingly running on 32 bits architecture. <@U3GHS132Q> I’ll show you this week-end
* _2017-03-03 09:39:29_> @U0AAL4W13: out of curiosity, what are you using fftw on android for?
* _2017-03-03 09:52:01_> @U0B47KC3S: <@U07UEJC2H> produced great images by using detection envelope in his computer, we are jusst porting the code on the android app, so we want to see those nice images on the app. But, in  the “normal” state , fft will not be processed  on the smartphone (reactions: @U0AAL4W13)
* _2017-03-03 10:13:26_> @U38HVMZ6K: &gt; I had an issue when compiling some lib, seemingly running on 32 bits architecture what is the issue ?
* _2017-03-03 10:14:13_> @U38HVMZ6K: do you mean FFTw is designed to be run on 64 bits and you had issues compiling/running it on 32 bits or the other way ?
* _2017-03-03 10:15:09_> @U38HVMZ6K: I'm sure FFTw can be compiled and run for ARM 32 bits (we used it on a Cortex-A8 single core ARM)
* _2017-03-03 10:16:12_> @U38HVMZ6K: I never used it on ARM 64 bits but these are not already widespread and I don't know how far Android supports it
* _2017-03-03 10:17:30_> @U38HVMZ6K: if something is wrong on Android I would more suspect their non standard low-level implementation (bionic libc and other creepy stuff) possibly not compatible with FFTw than FFTw itself
* _2017-03-03 10:17:46_> @U38HVMZ6K: on standard embedded Linux at least it worked like a charm
* _2017-03-03 10:21:48_> @U0B47KC3S: what is weird is that I got the android ffw implementation form this project <https://github.com/andrejb/DspBenchmarking> and the line `LOCAL_LDLIBS    := -llog -lz -lm $(LOCAL_PATH)/$(LIBFOLDER)/android/armv6/lib/libfftw3.a` fails when the following file is compiled `<https://github.com/andrejb/DspBenchmarking/blob/master/jni/Android.mk>`
* _2017-03-03 10:23:50_> @U0B47KC3S: I stackoverflowed the issue, and it seemed that this was related to a lib running on 32 bits architecture. Btw, the github project I mentionned is outdated of 4 years
* _2017-03-03 10:30:12_> @U38HVMZ6K: do you have the stackoverflow link ?
* _2017-03-03 10:52:59_> @U0B47KC3S: I passed from link to link and I am now trying to find out again but with no success for the moment. I let you know
* _2017-03-03 20:34:11_> @U3GHS132Q: <@U38HVMZ6K> FFTW seems to make coffee Oo Already SIMD optimization :open_mouth: I am sad I want to try to optimize with it lol
* _2017-03-08 00:03:20_> @U0AAL4W13: <@U38HVMZ6K> : what does the inside of a former probe yield: <https://source.wustl.edu/2009/04/ultrasound-imaging-now-possible-with-a-smartphone/>
* _2017-03-08 00:03:59_> @U0AAL4W13: <@U0AAL4W13> and commented: Could find a better pic so far
* _2017-03-08 00:11:52_> @U0AAL4W13: <@U0AAL4W13>
* _2017-03-08 07:03:14_> @U38HVMZ6K: Great! Very interesting device. That's the kind of architecture I would go for a low-cost version. 
* _2017-03-08 07:11:03_> @U38HVMZ6K: Several highlight points from the article: - 100'000$ grant from Microsoft.  - "Some of these USB-based probes sell for less than $2,000 with the goal of a price tag as low as $500." - Field trials in the Third World. Personal note: not for philanthropic reasons but because regulations are more relaxed or not existing... - "One such application could find its way to the military". Philanthropy stops here and they go where budget is available. Sad but true reality. (reactions: @U0AAL4W13)
* _2017-03-08 19:43:43_> @U38HVMZ6K: Stucked in a boring dinner with our US customers today evening. I will not attend today's meeting unless I can make diversion and discretely escape :joy: 
* _2017-03-08 19:53:24_> @U0B47KC3S: ok tell us !!
* _2017-03-08 20:40:34_> @U3PLYAJPJ: <@U38HVMZ6K> Have fun :grimacing:
* _2017-03-15 20:27:58_> @U3GHS132Q: Hey ! Nobody can come on jitsi for the embsys meetin ?
* _2017-03-15 20:39:36_> @U0AAL4W13: What's happening?
* _2017-03-15 20:43:38_> @U3GHS132Q: I am on the jitsi and no there is no one :cry:
* _2017-03-15 20:45:59_> @U3J40RUDT: Hey guys, i'm just leaving the lab now, I completely forgot it was Wednesday! 
* _2017-03-15 20:46:49_> @U3GHS132Q: <@U3J40RUDT> No problem ^^
* _2017-03-15 20:46:53_> @U3J40RUDT: I guess by the time I get home it'll be too late 
* _2017-03-20 22:40:53_> @U41ATL4EM: <@U41ATL4EM> and commented: Hey everyone, we're having a presentation of our progress on the project tomorrow at our school, I'm uploading the presentation if anyone is interested
* _2017-03-21 00:10:36_> @Hyacinthe: <@U0AAL4W13>: Thanks!
* _2017-03-21 00:15:23_> @U0B47KC3S: thanks polytech-kevin tech team ! we’ll see each other tomorrow afternoon and my take on it that <@U37GZRZU6> will masterfully enounce  some github/gitbook documentation principles :wink: (reactions: @U37GZRZU6)
* _2017-03-21 00:52:50_> @U41ATL4EM: alright see you tomorrow afternoon then !
* _2017-03-21 08:43:46_> @U38HVMZ6K: <@U41ATL4EM> thanks for sharing! I'll have a look at it when I find 15 mins of spare time
* _2017-03-21 10:35:31_> @U3GHS132Q: <@U41ATL4EM> Good presentation :slightly_smiling_face: According to your Gantt planing you are actually trying to get analog signal from FPGA, where are you in your current task ? Did you get exciting results ?
* _2017-03-21 10:55:29_> @U41ATL4EM: Thank you <@U3GHS132Q> Currently we are trying to program the RedPitaya with a frequency counter code we found on the internet that uses an acquisition with the ADC, but we had some issues with it, it is supposed to display a frequency we type in input, but it shows a wrong frequency
* _2017-03-21 10:56:27_> @U41ATL4EM: We'll try to figure out if the issue is coming from the acquisition or the signal generation today
* _2017-03-21 10:57:15_> @U3QGT3Q74: I have few comments :) You should split project goals - probe miniaturisation / device performances (15 frames / seconds) from technical solutions you want to implement - Unique PCB - FPGA development and explain why you make theses choices Also is the school forcing you to use Gantt planification? It seems to me that it is an old school V cycle development method. I don't know much about hardware development but for software we use more flexible planification Agile/ kan ban ... (reactions: @U37GZRZU6)
* _2017-03-21 10:59:51_> @U3GHS132Q: <@U41ATL4EM> Is the code you got on the web in VHDL ? If yes can I see it ?
* _2017-03-21 11:00:00_> @U38HVMZ6K: &gt; a frequency counter code we found on the internet that uses an acquisition with the ADC Could you share it ? (reactions: @U3GHS132Q)
* _2017-03-21 11:04:38_> @U3GHS132Q: Best method for any development (hardware of software) is [<http://www.la-rache.com/> :stuck_out_tongue: :stuck_out_tongue: :stuck_out_tongue: (reactions: @U0AAL4W13)
* _2017-03-21 11:41:10_> @U41ATL4EM: It's actually a project on Xilinx Vivado, and the code is not in VHDL but in Verilog
* _2017-03-21 11:43:24_> @U3GHS132Q: Even though Verilog and VHDL share the same principle I think that it would be greater for you to use the one you are the more familiar with
* _2017-03-21 11:44:14_> @U3GHS132Q: So is the code on the website of Vivado ? Or in your Vivado IDE ?
* _2017-03-21 11:44:56_> @U38HVMZ6K: Most probably packed in Vivado examples. Is it this <@U41ATL4EM>  ? <https://wiki.trenz-electronic.de/display/ToT/Vivado+Frequency+Meter>
* _2017-03-21 11:47:04_> @U3J40RUDT: It looks like it's a core IP from Xilinx
* _2017-03-21 11:47:32_> @U38HVMZ6K: yep: <http://www.xilinx.com/support/documentation/ip_documentation/c_counter_binary/v12_0/pg121-c-counter-binary.pdf>
* _2017-03-21 11:47:42_> @U38HVMZ6K: or some other IP
* _2017-03-21 11:47:46_> @U41ATL4EM: No it's on another website I'll send it later around 1pm 
* _2017-03-21 12:43:26_> @U41ATL4EM: Here is the link we found <http://antonpotocnik.com/?p=519284>
* _2017-03-21 12:43:47_> @U41ATL4EM: And the project is on that github <https://github.com/apotocnik/redpitaya_guide>
* _2017-03-21 13:04:03_> @U3GHS132Q: You use exactly the same code and you do not get the same frequency ?
* _2017-03-21 13:11:05_> @U41ATL4EM: Yes we didn't change the code
* _2017-03-21 13:20:02_> @U38HVMZ6K: quick look through the sources shows: - they use an open source Verilog IP for ADC: <https://github.com/apotocnik/redpitaya_guide/blob/master/projects/4_frequency_counter/basic_red_pitaya_bd.tcl#L67> - Verilog sources for the ADC are also freely available at <https://github.com/pavel-demin/red-pitaya-notes/blob/master/cores/axis_red_pitaya_adc_v1_0/>
* _2017-03-21 13:21:59_> @U38HVMZ6K: I'm absolutely not familiar with Verilog but the ADC "IP" seems to be quite dumb and could be implemented easily in VHDL: <https://github.com/pavel-demin/red-pitaya-notes/blob/master/cores/axis_red_pitaya_adc_v1_0/axis_red_pitaya_adc.v>
* _2017-03-21 13:24:06_> @U3J40RUDT: Ill check it out in a bit im quite familiar with verilog 
* _2017-03-21 13:25:27_> @U41ATL4EM: Yes the code for the ADC is just extending the sign bit if I remember correctly
* _2017-03-21 13:26:29_> @U41ATL4EM: and also merges both input signals into a single output signal
* _2017-03-21 13:34:17_> @U38HVMZ6K: shifting a single bit coming from ADC at every clock edge and provide the concatenated value of both 14 bits ADCs in a single 32 bits word yes
* _2017-03-21 15:41:46_> @U41B4HNU9: <@U41B4HNU9> and commented: Hello, we are currently studying (with Niverthan) the analog part of the project. We are trying to improve the peak detector but the problem is that normaly the circuit we have designed is not supposed to take the threshold of the diode. Have we made any mistake on the design of the circuit ?
* _2017-03-21 15:41:50_> @U41B4HNU9: <@U41B4HNU9>
* _2017-03-21 15:44:12_> @U41B4HNU9: Here you can find our circuit which realize the peak detection with the negative lobes rectifier and the simulation of the circuit
* _2017-03-21 15:48:17_> @U0AAL4W13: looks like a diode bridge rectifier behavior ?
* _2017-03-21 15:52:52_> @U0AAL4W13: for peak detection you may be interested in this thread <http://electronics.stackexchange.com/questions/112347/how-to-make-a-peak-detector-circuit> (and there may be hints about a track and hold approach as a bonus ^^)
* _2017-03-21 16:00:04_> @U41B4HNU9: Thank you for the link (We have thought about the diode bridge but I think it's not adapted in this case because of the voltage drop caused by diodes)
* _2017-03-21 22:30:14_> @U0GMX7QUB: My two cents, about an idea we had several months ago but never tested. If we remove R25, the circuit will hold indefinitely the peak value. We can digitize it at any time. Then, the µcontroller have to shorten C8 to reset the last peak value. Thus the sampling frequency is no longer dependent on the frequency of the input signal (n times 3.5MHz) but on the number of samples per second required to have a resolution greater than 1mm (n times 770KHz). To avoid to be blind during C8 reset we could use two out of phase peak detector.
* _2017-03-21 22:34:44_> @U0AAL4W13: One also needs to get a way to reset the value "held" to zero in a very short time (so to minimize the "blind" period)
* _2017-03-22 12:30:16_> @U0AAL4W13: <@U41B4HNU9> <@U0GMX7QUB> we had this sort of setup for track and hold, with live demo :  <http://www.falstad.com/circuit/e-peak-detect.html>
* _2017-03-22 19:46:49_> @U3J40RUDT: Is there a meeting tonight ? 
* _2017-03-22 19:48:25_> @U0B47KC3S: sure ! we are finishing the SigProc meeting
* _2017-03-22 20:42:14_> @U3J40RUDT: What bandwidth are you aiming for, for the op amp ?
* _2017-03-22 21:00:25_> @U3GHS132Q: <@U3J40RUDT> I do not know, which bandwith are you speaking ? Wifi bandwith ?
* _2017-03-22 21:01:17_> @U3GHS132Q: Notes from today meetup are here <https://mensuel.framapad.org/p/CR_embsys-2017-03-22> I will traduct them tonight.  They will stay one week on framapad then I will commit them in the gitbook.
* _2017-03-22 21:02:04_> @U3J40RUDT: The op amps used for the peak detector 
* _2017-03-22 21:03:01_> @U3GHS132Q: Unhappily I can not answer you because of my poor knowledge in analogic :s
* _2017-03-22 21:23:49_> @U41B4HNU9: We are aiming to use a high GBW op amp in this case
* _2017-03-22 21:24:38_> @U3J40RUDT: What order approximately? 
* _2017-03-22 21:24:53_> @U3J40RUDT: 50 mhz ? 
* _2017-03-22 21:25:20_> @U41B4HNU9: Above 200
* _2017-03-22 21:26:05_> @U41B4HNU9: Oh sorry I'm speaking for the bandpass we have designed
* _2017-03-22 21:27:52_> @U41B4HNU9: but for the peak detector, I think that 50Mhz bandwidth op amp will be enough
* _2017-03-22 21:30:04_> @U3J40RUDT: I found a reference of one that could be interesting ill post it here when i get back home 
* _2017-03-22 21:35:41_> @U41B4HNU9: ok thank you very much
* _2017-03-22 23:42:21_> @U3J40RUDT: I found this source, <http://www.linear.com/solutions/7161>
* _2017-03-22 23:42:41_> @U3J40RUDT: <http://cds.linear.com/docs/en/datasheet/6244fb.pdf>
* _2017-03-22 23:42:49_> @U3J40RUDT: That’s the op amp
* _2017-03-27 12:51:06_> @U3GQS8JTZ: <@U3GQS8JTZ> has left the channel
* _2017-03-29 18:32:12_> @U3GHS132Q: It seems that there are no auto remember for embsys channel but I notify the channel that there is a meeting tonight at 8 o'clock :slightly_smiling_face:
* _2017-03-29 18:49:54_> @U04DFTZ7D: <@U3GHS132Q> someone unscheduled it ! But I can re-schedule it if needed. Let me know 
* _2017-03-29 18:58:47_> @U0B47KC3S: yes oliv you should tell the bot he’s welcome to remind us :wink:
* _2017-03-29 20:17:56_> @U3GHS132Q: <@U3PLYAJPJ>  <@U38HVMZ6K> are you free to come on jitsi ?
* _2017-03-29 20:19:03_> @U38HVMZ6K: sorry, busy at a session of my village's municipal council today evening
* _2017-03-29 20:21:11_> @U3PLYAJPJ: <@U3GHS132Q> Hi,  sorry I haven't been accessible the last two weeks I cannot attend for the whole meeting, but I can join if you need me for coordiantion
* _2017-03-29 20:31:47_> @U3GHS132Q: If you can come it would be cool :slightly_smiling_face:
* _2017-03-29 20:40:17_> @U3PLYAJPJ: <@U3GHS132Q> here is the link of an example logic analyzer
* _2017-03-29 20:40:24_> @U3PLYAJPJ: using icestick
* _2017-03-29 20:40:36_> @U3PLYAJPJ: <https://blackmesalabs.wordpress.com/2016/12/22/sump2-100-msps-32bit-logic-analyzer-for-icoboardraspberrypi/>
* _2017-03-29 20:44:08_> @U3PLYAJPJ: sorry this the correct link <https://blackmesalabs.wordpress.com/2016/10/24/sump2-96-msps-logic-analyzer-for-22/>
* _2017-03-29 21:39:37_> @U0AAL4W13: As discussed tonight, here's a shield for a up to 40msps adc based on a beaglebone : <https://github.com/google/prudaq/wiki>
* _2017-03-29 21:41:00_> @U0AAL4W13: It exposes the adc as a /dev/device with 0 cpu overhead, with clean programming it could stream in close real time images
* _2017-03-29 21:41:18_> @U0AAL4W13: Could be an interesting alternative to the redpitaya
* _2017-04-01 20:54:00_> @U3GHS132Q: Hello, I will buy some hardware from <http://eu.mouser.com/> delivery are free over 50€ and my device costs ~ 40€ so if someone wants to buy something do not hesitate to contact me :slightly_smiling_face: I can lend money for device less than 30€ (reactions: @U0B47KC3S)
* _2017-04-05 12:04:25_> @U04DFTZ7D:  set up a reminder “:mega: a memo for the embysy weekly meeting” in this channel at noon every Wednesday, Central European Summer Time.
* _2017-04-05 15:07:23_> @U37GZRZU6: As it is holidays, polytech-guys are not here this week --&gt; I'm not sure if it's worth maintaining the weekly embsys meetings, depending on who has planned to attend tonight : <@U3GHS132Q> <@U3PLYAJPJ> <@U38HVMZ6K> <@U3J40RUDT> what do you think ?
* _2017-04-05 15:09:36_> @U3J40RUDT: Im ok either way, i'll be there if it's still on 
* _2017-04-05 15:10:54_> @U38HVMZ6K: hi, I personnally cannot attend. Busy with many professional and private/family activities and issues these last weeks.
* _2017-04-05 15:11:27_> @U38HVMZ6K: I'm a bit less involved but always follow on what's going on on Slack and where stuff gets published
* _2017-04-05 15:11:41_> @U38HVMZ6K: I hope to be able to join again more actively soon
* _2017-04-05 15:12:46_> @U37GZRZU6: <@U38HVMZ6K> no worries, thanks for the update! hope you're doing well :slightly_smiling_face:
* _2017-04-05 16:48:00_> @U3GHS132Q: I think that it is important to maintain the meeting even thought few people can come (reactions: @U0AAL4W13)
* _2017-04-05 17:00:51_> @U37GZRZU6: <@U3GHS132Q> sure, but actually, with polytech-guys, <@U0B47KC3S> and <@U38HVMZ6K> missing, the question is : "is <@U3GHS132Q> the only one who can attend tonight's meeting ?" if the answer is "yes", I think it won't be very productive to maintain the meeting :wink: obviously, if <@U3PLYAJPJ> has planned to be with us, let's go for it
* _2017-04-05 17:06:13_> @U3GHS132Q: I will do the meeting alone, thinking of embsys, myself and the sense of life ! (reactions: @U37GZRZU6,@U0B47KC3S)
* _2017-04-06 21:54:29_> @U0AAL4W13: <@U3GHS132Q> have a look at that sh*t : <https://hackaday.io/project/20989-beaglewire> :wink:
* _2017-04-06 22:53:23_> @U3GHS132Q: Pretty interesting but it is a ice40hx4k so only around 4000 LUT (the fewer LUT you have, the simpler the designs you implement are)
* _2017-04-07 09:35:02_> @U0AAL4W13: Yup, screw cheap designs which force you to have clever implementation :trollface: 
* _2017-04-07 09:35:42_> @U0AAL4W13: (Disclaimer: I have tremendous respect for 1k challenges, the demo scene and such)
* _2017-04-07 09:36:47_> @U0AAL4W13: <@U3GHS132Q> btw with this cape you can stack the adc so it means you have play with some simple signal proc at first :)
* _2017-04-07 09:41:45_> @U38HVMZ6K: other capes/hats of interest are the LOGI family: <https://www.element14.com/community/docs/DOC-69129/l/logi-fpga-development-boards-by-valentfx>
* _2017-04-07 09:42:56_> @U38HVMZ6K: with Xilinx Spartan6 FPGAs, a bit more powerful. Available for BBB (<http://valentfx.com/wiki/index.php?title=Logi-Bone_Quick_Start_Guide>) or Pi (<http://valentfx.com/wiki/index.php?title=Logi-Pi_Quick_Start_Guide>)
* _2017-04-07 11:32:04_> @U3J40RUDT: The arduino compatibility is pretty cool 
* _2017-04-07 11:43:14_> @U3J40RUDT: This one should also be quite good, it has pretty much everything on it <https://www.altera.com/products/boards_and_kits/dev-kits/altera/max-10-fpga-development-kit.html#Contents>
* _2017-04-07 16:44:12_> @U3GHS132Q: I always screw at defining what is an embedded system, here is an approximately complete (the authors does not define some acronym...) link which answers this question <https://blog.fedora-fr.org/renault/post/Les-syst%C3%A8mes-embarqu%C3%A9s>
* _2017-04-10 10:51:14_> @U37GZRZU6: Some news about our prototyping gitbook - work is still ongoing, but I completed the "how to contribute" section, no I would need some guinea pig to read it and give me a feedback about what's not clear enough :slightly_smiling_face: any volunteer ? would be interesting to get an opinion from someone who hasn't contributed yet to the echOpen github... <@U3J40RUDT> <@U4J138ZTL> <@U3PLYAJPJ> ?   <https://echopen.gitbooks.io/echopen_prototyping/content/howto/method.html> (reactions: @U0B47KC3S,@U04DFTZ7D)
* _2017-04-10 10:51:23_> @U4J138ZTL: <@U4J138ZTL> has joined the channel
* _2017-04-10 15:38:51_> @U3GHS132Q: I read it yesterday and find it clear ! Oh I already contributed lol :stuck_out_tongue: :stuck_out_tongue: :stuck_out_tongue: (reactions: @U37GZRZU6,@U0B47KC3S,@U0AAL4W13)
* _2017-04-10 17:52:30_> @U07UEJC2H: <@U37GZRZU6>, I read the gitbook. First why to you post that in this channel? general or method may be more accurate or we can make an prototyping channel?  You made classical typo, there is no space before colons. And may be one can explain quickly how to make a fork and a pull request (it is not so intuitive I think).
* _2017-04-10 22:05:04_> @U0AAL4W13: <@U3GHS132Q> <@U38HVMZ6K> I know you'll love that : <https://hackaday.io/project/7212-oshchip-v10> :smiley: (reactions: @U38HVMZ6K,@U0GMX7QUB)
* _2017-04-10 22:13:58_> @U3GHS132Q: It is an ARM CPU so I do no think that the CPU is open hardware. For this little card like this one I think that RISC V will be better.  But I think that this card should be funny to use :slightly_smiling_face: I wonder how is it possible to run an OS on this card, 32 KB of SRAM is few moreover it is SRAM so used as (L1, L2 or L3) cache in general.
* _2017-04-11 08:09:56_> @U38HVMZ6K: So coooool!
* _2017-04-11 08:34:19_> @U38HVMZ6K: &gt; It is an ARM CPU so I do no think that the CPU is open hardware Indeed, it's not open hardware but it's amazingly integrated ! &gt; For this little card like this one I think that RISC V will be better I wouldn't say that RISC V would be better. RISC V would be an alternative but as of today, RISC V are still at prototyping stage (except some integrated chips like the ones of SiFive: <https://www.sifive.com/products/freedom-e310/>) and they don't offer this level of integration (Bluetooth, UART, DAC, SPI, I2C, RTC, crypto engine,...): <http://oshchip.org/products/OSHChip_V1.0_Product.html> &gt; I wonder how is it possible to run an OS on this card, 32 KB of SRAM is few  Don't read rin an OS as run Linux, BSD, Windows,... but run an *embedded* OS. There are plenty of real-time OS which perfectly fit it so little memory even less. See all "Internet of Things" operating systems - FreeRTOS: <http://www.freertos.org>  - Contiki: <http://www.contiki-os.org> &gt; Memory footprint: "A typical system with full IPv6 networking with sleepy routers and RPL routing needs less than 10 k RAM and 30 k ROM." - RiotOS: <https://www.riot-os.org/> &gt; Features: min RAM ~1.5KB, min ROM ~5KB - Zephyr: <https://www.zephyrproject.org/> "The Zephyr kernel and software subsystems can run on systems as small as 8 kB of memory all the way up to 512 kB." These are only the most famous ones which come to my mind but there are plenty of them. open source, proprietary, dual-licensed,...  &gt; Moreover it is SRAM so used as (L1, L2 or L3) cache in general. These microcontrollers don't have caches. They just have ROM/Flash memory (non volatile for storing executable code and persistent data) and RAM as volatile memory. ALL microcontrollers have some RAM/SRAM so this is not an exception here.
* _2017-04-11 09:56:25_> @U0AAL4W13: Freertos on it would be amazing !
* _2017-04-11 10:03:10_> @U38HVMZ6K: FreeRTOS is a nice OS but I really hate their coding style :mask: (<http://www.freertos.org/FreeRTOS-Coding-Standard-and-Style-Guide.html>)
* _2017-04-11 10:04:42_> @U38HVMZ6K: puting ul, us, x, x, p ... prefix in all variables and functions names is not to my taste
* _2017-04-11 10:05:06_> @U38HVMZ6K: &gt; for example a pointer to a uint16_t will have prefix pus.
* _2017-04-11 10:05:25_> @U38HVMZ6K: otherwise very nice and supported OS indeed
* _2017-04-11 10:05:46_> @U38HVMZ6K: I'll get a OSChip and will try to run Freertos on it
* _2017-04-11 10:08:28_> @U38HVMZ6K: it shouldn't be so difficult since the MCU seems to be supported: <https://devzone.nordicsemi.com/question/2197/freertos/> it's then a matter of integrating additional peripherals if any...
* _2017-04-11 10:09:25_> @U3GHS132Q: <@U38HVMZ6K> RISC-V is the future :slightly_smiling_face: and Nvidia is protytping a RISC-V core <https://riscv.org/wp-content/uploads/2016/07/Tue1100_Nvidia_RISCV_Story_V2.pdf>
* _2017-04-11 10:11:31_> @U0AAL4W13: <@U38HVMZ6K> if you do this I'd be keen on trying as well :p (reactions: @U38HVMZ6K)
* _2017-04-11 10:12:42_> @U38HVMZ6K: &gt; RISC-V is the future :slightly_smiling_face: and Nvidia is protytping a RISC-V core Trust me that if NVIDIA is developing a RISC-V core it won't be open source, open hardware and won't be documented at all unless you buy them millions of chips!
* _2017-04-11 10:13:19_> @U38HVMZ6K: NVIDIA has always be known to violate open licenses and not release source code, design documentation,...
* _2017-04-11 10:13:44_> @U3GHS132Q: For sure Nvidia will not release their sources, but if big companies are interested in RISC-V it shows that this project has a future :slightly_smiling_face:
* _2017-04-11 10:14:44_> @U38HVMZ6K: And I'm in a good position to confirm it, I'm working with NVIDIA CPUs on a daily basis (Nvidia Tegra3 ARM Cortex-A9) and it really sucks! No up to date software, no documentation, ...
* _2017-04-11 10:15:44_> @U3GHS132Q: <https://www.youtube.com/watch?v=iYWzMvlj2RQ>
* _2017-04-11 10:15:52_> @U38HVMZ6K: &gt; big companies are interested in RISC-V They are interested in the technology but not in the open source/open hardware concepts behind it.
* _2017-04-11 10:17:26_> @U38HVMZ6K: Yes, I know this famous Linus intervention, back in 2012... But 5 years later nothing has changed or only a bit to stay politically correct
* _2017-04-11 10:19:20_> @U3GHS132Q: If RISC-V pierces there will be open source implementation and IP core it is a certainty :slightly_smiling_face:
* _2017-04-11 10:24:29_> @U3GHS132Q: There are already open RISC-V IP : <https://github.com/sifive/freedom>
* _2017-04-11 11:14:12_> @U38HVMZ6K: Yes mentionned in my post above (<https://www.sifive.com/products/freedom-e310/>)  But what does it really bring to you ? You can implement a RISC-V in a huge power-hungry FPGA but to miniaturize, integrate and develop an ASIC you need amazing resources. Do you think you will be able to integrate these open source implementations and IP cores in a nanometer-scale silicium process in your garage ? At some point you will have to rely on the big companies you dislike so much. Even to produce semiconductors devices with technology of 40 years ago (10um lithography) you need expensive equipment. And today's semiconductors fabs are not focussed and interested in these technologies and target nanometers processes which are even more expensive. Semiconductors manufacturing is a huge and complex domain where only few big actors can play (TSMC, Samsung, Intel at the top and others challengers TI, NXP, ST).
* _2017-04-11 12:04:04_> @U37GZRZU6: BTW, I created an "embSys" team on the github : <https://github.com/orgs/echopen/teams/embsys> embSys has no team maintainer yet (who will be in charge of maintaining the embSys repo) --&gt; you might proclaim one :wink: I propose <@U3GHS132Q> :grinning: :+1:
* _2017-04-11 12:49:45_> @U3GHS132Q: <@U38HVMZ6K> Sorry I did not see that you already share the link. Some research labs can make nanometer-scale core. If open hardware democratizes maybe founders will change their business and propose to found core for particulars.
* _2017-04-11 13:00:28_> @U3GHS132Q: <@U37GZRZU6> I do not think that I have sufficient knowledge for this task :s (reactions: @U0AAL4W13,@U37GZRZU6)
* _2017-04-11 14:11:17_> @U37GZRZU6: so? who? there has to be one :smiley:
* _2017-04-11 14:11:49_> @U38HVMZ6K: I volunteer (reactions: @U37GZRZU6,@U37GZRZU6,@U0AAL4W13,@U3QGT3Q74,@U04DFTZ7D)
* _2017-04-11 14:12:50_> @U38HVMZ6K: but put <@U3GHS132Q> as a co-maintainer with enough rights so that he can take over the relay if/when I'm too busy. (reactions: @U37GZRZU6,@U3GHS132Q,@U0AAL4W13)
* _2017-04-11 14:14:34_> @U37GZRZU6: seems legit :wink: thanks <@U38HVMZ6K> ! (and thanks <@U3GHS132Q> for your unintentional participation :smile: )
* _2017-04-11 14:16:22_> @U3GHS132Q: <@U37GZRZU6> Do no think that becoming comaintainer of embsys team I will become your minion lol (reactions: @U37GZRZU6)
* _2017-04-11 14:19:17_> @U3GHS132Q: As a comaintainer of this team the first thing I will do is to change the license of the repo !
* _2017-04-11 14:39:42_> @U38HVMZ6K: to which license ? eiffel-PL ? (reactions: @U0AAL4W13,@U37GZRZU6)
* _2017-04-11 14:40:25_> @U38HVMZ6K: as I already mentioned some time ago, I think it will be difficult to put a license on the whole embsys repository (reactions: @U3GHS132Q)
* _2017-04-11 14:41:09_> @U38HVMZ6K: It will most probably be a bunch of different open source components integrated together to form an embedded system software/distribution
* _2017-04-11 14:41:43_> @U38HVMZ6K: and since all open source components already have their own license we won't be able to put a "global" license on top of it
* _2017-04-11 14:49:07_> @U38HVMZ6K: the majority of systems I worked on had their license reporting or license compliance tool to ensure that the system as a whole is compliant and does not violate any license
* _2017-04-11 14:49:48_> @U38HVMZ6K: e.g. on yocto project: <http://www.yoctoproject.org/docs/1.6.1/dev-manual/dev-manual.html#maintaining-open-source-license-compliance-during-your-products-lifecycle>
* _2017-04-11 14:51:24_> @U38HVMZ6K: or with Buildroot: `make legal-info` <https://buildroot.org/downloads/manual/manual.html#legal-info>
* _2017-04-11 14:52:36_> @U38HVMZ6K: There is also a trend going towards SPDX (<https://spdx.org/>) &gt; Software Package Data Exchange® (SPDX®) specification is a standard format for communicating the components, licenses and copyrights associated with software packages.
* _2017-04-11 17:11:06_> @U3GHS132Q: <@U38HVMZ6K> GPL will do the job ! I agree with you, it will be complicated to put the global repo under a license.
* _2017-04-12 10:57:10_> @U3GHS132Q: Hey <#C3F765DT7> do not forget the meeting "système en bar gay" tonight !
* _2017-04-12 11:01:06_> @U3J40RUDT: I'll be on my way to my parents' place for easter but i'll try to connect at around 20h on the go.  I'll just mute myself so there's not too much background noise but I should be able to follow the meeting 
* _2017-04-12 11:02:29_> @U3GHS132Q: <@U3J40RUDT> No problem :slightly_smiling_face:
* _2017-04-12 11:10:34_> @U0AAL4W13: <@U3GHS132Q> got it !
* _2017-04-12 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for the embysy weekly meeting.
* _2017-04-12 12:14:15_> @U0AAL4W13: <@U3GHS132Q> master I'll try and get a Jabra omni spider/speaker
* _2017-04-12 12:17:30_> @U0AAL4W13: Do you think you'll have the drivers for it? ;)
* _2017-04-12 12:28:20_> @U3GHS132Q: <@U0AAL4W13> Do not call me master lol I am not a dictator ! I do not know for the speaker :s Can you pm me the reference so I search on the web
* _2017-04-12 12:32:15_> @U38HVMZ6K: &gt; Do you think you'll have the drivers for it? ;) Only if open source GPL drivers exist :stuck_out_tongue:  (reactions: @U37GZRZU6)
* _2017-04-12 12:33:14_> @U3GHS132Q: <@U38HVMZ6K> Sure lol I will never installed proprietary drivers lol
* _2017-04-12 12:33:30_> @U3GHS132Q: They will taint the beautiful Linux kernel lol
* _2017-04-12 12:40:05_> @U38HVMZ6K: &gt; <@U38HVMZ6K> Sure lol I will never installed proprietary drivers lol Then you can stop doing GPU work with CUDA right now...
* _2017-04-12 12:41:50_> @U3GHS132Q: Never used CUDA and I only use the nouveau driver
* _2017-04-12 12:49:05_> @U3GHS132Q: Moreover you can use OpenCL to do GPGPU. And GPGPU suffers from the data transfer between main memory and GPU memory.
* _2017-04-12 19:36:16_> @U4J138ZTL: Here some first results on my recent works on fpga development ! I'm still working on the documentation of what i'm doing but i could wait more :slightly_smiling_face:  <https://github.com/Halipster/for_echOpen/blob/master/rapport/FPGA.ipynb> (reactions: @U04DFTZ7D,@U0AAL4W13)
* _2017-04-12 20:06:33_> @U3GHS132Q: Where are you Power Rangers ?
* _2017-04-12 20:06:42_> @U3GHS132Q: Euh members of <#C3F765DT7> ?
* _2017-04-12 20:07:11_> @U4YCKBDR8: <@U4YCKBDR8> has joined the channel
* _2017-04-12 20:23:23_> @U3J40RUDT: Nobody here ? (Im still on the train but i joined anyway) 
