* _2016-06-13 10:15:48_> @U04DFTZ7D: <@U04DFTZ7D> has joined the channel
* _2016-06-13 10:16:02_> @U0B47KC3S: <@U0B47KC3S> has joined the channel
* _2016-06-13 10:16:02_> @U1G9AEN7L: <@U1G9AEN7L> has joined the channel
* _2016-06-13 10:30:57_> @U1G9AEN7L: la carte utilisé c'est une Arduino ?
* _2016-06-13 10:31:53_> @U04DFTZ7D: Non, une Red Pitaya pour le moment
* _2016-06-13 10:32:40_> @U07UEJC2H: <@U07UEJC2H> has joined the channel
* _2016-06-20 11:53:52_> @U1JCFS7N3: <@U1JCFS7N3> has joined the channel
* _2016-07-05 17:07:44_> @U0AAL4W13: <@U0AAL4W13> has joined the channel
* _2016-07-06 19:31:38_> @U1PAGSKGU: <@U1PAGSKGU> has joined the channel
* _2016-07-06 19:31:49_> @U0B47KC3S: <@U0B47KC3S> and commented: these are the key metrics for image denoising
* _2016-07-06 19:39:27_> @U1P9ARRU3: <@U1P9ARRU3> has joined the channel
* _2016-07-07 11:28:18_> @U0B47KC3S: hello à tous, voici le lien vers le dossier gDrive, où je vous propose d'ajouter les docs de revue de littérature
* _2016-07-07 11:28:40_> @U0B47KC3S: <@U0B47KC3S>
* _2016-07-07 11:30:20_> @U0B47KC3S: j'ai donc récupéré deux des articles dont nous discutions hier. Je reste à la recherche de celui-ci "Comparative evaluation of despeckle filtering in ultrasound imaging of the carotid artery, IEEE Trans. Ultrason. Feroelctr. Freq."
* _2016-07-07 11:30:41_> @U0B47KC3S: le doc. "Quality evaluation...." semble détailler les métriques que nous cherchons
* _2016-07-07 16:49:17_> @U1PKXQVDW: <@U1PKXQVDW> has joined the channel
* _2016-07-08 10:05:16_> @U0B47KC3S: <@U1P9ARRU3>: je remarque ce jour que si tu télécharges l’app desktop de slack, tu peu gérer tous tes comptes slack dans la même interface :wink:
* _2016-07-13 09:32:15_> @U0B47KC3S: hello à tous, <@U1PAGSKGU> je suis navré d’apprendre que tu t’es blessé. J’espère rien de trop grave.
* _2016-07-13 09:33:16_> @U0B47KC3S: btw, <@U1P9ARRU3> as-tu pu avancer sur le script ?
* _2016-07-13 09:41:48_> @U0B47KC3S: du coup, si ce n’est pas le cas, on peut soit remettre à la semaine pro ou alors <@U1PKXQVDW>  tu peux nous raconter ce que tu as fait en débruitage et ce dont on peut s'inspirer, si tu penses cela pertinent ;!
* _2016-07-13 09:46:31_> @U1PAGSKGU: salut, pas grave, genou enfle. Ca demande quelque jour de repos.
* _2016-07-13 10:10:17_> @U1P9ARRU3: cc !! j'ai avancer un peu mais jen'ai pas encore récupérer toutes les metrics attendu
* _2016-07-13 14:11:59_> @U1P9ARRU3: Je penses que l'on devrait se voir la semaine pro
* _2016-07-13 17:04:34_> @U0B47KC3S: et bien reposez-vous bien et on se dit à la semaine prochaine, <@U1PKXQVDW> j’imagine que toi aussi tu es Ok ?
* _2016-07-17 22:14:47_> @U0B47KC3S: ca va vous intéresser ;)1 cours sur l’image processing , ca commence en septembre <https://www.coursera.org/learn/image-processing> (reactions: @U1P9ARRU3)
* _2016-07-20 19:21:13_> @U1P9ARRU3: <http://xmcvs.free.fr/astroart/Chapitre4.pdf>
* _2016-07-22 14:50:02_> @U0B47KC3S: hello à tous, je me suis mis en relation avec Loizou et Pattichis pour leur demander de partager ceci <http://www.morganclaypool.com/doi/abs/10.2200/S00116ED1V01Y200805ASE001>. Je vous tiens au courant, pour la suite
* _2016-07-22 20:28:32_> @U0B47KC3S: set up a reminder “un message automatique pour nous rappeler la réunion du mercredi” in this channel at 12:18pm every Monday, Central European Summer Time. (reactions: @U04DFTZ7D)
* _2016-07-22 20:29:05_> @U0B47KC3S: set up a reminder “un message automatique pour nous rappeler la réunion du mercredi” in this channel at 12:18pm every Monday, Central European Summer Time.
* _2016-07-22 20:29:45_> @U0B47KC3S: set up a reminder “"un message automatique pour nous rappeler la réunion du mercredi" at 18:00h eve” in this channel at 9am every Monday, Central European Summer Time.
* _2016-07-22 20:30:11_> @U0B47KC3S: set up a reminder “un message automatique pour nous rappeler la réunion du mercredi” in this channel at 6pm every Monday, Central European Summer Time.
* _2016-07-25 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-07-27 11:56:20_> @U0B47KC3S: hello à tous, je suis absolument confus mais contrairement à ce que je prévoyais, je ne peux être à Paris ce jour. Bien entendu, vous pouvez vous rencontrer ou alors nous décalons à la fin de semaine ou à mercredi en 8. Bien à vous, Mehdi
* _2016-07-27 13:56:24_> @U1P9ARRU3: Ok, je crois qu'on se reverra mercredi alors
* _2016-07-27 13:56:32_> @U1P9ARRU3: bonne journée
* _2016-07-27 15:58:03_> @U0B47KC3S: parfait @mercredi alors !
* _2016-08-01 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-08-03 18:45:17_> @U0B47KC3S: <@U1PAGSKGU> : pour l'update du README du dossier `signal_processing`, voici la liste des packages installés -&gt; packages installés   libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev libv4l-dev  installation archi i386   opencv installé, version 3.0.0   scipy
* _2016-08-04 00:10:09_> @U0B47KC3S: <@U1PAGSKGU>: ayé, g réussi à faire un sparse checkout, je vais updater la doc :wink:
* _2016-08-04 00:34:06_> @U0B47KC3S: <@U1PAGSKGU>: si tu peux relire mon pull request et l’accepter le cas échéant, c top !
* _2016-08-08 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-08-11 16:10:51_> @U20C8CKTL: <@U20C8CKTL> has joined the channel
* _2016-08-11 16:12:20_> @U0B47KC3S: hello à tous, un mot pour vous présenter Loic. Loic est développeur python et nous rejoint notamment autour de l’écriture de script de validation des soumissions + update du leaderboadr. Welcome :wink: !
* _2016-08-11 16:13:28_> @U0B47KC3S: <@U20C8CKTL>: pour info, il n’ets pas impossible que je double parfois les infos sur une boucle mail car certains d’entre nous n’utilisent pas slack. Néanmoins c ici qu’on va basculer l’essentiel de la circulation de l’information (reactions: @U04DFTZ7D)
* _2016-08-12 18:59:07_> @U0AAL4W13: pour ceux que ca pourrait amuser, petit dump de data brutes de 32M d'une loop echo sortie d'une sonde ATL3 <https://github.com/kelu124/echomods/blob/7550201f092bcc825ad175e80f880b3f18b0f153/toadkiller/data/sonde3Vnobitscpe.bin.bz2> - avec pour défi d'en sortir une image / loop ^^ (ok, j'avoue, ca fait beaucoup)
* _2016-08-13 16:17:56_> @U0B47KC3S: ok on a pas encoire fini le set-up mais on regardera ça asap
* _2016-08-15 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-08-17 22:18:45_> @U0B47KC3S: hello <@U1PAGSKGU> <@U1P9ARRU3> <@U1PKXQVDW>, hackolite  vient de soumettre un pull request : c la routine qui permet de valider une soumission, de comparer input et output. La mécanique est en place, il ne reste plus qu’à ajouter les scripts de Soobash. <@U1PAGSKGU> on review le code qd tu veux
* _2016-08-17 22:35:34_> @U20C8CKTL: hi
* _2016-08-17 22:35:46_> @U20C8CKTL: francais
* _2016-08-17 22:36:14_> @U20C8CKTL: j'ai une question, pour les tests de perfs vous avez des préférences pour un choix de vm android ?
* _2016-08-17 22:36:36_> @U20C8CKTL: <@U0B47KC3S>
* _2016-08-18 09:23:32_> @U0B47KC3S: <@U20C8CKTL>: je ne suis pas sûr de comprendre la question. A priori il s’agit de la VM dalvik pour android, on n’a pas vraiment le choix non ?
* _2016-08-18 09:41:00_> @U0B47KC3S: btw si les algo agissent localement sur l’image, on peut envisager l’usage de GPU :wink:
* _2016-08-18 09:49:18_> @U20C8CKTL: Jai vu sur le wiki qu il y avait une evalutiob des  perfs de lalgo en consommation memoire cpu etc. Pour etre dans les conditions de fonctionnement de lalgo je voulais savoir si vous aviez un systeme d emulation android phone.
* _2016-08-18 10:17:35_> @U0B47KC3S: je pense que le plus simple est d’installer AndroidStudio et de lancer l’émulateur depuis là. Sinon, j’ai vu des tuto pour installer dalvik dans virtualbox sur linux ou sur Windows, tu peux checker ce post de SO : <http://stackoverflow.com/questions/7622157/android-is-it-possible-to-run-dalvik-vm-on-any-kind-of-oss-in-order-to-run-andr>
* _2016-08-18 11:50:11_> @U20C8CKTL: Yes j invedtigue thanx
* _2016-08-18 12:13:31_> @U20C8CKTL: Plus maintenu apparement
* _2016-08-18 12:13:36_> @U20C8CKTL: Dalkit...
* _2016-08-18 12:13:43_> @U20C8CKTL: Dalvik pardon
* _2016-08-18 15:04:46_> @U0B47KC3S: en fait qd tu utilises android studio, tu crées des virtual machine, dont la legacy des versions antérieures. Du coup, dalvik est un peu partout, sinon Google a en effet remplacé dalvik par android runtime
* _2016-08-18 16:33:51_> @U0B47KC3S: [Point Documentation] nous sommes en train de structurer l’ensemble de la documentation d’echOpen sous la forme de GitBook. Voici deux examples : le premier sur l’espace echOpen et le second sur l’app android (en cours d’écriture). L’avantage est que la doc devient éditable, collaborative et surtout plus aisée à structurer qu’un wiki. Je vais donc vous faire une proposition d’architecture qui sera notre base commune de collaboration
* _2016-08-18 16:33:53_> @U0B47KC3S: <https://echopen.gitbooks.io/echtopian/content/>
* _2016-08-18 16:34:00_> @U0B47KC3S: <https://echopen.gitbooks.io/android-app/content/>
* _2016-08-18 16:35:19_> @U0B47KC3S: une précision : ces documents sont automatiquement synchronisé sur GitHub :wink:
* _2016-08-19 12:40:28_> @U0B47KC3S: hello à tous, voici donc notre GitBook avec la doc updatée <https://benchoufi.gitbooks.io/image-processing/content/>
* _2016-08-19 12:40:34_> @U0B47KC3S: <@U20C8CKTL> dans la section `How to contribute`, je te laisse compléter ce qui mérite de l’être
* _2016-08-19 12:40:36_> @U0B47KC3S: <@U1PKXQVDW> peux-tu dans la partie KPIs faire une rapide synthèse du mini-cours que tu nous a fait la fois dernière :wink:
* _2016-08-19 12:45:34_> @U0B47KC3S: [MAJ] conversion de l’url du gitbook -&gt; <https://echopen.gitbooks.io/image-processing/content/>
* _2016-08-19 14:00:54_> @U20C8CKTL: oki !
* _2016-08-19 14:03:02_> @U20C8CKTL: <@U0B47KC3S> par scan_converted tu entends le .csv ou .bitmap?
* _2016-08-19 14:03:19_> @U20C8CKTL: .png ou watever
* _2016-08-19 14:12:00_> @U0B47KC3S: le .csv en fait :wink:
* _2016-08-19 14:13:54_> @U0AAL4W13: Avant la scan conversion aussi, histoire que l'algorithme de scan conversion ne joue pas?
* _2016-08-19 15:14:54_> @U0B47KC3S: yo c ce que <@U1PAGSKGU> a prévu pour ses scripts-&gt;le fichier de base data/data_kydney.csv, non scan converté
* _2016-08-19 15:15:53_> @U0AAL4W13: Top
* _2016-08-19 16:33:00_> @U20C8CKTL: question : est ce qu'un system de ticketing ne pourrait pas etre intéressant ?
* _2016-08-19 16:33:05_> @U20C8CKTL: comme track ?
* _2016-08-19 16:33:49_> @U20C8CKTL: ou jira ?
* _2016-08-19 20:46:03_> @U0B47KC3S: je crains que cela soit un peu oversize pour le moment mais tu penses à quel usage utile d’ores et déjà ?
* _2016-08-19 22:46:47_> @U20C8CKTL: Alors par exemple dans github tu as les issues.  Mais ca fonctionne  pareil  pour les enhancements. Pour kitsoft quelqun voit un soucis ouvre un ticket et la personne qui veut s en charger prend le ticket. Il crée sa pull request et si c validé on clos le ticket.
* _2016-08-19 22:48:25_> @U20C8CKTL: Pour les enhancements cest pareils. Ce qui est bien cest quon peut faire des tickets ouverts au public de facon a orienter les devs qui veulent aider le projet. Comme vous avez commencé a faire.
* _2016-08-19 22:49:10_> @U20C8CKTL: Les devs ou electronicien ou autre pour la doc.
* _2016-08-20 02:47:26_> @U0B47KC3S: ok je comprends. Du coup, une suggestion, exploiter à fond github. Ce qu’on pourrait faire c utiliser extensivement les labels (et aussi les milestones qui seraient intéressants d’implémenter dans notre cas). Car, non seulement on garde une homogénéité, on laisse des archives accessibles par les moteurs de recherches, on peut y cross-référencer des commits, mais surtout le point qui me paraît capitale c que les personnes qui “watch” le projet sont notifiées. De plus et de façon plus anecdotique, github est intégré à gmail désormais, si bien que si on a un label genre “task” ou “feature request”, ce qui ont un compte gmail reçoivent un joli email estampillé “task” ou “feature request”.   Qu’en penses-tu ?
* _2016-08-20 09:16:07_> @U20C8CKTL: Yes ca peut etre une idee
* _2016-08-20 09:17:20_> @U20C8CKTL: Cest un debut
* _2016-08-22 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-08-22 21:08:11_> @U0B47KC3S: <@U20C8CKTL> suis en train de tester le site que tu m’indiquais <http://zube.io>. Ca m’a l’air particulièrement adapté et la synchro label/milestones est bi-directionnelle. C exactement ce qu’il nous faut thks :grinning:
* _2016-08-23 08:48:25_> @U0B47KC3S: <@U20C8CKTL> dans le même esprit et complétement intégré à github, <@U04DFTZ7D> m’a indiqué ceci <http://zenhub.io>. Tu connais ?
* _2016-08-23 13:29:54_> @U20C8CKTL: <@U0B47KC3S>:  a non je ne connaissais pas. Le concept est le meme a premiere vu. Il y a waffle aussi. 
* _2016-08-23 14:51:30_> @U0B47KC3S: oui en revanche il n’y pas de système de tickets mais tant qu’on n’est pas en prod, ca ne doit pas poser de problème ?
* _2016-08-23 15:14:43_> @U20C8CKTL: Les tickets ca peut servir pour les enhancements. Car tu peux attribuer une amélioration a quelqu un ou mieux. Tu crees tout plein de tickets et si ils  ne sont pas dependants les un des autres les gens qui veulznt contribuer prennent ce quil veulent.
* _2016-08-23 15:15:14_> @U20C8CKTL: Et si la merge request passe. Tu clos.
* _2016-08-23 16:59:30_> @U0B47KC3S: ok, suis OK pour tester anyway. Donc soit tu penses qu’à ce stade on a besoin des features complètes de <http://zube.io>, alors on y va !  :wink:
* _2016-08-23 17:01:15_> @U20C8CKTL: Oui je pense que c est une plus value. Je te tiens au courant de mob avancée.
* _2016-08-23 23:52:39_> @U0B47KC3S: top
* _2016-08-24 09:20:48_> @U0B47KC3S: ce qui suis est juste un test de l’app polly
* _2016-08-24 09:21:13_> @U24BZF8UR: <@U24BZF8UR> has joined the channel
* _2016-08-24 09:21:30_> @U24BZF8UR: <@U0B47KC3S> used `/poll`! Vote using the buttons below. View results <https://app.polly.ai/slackvote/tvexwFKLoT6m4zLPs>
* _2016-08-24 09:21:34_> @U0B47KC3S: sympa :wink:
* _2016-08-24 09:39:32_> @U0B47KC3S: c juste pour le fun
* _2016-08-24 10:39:59_> @U20C8CKTL: slt, je suis en train de regarder zenhub et ça marche vraiment comme zube,  avec les issus tu peut faire comme tu veux
* _2016-08-24 10:41:21_> @U20C8CKTL: attribuer a plusieurs personnes. c'est équivalent a zube j'ai l'impression
* _2016-08-24 11:04:08_> @U0B47KC3S: dis-moi c toi qui nous dit :wink:
* _2016-08-24 11:37:22_> @U20C8CKTL: il semble qu'il soit impossbile de modifier le contenue de la page
* _2016-08-24 11:37:30_> @U20C8CKTL: gitbook echopen
* _2016-08-24 11:37:46_> @U20C8CKTL: image processing /ow to contribute
* _2016-08-24 11:38:58_> @U20C8CKTL: <https://echopen.gitbooks.io/image-processing/content/how_to_contribute.html>
* _2016-08-24 12:52:30_> @U0B47KC3S: en effet, je viens de t’ajouter ainsi que toute la boucle parmi les auteurs du gitbook. Dis-moi si ça marche
* _2016-08-24 13:01:27_> @U20C8CKTL: toujours rien
* _2016-08-24 13:01:32_> @U20C8CKTL: j'ai read mais pa write
* _2016-08-24 13:02:05_> @U0B47KC3S: tu as reçu un mail ?
* _2016-08-24 13:02:48_> @U0B47KC3S: car je ne vois pas que tu as accepté l’invitation
* _2016-08-24 13:03:30_> @U20C8CKTL: non, pas demail
* _2016-08-24 13:14:10_> @U0B47KC3S: arg
* _2016-08-24 13:14:12_> @U0B47KC3S: wait
* _2016-08-24 13:19:00_> @U0B47KC3S: il est proposé d’entrer une adresse email sans + de précision. Je pense qu’il faut rentrer une adresse correspondant déjà à un username enregistré. Peux-tu t’enregistrer sur gitbook et me donner ton username plz
* _2016-08-24 13:34:40_> @U20C8CKTL: ok
* _2016-08-24 13:36:24_> @U20C8CKTL: normalement, c'est hackolite
* _2016-08-24 14:26:16_> @U0B47KC3S: en pcpe c envoyé
* _2016-08-24 14:49:28_> @U20C8CKTL: bon, je n'ai rien reçu.
* _2016-08-24 14:52:24_> @U0B47KC3S: ah là je te vois comme ayant accepté, on est dac ?
* _2016-08-24 14:52:43_> @U0B47KC3S: tu as les droits RW
* _2016-08-24 14:56:11_> @U20C8CKTL: oui, c'est bon
* _2016-08-24 14:56:19_> @U20C8CKTL: thx
* _2016-08-24 14:57:52_> @U0B47KC3S: :+1:
* _2016-08-24 14:58:09_> @U0B47KC3S: now tout le monde est invité
* _2016-08-25 12:17:37_> @U0B47KC3S: #Implémentation du LeaderBoard <@U20C8CKTL> on se met donc sur zenhub ou zube (je ne sais plus que ce qui te convient le mieux;)) ? je commence à créer des tickets ?
* _2016-08-25 13:56:40_> @U20C8CKTL: Va pour zenhub si olivier connais
* _2016-08-25 14:26:36_> @U0B47KC3S: je viens de t’inviter à zenhub - et j’ai crée un milestone
* _2016-08-25 14:31:56_> @U0B47KC3S: + une première todo
* _2016-08-25 14:38:03_> @U0B47KC3S: g créé 4 sous-tâches -  c à titre indicatif, tu peux éditer si tu le juges nécessaire
* _2016-08-25 16:36:56_> @U0B47KC3S: j’ajoute au canal <@U2404BG5N> qui est le master du serveur node installé à ce jour
* _2016-08-25 16:37:07_> @U2404BG5N: <@U2404BG5N> has joined the channel
* _2016-08-29 09:55:02_> @U0B47KC3S: création d’une bibliothèque familiale sur l’espace Google Books afin de partager l’ouvrage “Despeckle filtering for ultrasound imaging and video, Vol. I: Algorithms and software”. Testé avec Benjamin, vous tiens au courant du succès de l'opération
* _2016-08-29 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-09-05 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-09-07 09:51:09_> @U0B47KC3S: reminder -&gt; on se retrouve à 18H30 ce soir !
* _2016-09-12 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-09-14 23:23:37_> @U20C8CKTL: Github a annoncé des mises a jour  importantes notamment au niveau du management des issus. 
* _2016-09-15 00:44:35_> @U0B47KC3S: ah c bon ça, on est sur le qui-vive;)
* _2016-09-15 16:05:51_> @U0B47KC3S: bonjour à tous, pour simplifier l’accès à une bibliothèque partagée d’ouvrages qui ne sont pas accessibles depuis mes accès universitaires, j’ai crée une adresse gmail commune : login : <mailto:echopenshare@gmail.com>` et clicquer sur `my library` et vous trouverez l’ouvrage `Despeckle Filtering for Ultrasound Imaging and Video: Algorithms ..., Volume 1: Algorithms and Software, Second Edition Christos P. Loizou, Constantinos S. Pattichis - Apr 1, 2015 - 180 pages `
* _2016-09-15 16:05:54_> @U0B47KC3S: Bonne lecture !
* _2016-09-19 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-09-19 19:18:26_> @U20C8CKTL: #benchoufi PR envoyé. j'ai packagé le module imageprocessing.
* _2016-09-19 19:18:48_> @U20C8CKTL: <@U0B47KC3S>
* _2016-09-19 19:18:54_> @U20C8CKTL: oups
* _2016-09-19 19:19:48_> @U20C8CKTL: Il reste pas mal de boulot mais la verson actuel est utilisable.
* _2016-09-19 19:33:13_> @U20C8CKTL: pour l'évaluation des algos je suggère d'utiliser jenkins
* _2016-09-19 19:34:04_> @U20C8CKTL: jenkins fera passer les tests (je vais en écrire quelques uns pour le principe), et des tests de perfs sur l'algo.
* _2016-09-19 19:34:47_> @U20C8CKTL: je trouve l'algo de denoising par défaut très lent. :confused:
* _2016-09-20 13:41:16_> @U0B47KC3S: hello <@U20C8CKTL> j’ai fait le merge à la main du PR
* _2016-09-20 13:41:56_> @U20C8CKTL: oui, j'ai vérifié ça al'air de tourner. :smile:
* _2016-09-20 13:43:23_> @U0B47KC3S: pour ce qui est de l’intégration continue, pour l’app android j’utilise travisCI. c plus simple à utiliser non ? si je ne m’abuse, jenkins exige d’installer sur 1 serveur dédié. Ceci étant, si tu connais ça bien, on peut l’installer sur notre dédié. Qu’en penses-tu ?
* _2016-09-20 13:45:27_> @U20C8CKTL: je veux bien regarder travis, ça me permettra de découvrir
* _2016-09-20 13:51:58_> @U20C8CKTL: il faut un server pour jenkins oui
* _2016-09-21 09:14:28_> @U0B47KC3S: top, voici un peu de doc pour travis python : <https://docs.travis-ci.com/user/languages/python/>
* _2016-09-21 09:15:47_> @U0B47KC3S: l’idée est simple. tu ajoutes un fichier caché `.travis.yml`, qui tient lieu de fichier de config et les test sont lancés automatiquement. Btw, ce qui est pratique avec ce fichier, c qu’il supporte l’execution de script sur la VM distante, ce qui donne une grande flexibilité !
* _2016-09-26 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-10-03 11:08:13_> @U0B47KC3S: hello à tous, on se retrouve donc mercredi prochain avec à la clé un debrief de la semaine au MIT qui était #toptoptop :wink:
* _2016-10-03 11:08:51_> @U20C8CKTL: Slt. Mercredi qui vient ?
* _2016-10-03 11:09:25_> @U20C8CKTL: Ou le 12 ?
* _2016-10-03 15:02:50_> @U0B47KC3S: yes mercredi qui vient :wink:
* _2016-10-03 15:03:24_> @U0B47KC3S: Soobash sera là à 18H00 et Benjamin un peu plus tard
* _2016-10-03 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-10-05 10:07:25_> @U0GMX7QUB: <@U0GMX7QUB> has joined the channel
* _2016-10-10 12:37:57_> @U04DFTZ7D: <@U04DFTZ7D> has renamed the channel from "signal_processing" to "prj_medtec_sigproc"
* _2016-10-10 12:38:39_> @U04DFTZ7D: <@U04DFTZ7D> set the channel purpose: De-noising and signal processing
* _2016-10-10 17:31:46_> @U0B47KC3S: <@U20C8CKTL> : qd tu en sera au moment documentation, sache que nous la produisons en format GitBook, soit ici pour ce qui nous intéresse : <https://www.gitbook.com/book/echopen/image-processing/details>. Et, cf ici -&gt; <https://www.gitbook.com/@echopen> pour tous les gitbooks d'echOpen !
* _2016-10-10 17:33:00_> @U20C8CKTL: Yes. Je regarde ca.
* _2016-10-10 17:33:11_> @U20C8CKTL: Cette semaine
* _2016-10-10 17:38:59_> @U0B47KC3S: top !
* _2016-10-10 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-10-13 13:31:15_> @U20C8CKTL: Salut, pour le leaderboard, quel est votre préférence : afficher les 100 meilleurs valeurs, les 200 ?
* _2016-10-13 14:17:29_> @U04DFTZ7D: 100 c'est bien, non ? <@U0B47KC3S> ?
* _2016-10-13 15:35:30_> @U20C8CKTL: on peut changer ça facilement, ce que je vais faire pour le moment c'est afficher le score du code soumis et les 100 premiers
* _2016-10-14 15:48:38_> @U0B47KC3S: ok top pour les 100 premiers. Btw, on fera un peu de js pour faire un scroll dynamique
* _2016-10-14 15:51:55_> @U20C8CKTL: Ok. Il y a un module pip que jutilise pour automatiser l installation de package tiers de pipy
* _2016-10-14 15:54:05_> @U20C8CKTL: def install_packages():     pip.main(['install', 'aesop'])
* _2016-10-14 15:55:28_> @U20C8CKTL: donc on peut envisager un IDE.
* _2016-10-14 16:48:12_> @U2PFHNN3C: <@U2PFHNN3C> has joined the channel
* _2016-10-17 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-10-20 10:13:48_> @U0B47KC3S: hi all et je dirais même + hi <@U20C8CKTL>  : voici le lien qui t’emmènera vers le challenge kaggle que nous évoquions hier -&gt; <https://www.kaggle.com/c/ultrasound-nerve-segmentation> et vers la data de ce challenge <https://www.kaggle.com/c/ultrasound-nerve-segmentation/data>
* _2016-10-24 18:00:00_> @USLACKBOT: Reminder: un message automatique pour nous rappeler la réunion du mercredi.
* _2016-10-25 21:53:41_> @U0B47KC3S: set up a reminder “un memo pour la réunion du jeudi” in this channel at noon every Wednesday, Central European Summer Time.
* _2016-10-26 12:00:00_> @USLACKBOT: Reminder: un memo pour la réunion du jeudi.
* _2016-10-28 16:11:43_> @U20C8CKTL: salut, le code du leaderboard est sur mon repo github
* _2016-10-28 16:11:48_> @U20C8CKTL: <https://github.com/hackolite/kit-soft/tree/master/leaderboard>
* _2016-10-28 16:12:40_> @U20C8CKTL: Pour le moment je n'ai pas encore fait de pull-request le code étant encore en chantier
* _2016-10-28 16:13:37_> @U20C8CKTL: le nouveau metrics.py ne fonctionne pas chez moi
* _2016-10-28 17:04:56_> @U0B47KC3S: top <@U20C8CKTL>, btw qd on a du temps, c bien de pouvoir updater la doc sur le gitbook ! <https://echopen.gitbooks.io/image-processing/content/>
* _2016-10-28 17:05:06_> @U0B47KC3S: j’envoie un mail dans ce sens à la team;à
* _2016-10-28 17:05:08_> @U0B47KC3S: :wink:
* _2016-10-28 17:12:52_> @U20C8CKTL: A oui ! Je vais mettre a jour. Noté.
* _2016-10-29 10:46:37_> @U0B47KC3S: top !
* _2016-11-02 12:00:00_> @USLACKBOT: Reminder: un memo pour la réunion du jeudi.
* _2016-11-02 17:37:59_> @U04DFTZ7D: <!channel> interesting seminar tomorrow at IHP (2.00 pm room 314 with Stéphane Mallat &amp; Emilie Chouzenoux.) : Unsupervised Learning and Inverse Problems with Deep Neural Networks...  If anyone is available to go and send the others a note, that would be cool !!   <https://imaging-in-paris.github.io/next/>
* _2016-11-02 18:03:40_> @U0B47KC3S: :+1: thanks Oliv too bad de ne pas être à Paris !
* _2016-11-02 19:02:44_> @U0B47KC3S: Il y a plein de projets notamment 1 bioréacteur
* _2016-11-02 19:03:53_> @U0B47KC3S: special dédicace <@U20C8CKTL> :wink:
* _2016-11-02 20:30:03_> @U20C8CKTL: :smile:
* _2016-11-02 20:30:11_> @U20C8CKTL: des colaborations en perspective !
* _2016-11-02 20:31:36_> @U20C8CKTL: sinon voici le proto du leaderboard en ligne ! dites moi ce que vous en pensez, je l'ai fais un peu en mode microsocial pour permettre aux participant d'échanger plus facilement sur leur code. dites moi si je suis sur la bonne voie, si il manque des choses si il y en a trop, etc ...
* _2016-11-02 20:32:09_> @U20C8CKTL: par ici la demo du leaderboard du challenge echopen :  <http://37.187.117.106/>
* _2016-11-02 20:33:53_> @U20C8CKTL: le code a uploader est le suivant :
* _2016-11-02 20:34:13_> @U20C8CKTL: <@U20C8CKTL>
* _2016-11-02 20:36:51_> @U20C8CKTL: la partie IDE n'est pas encore fonctionnelle mais je bosse dessus, ce serait bien d'avoir une branch sur le repo echopen pour qu'on puisse bosser dessus enseemble.
* _2016-11-02 23:22:08_> @U0B47KC3S: merci <@U20C8CKTL> ! y a-t-il un username et un password ?
* _2016-11-02 23:23:09_> @U20C8CKTL: Inscrit toi
* _2016-11-02 23:24:59_> @U20C8CKTL: Tu as un lien tout en bas. Sign up
* _2016-11-02 23:34:14_> @U2PFHNN3C: Super job <@U20C8CKTL> :slightly_smiling_face:
* _2016-11-02 23:36:12_> @U20C8CKTL: Merci <@U2PFHNN3C> !
* _2016-11-03 00:04:43_> @U0B47KC3S: top job <@U20C8CKTL> !!
* _2016-11-03 00:07:55_> @U20C8CKTL: <@U0B47KC3S>  super. Je vous tiens au courant pour la suite au plus vite.
* _2016-11-03 00:09:00_> @U0B47KC3S: cc <@U04DFTZ7D> check
* _2016-11-05 18:19:04_> @U0AAL4W13: Trouvé un truc fun: <https://github.com/sigurdstorve/OpenBCSim> pour émuler des images.. or so it seems. (reactions: @U0B47KC3S)
* _2016-11-07 19:26:35_> @U0B47KC3S: <@U0B47KC3S> set the channel topic: dedicated to  signal processing, image denoising software tools
* _2016-11-08 17:32:38_> @U0B47KC3S: <@U1PAGSKGU> je suis en train de cleaner le repo `kit-soft`. peux-tu pusher tes scripts ? @++
* _2016-11-08 18:00:16_> @U20C8CKTL: Il faudrait fusionner Image Processing et EchoImageProcessing
* _2016-11-08 18:02:07_> @U0B47KC3S: yes exactement ce que g en tête;)
* _2016-11-09 01:21:34_> @U20C8CKTL: Plop ! Je viens de mettre en place les notifications pour les jobs soumis par les developpeurs avec des couleurs et un fik d actu des jobs soumis pour voir l activité zn temps réel. Vous pouvez  tester tout ça  par ici : <http://37.187.117.106/> (reactions: @U0B47KC3S)
* _2016-11-09 10:35:39_> @U2PFHNN3C: <@U20C8CKTL> ya moyen de reset le password? oups...
* _2016-11-09 11:40:40_> @U0B47KC3S: <@U20C8CKTL> peux-tu prévoir une PR -  je vais mettre notre dev UI sur le coup, de façon à intégrer notre charte de style
* _2016-11-09 12:00:00_> @USLACKBOT: Reminder: un memo pour la réunion du jeudi.
* _2016-11-09 15:35:12_> @U20C8CKTL: <@U0B47KC3S> Ok je tenvoie ca dans la soirée.
* _2016-11-09 15:37:20_> @U20C8CKTL: <@U2PFHNN3C>  la base de donnée est reseté il faut que tu recrées un compte.
* _2016-11-09 15:37:44_> @U2PFHNN3C: <@U20C8CKTL> thanks!
* _2016-11-09 18:48:10_> @U20C8CKTL: <@U0B47KC3S>  Pull request  envoyé.
* _2016-11-09 19:52:32_> @U0B47KC3S: @loic relecture effectuée, et PR accepté ! thkx
* _2016-11-10 14:10:20_> @U20C8CKTL: <@U1PKXQVDW>  <@U0B47KC3S>  j'ai une question :smile:. La métrique spécifique à l'échographie donnera un meilleur score pour une méthode de dénoise spécifique aux images échographiques par rapport  à un dénoise  par patch ?
* _2016-11-10 14:11:19_> @U20C8CKTL: je regarde le dénoise par patch et je n'ai pas du tout l'impressio que ça correspond aux images échographiques.
* _2016-11-10 19:51:19_> @U0B47KC3S: <@U1PKXQVDW> les appareils sont au nombre de 5 -&gt;  Cardio-Thoracique, Abdomino-Pelvien, Gynéco-Obsétrique, Ostéo-articulaire, Vasculaire (ex. de la carotide)
* _2016-11-10 19:53:49_> @U2PFHNN3C: <@U20C8CKTL> ramp.studio
* _2016-11-10 19:55:08_> @U2PFHNN3C: <@U20C8CKTL> <http://www.ramp.studio/>
* _2016-11-10 20:00:25_> @U2PFHNN3C: <@U20C8CKTL> libs: tensorflow + keras
* _2016-11-10 20:17:06_> @U2PFHNN3C: <@U1PKXQVDW> <https://github.com/echopen/kit-soft/tree/master/EchoImageProcessing>
* _2016-11-10 20:17:41_> @U20C8CKTL: <https://github.com/echopen/kit-soft/tree/master/echopen-leaderboard/bootcamp/leaderboard>
* _2016-11-10 20:43:33_> @U0B47KC3S: top merci <@U20C8CKTL>
* _2016-11-10 20:43:43_> @U0B47KC3S: btw, voici le CR de la réu <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo/edit#heading=h.xsjhfeqw1gz9>
* _2016-11-10 20:43:44_> @U0B47KC3S: <@U0B47KC3S>
* _2016-11-10 20:45:08_> @U0B47KC3S: questions pour la prochaine fois, pensons-nous qu’il faille sur github un repo dédi au sigproc ?
* _2016-11-10 21:29:48_> @U20C8CKTL: Je pense que si le code a coté bouge beaucoup oui ça sera plus simple a merger.
* _2016-11-10 21:30:14_> @U20C8CKTL: Plus simple pour la relecture.
* _2016-11-10 23:29:22_> @U0B47KC3S: en effet
* _2016-11-11 19:20:40_> @U0B47KC3S: <@U20C8CKTL> <@U1PKXQVDW> <@U2PFHNN3C> <@U1PAGSKGU>  since we begin to receive contributions from outdoor France, so I try to switch in english !
* _2016-11-11 19:20:48_> @U0B47KC3S: Btw, here's some news of the day.
* _2016-11-11 19:20:52_> @U0B47KC3S: we  received today 2 more requests to participate in echOpen
* _2016-11-11 19:20:57_> @U0B47KC3S: -&gt; 1 Togolese dev, python dev, that I will therefore plugge into our team
* _2016-11-11 19:21:02_> @U0B47KC3S: -&gt; 1 dev from Turkey, PhD student on ultra-sound and mobile devices;)  he has just developed the android drivers for the data transfer via usb !!
* _2016-11-11 19:22:41_> @U0B47KC3S: + 1 a core developer of ruby language is currently spending some time @ echopen/hôtel dieu. He loves the project and ready to contribute in hackathon format &amp; nicolas
* _2016-11-12 12:00:39_> @U0B47KC3S: <@U20C8CKTL> I'm back: I made an update on the Android app's gitbook. I updated the "Challenges" section. Last year, there was consensus to make visible a section "Challenges" in every GitBook. The idea is, alongside those who want to develop a full instance of echOpen, to engage contributors around what deserves to be done, but which is considered as  difficult. It is a rather stimulating approach, has the merit of being able to harmonize our format of contributions , without compromising the possibilities of free contributions which would not be within the scope of the challenges. So, it would be nice if we think about what we consider to be the "Image Processing" challenges. What do you think?
* _2016-11-12 20:40:41_> @U32FZ0QLX: <@U32FZ0QLX> has joined the channel
* _2016-11-13 19:02:26_> @U31UCUFPW: <@U31UCUFPW> has joined the channel
* _2016-11-13 19:02:26_> @U3210MXC5: <@U3210MXC5> has joined the channel
* _2016-11-14 12:20:57_> @U20C8CKTL: <@U0B47KC3S>  could you provide me on server for leaderboard testing ?
* _2016-11-14 12:22:25_> @U20C8CKTL: I will separate webserver with image processing server to avoid interference between processes.
* _2016-11-14 12:30:08_> @U0B47KC3S: sure, I send this !
* _2016-11-15 02:07:52_> @U1NTT0ZPH: <@U1NTT0ZPH> has joined the channel
* _2016-11-15 02:07:52_> @U1NM17NHF: <@U1NM17NHF> has joined the channel
* _2016-11-15 02:07:52_> @U1NLWV4BZ: <@U1NLWV4BZ> has joined the channel
* _2016-11-15 17:22:10_> @U0B47KC3S: as soon as Eklou kodjo, registers on slack, he will present himself. He is a python developer. <@U20C8CKTL> you have some friend !
* _2016-11-15 19:48:31_> @U20C8CKTL: Nice <@U0B47KC3S> :dizzy_face: 
* _2016-11-16 09:38:53_> @U32AR6TED: <@U32AR6TED> has joined the channel
* _2016-11-16 12:00:00_> @USLACKBOT: Reminder: un memo pour la réunion du jeudi.
* _2016-11-16 14:24:01_> @U20C8CKTL: hi everyboy, a new echopen-leaderboard is avalaible at <http://92.243.29.92:8000/>.
* _2016-11-16 14:25:39_> @U20C8CKTL: i split webserver and image processing on two diffrente VM to reduce time processing variabilty.
* _2016-11-16 14:28:00_> @U20C8CKTL: I use 'message passing'-rpc to connect 2 servers.
* _2016-11-16 14:29:59_> @U20C8CKTL: code example :
* _2016-11-16 14:31:05_> @U20C8CKTL: next two days i will provide you every implementation details on gitbook
* _2016-11-16 14:31:39_> @U20C8CKTL: <@U20C8CKTL>
* _2016-11-16 14:49:07_> @U0B47KC3S: great <@U20C8CKTL>, we re going to check
* _2016-11-16 15:17:57_> @U0B47KC3S: /monkeytest <http://92.243.29.92:8000>
* _2016-11-16 15:17:57_> @Hyacinthe: Got it! I'll let you know once I'm done testing :monkey_face:
* _2016-11-16 15:18:10_> @Hyacinthe: All done :see_no_evil::hear_no_evil::speak_no_evil: Check your results here: <https://monkeytest.it/test/6b7afcf6-112b-4474-95b1-6730f4cfd3d7>
* _2016-11-16 15:19:24_> @U0B47KC3S: <@U20C8CKTL> <@U2PFHNN3C> <@U1PKXQVDW> <@U1PAGSKGU>  the site passes well the MonkeyTest :zap::muscle:
* _2016-11-16 15:32:18_> @U20C8CKTL: :D
* _2016-11-16 15:33:11_> @U20C8CKTL: well done. I guess you can schedule tests
* _2016-11-16 15:55:46_> @U32UWGGN9: <@U32UWGGN9> has joined the channel
* _2016-11-16 15:56:46_> @U0B47KC3S: yes it is nice :wink:
* _2016-11-16 16:12:13_> @U34231VFH: <@U34231VFH> has joined the channel
* _2016-11-17 09:04:53_> @U32V2JWFJ: <@U32V2JWFJ> has joined the channel
* _2016-11-17 18:30:49_> @U20C8CKTL: I will be connected by skype for our meeting
* _2016-11-17 18:30:56_> @U20C8CKTL: If needed
* _2016-11-17 18:36:37_> @U0B47KC3S: ok on air in 10mn !
* _2016-11-17 18:44:23_> @U0B47KC3S: loic, can’t join you
* _2016-11-17 18:44:56_> @U0B47KC3S: btw djalel is reaching us on skype in a few minutes
* _2016-11-17 18:45:24_> @U20C8CKTL: Ok je mz connect
* _2016-11-17 19:10:07_> @U2PFHNN3C: joblib
* _2016-11-17 19:10:12_> @U2PFHNN3C: wrapper sur multiprocessing
* _2016-11-17 19:10:34_> @U2PFHNN3C: en python
* _2016-11-17 19:48:02_> @U0B47KC3S: <@U20C8CKTL>  tu es là ?
* _2016-11-17 19:50:24_> @U0B47KC3S: #booboo on t’a perdu
* _2016-11-17 19:56:28_> @U20C8CKTL: plus de batterie sur mon phone
* _2016-11-17 19:56:39_> @U20C8CKTL: j'ai siwtché sur mon windoxs
* _2016-11-17 19:57:59_> @U0B47KC3S: can’t reach you my dear fellow
* _2016-11-17 19:58:44_> @U0B47KC3S: ok now I can see you;)
* _2016-11-17 19:59:56_> @U20C8CKTL: :smile:
* _2016-11-17 20:00:25_> @U20C8CKTL: it could be cool to hav some kind of word clood
* _2016-11-17 20:02:45_> @U20C8CKTL: 'cloud'
* _2016-11-17 23:58:27_> @U0B47KC3S: hi guys, anyone interested by the weekly signal processing session, here’s the review :wink: <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo/edit#>
* _2016-11-17 23:58:28_> @U0B47KC3S: <@U0B47KC3S>
* _2016-11-18 14:02:12_> @U20C8CKTL: the leaderboard IDE is online you can test it here :  <http://echopen.org:8000>
* _2016-11-18 14:03:32_> @U20C8CKTL: a lot of stufs are missing but you can for instance compare  denoise with  opencv with skimage
* _2016-11-18 14:03:58_> @U20C8CKTL: <@U20C8CKTL>
* _2016-11-18 14:05:07_> @U20C8CKTL: <@U20C8CKTL>
* _2016-11-18 14:39:42_> @U0B47KC3S: great job hackolite :zap::zap::zap: Could you .htacess protect the website untill we  make it public ?
* _2016-11-18 15:26:18_> @U20C8CKTL: Oki
* _2016-11-18 22:23:13_> @U34N7NQNR: <@U34N7NQNR> has joined the channel
* _2016-11-19 09:37:19_> @U33817K25: <@U33817K25> has joined the channel
* _2016-11-21 18:49:28_> @U20C8CKTL: Hey. Question : 
* _2016-11-21 18:50:23_> @U20C8CKTL: Burgerquizz:could you tell me the minimal fps for an echographe ?
* _2016-11-21 18:51:27_> @U0AAL4W13: Ballpark guess: 10 is low, 15 acceptable?
* _2016-11-22 14:28:48_> @U0B47KC3S: <#C1G7T0PNX> : To inform you that the acquirium with a dived probe inside will be up and running at the beginning of next week [Can’ WAIT] !!:grinning:
* _2016-11-22 15:38:26_> @U0B47KC3S: <@U20C8CKTL> as you suggested, there is now a dev branch on the kit-soft repo. You can know collaborate in proper conditions cc <@U34N7NQNR> (reactions: @U34N7NQNR)
* _2016-11-22 16:25:09_> @U20C8CKTL: <@U34N7NQNR> a dev version is  available  on PR. try to install it and tell me if something goes wrong
* _2016-11-22 16:28:55_> @U34N7NQNR: cool <@U20C8CKTL> , where can I find the PR repository. I'll intall it this nite
* _2016-11-22 20:04:31_> @U0B47KC3S: <@U20C8CKTL> <@U34N7NQNR> PR merged !
* _2016-11-22 22:38:41_> @U20C8CKTL: <@U34N7NQNR> yu can now use <https://github.com/echopen/kit-soft/tree/dev>
* _2016-11-22 22:39:57_> @U20C8CKTL: echopen-leaderboard is the server side, DenoiseServer is the processing side
* _2016-11-23 12:00:00_> @USLACKBOT: Reminder: un memo pour la réunion du jeudi.
* _2016-11-23 17:50:29_> @U35LGETA4: <@U35LGETA4> has joined the channel
* _2016-11-24 21:42:58_> @U0B47KC3S: hi there, the report of today's Signal Processing session is there
* _2016-11-24 21:42:59_> @U0B47KC3S: <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo/edit#heading=h.9eq4h2sb5dhw>
* _2016-11-24 21:42:59_> @U0B47KC3S: <@U0B47KC3S>
* _2016-11-24 21:43:09_> @U0B47KC3S: for the hacker team <@U0AAL4W13> <@U0GMX7QUB> <@U20C8CKTL>
* _2016-11-24 21:43:29_> @U0B47KC3S: we need to acquire in a week long session ultrasound data with moving target in the aquarium, the several positions should be as precise as possible. You in ?
* _2016-11-24 21:45:31_> @U36QEPF51: <@U36QEPF51> has joined the channel
* _2016-11-24 22:08:23_> @U37GZRZU6: <@U37GZRZU6> has joined the channel
* _2016-11-24 23:35:57_> @U0AAL4W13: <@U0B47KC3S> can be there this Saturday afternoon, why not? What specs for the signal being acquired ?
* _2016-11-24 23:51:30_> @U0B47KC3S: cool :wink: won't be in Paris this week-end, and we want to acquire images, and there are no untypical constraints, at least from the image denoising point of view, on the specs. Besides, <@U07UEJC2H> is about to finish the redpitaya cleaning. <@U07UEJC2H> when do you think we will be able to put the probe in the acquarium ?
* _2016-11-25 09:39:50_> @U0AAL4W13: So you just need the scan converted images?
* _2016-11-25 10:00:13_> @U0B47KC3S: I am not sure I am very clear :wink: in fact we need a mini hardware system moving with precision a target inside the acquarium
* _2016-11-25 10:02:23_> @U0AAL4W13: Ahh the stuff <@U0GMX7QUB> was proposing some time ago, moving a point in the shooting range with floppy servos! You'd be able to cover a 50x50mm area relatively precisely 
* _2016-11-25 10:02:57_> @U0AAL4W13: What's the coverage you need in terms of area ? And accuracy for the position ?
* _2016-11-25 10:05:59_> @U0B47KC3S: great if it ws already imagined !!! the critical idea is to get several **angles** of presentation of the target
* _2016-11-25 10:07:13_> @U0AAL4W13: So not only a point
* _2016-11-25 10:07:27_> @U0AAL4W13: Cause a 0d item has no angle 
* _2016-11-25 10:07:48_> @U0AAL4W13: 3 parameters to be fed in the system: x,y,theta
* _2016-11-25 10:08:14_> @U07UEJC2H: <@U0B47KC3S>, first tests will be made today :slightly_smiling_face:
* _2016-11-25 10:20:10_> @U0B47KC3S: <@U07UEJC2H>
* _2016-11-25 10:20:12_> @U0B47KC3S: great !!
* _2016-11-25 10:20:37_> @U0B47KC3S: <@U0AAL4W13> : moving target should be a 3D object
* _2016-11-25 10:43:00_> @U0AAL4W13: @Benchoufi in this case you could imagine a funny thing: you could do a 3D scan of your object, radon-transform the raw data, and get a volume ultrasound of your item ^^
* _2016-11-25 10:56:27_> @U0B47KC3S: funny indeed :wink: but we get there a digital image of an object. But how to process ultrasound scanning, with the idea to train your ML stuff to understand the specific noise ?
* _2016-11-25 11:06:36_> @U0AAL4W13: Hum
* _2016-11-25 11:06:54_> @U0AAL4W13: First get "empty" images and you'll get some noise already 
* _2016-11-25 11:07:50_> @U0AAL4W13: Then have an image a "dot" (thin wire) to see the focal characteristics (and resolution) of the setup
* _2016-11-25 11:08:39_> @U0AAL4W13: Those two are relatively simple quick wins, with no need for a complex moving system (at first) and can provide feedback on the noise
* _2016-11-25 11:09:43_> @U0AAL4W13: It depends what noise also you want to study: at the amplified signal stage, or at the image stage, or after scan conversion stage ? I assume the noise won't be exactly the same at each stage :)
* _2016-11-25 11:14:32_> @U0AAL4W13: <@U2PFHNN3C> lemme know if I'm saying stupid stuff 
* _2016-11-25 11:15:02_> @U0AAL4W13:  getting those quick wins may still provide some info on basic noise 
* _2016-11-25 12:55:54_> @U2PFHNN3C: <@U0AAL4W13> that was also discussed yesterday (provided I got exactly what you mean)
* _2016-11-25 13:58:40_> @U37GZRZU6: <@U2PFHNN3C> yes + <@U0AAL4W13> proposes to study the whole detection system on top of the noise that was discussed yesterday (e.g. spatial resolution)
* _2016-11-25 13:58:49_> @U37GZRZU6: if I got it right :slightly_smiling_face:
* _2016-11-25 13:59:47_> @U37GZRZU6: <@U2PFHNN3C> what’s still not clear to me is : can we really use those « empty » images to train a ML model
* _2016-11-25 14:00:03_> @U0AAL4W13: Plus a focus on the specific noise characteristic from this setup - especially from empty images
* _2016-11-25 14:00:46_> @U0AAL4W13: For example a black image (from a camera) won't be black, you'll still see some noise
* _2016-11-25 14:00:53_> @U37GZRZU6: yep :slightly_smiling_face:
* _2016-11-25 14:01:15_> @U0AAL4W13: Confusing for me is the moving target: I don't see how movement generates noise 
* _2016-11-25 14:02:15_> @U37GZRZU6: the noise doesn’t come from the movement at all. The noise is the one from the acquisition system. But for the denoising model to be trained we need many different images actually
* _2016-11-25 14:02:37_> @U37GZRZU6: one way to get that is to move the target
* _2016-11-25 14:04:23_> @U0AAL4W13: Okay !
* _2016-11-25 14:29:46_> @U0GMX7QUB: One (or more) goldfish with a GPS tracker collar ?
* _2016-11-25 14:48:03_> @U0B47KC3S: <@U0GMX7QUB> :wink: funny. the pb is that the fixed focus distance interval can miss the moving fish, and moving too constantly is not the real exam conditions. unless we put a dead floating fish :wink:
* _2016-11-25 15:19:06_> @U0GMX7QUB: Some possible solutions: - two cd-rom mechanisms - an XY plotter kit: <http://www.lextronic.fr/P35072-table-plotter-xy---v20.html> - recycle mechanisms of old printers - two stepping motors winding a wire tensioned by a spring like a "Y".  We can also save time in the realization by using mechanical elements like: <http://www.lextronic.fr/R3931-makerbeam--openbeam.html> (reactions: @U0AAL4W13,@U32FZ0QLX)
* _2016-11-25 17:26:11_> @U2PFHNN3C: Guys, as a general remark, I think we should use python 3 rather than 2. By definition, it has a brighter future :slightly_smiling_face:
* _2016-11-25 17:27:35_> @U2PFHNN3C: and if it’s really painful to some, at least, we ca write some code that is compatible with both versions
* _2016-11-25 17:27:52_> @U2PFHNN3C: Simply _never_ using the print statement (i.e without parenthesis)
* _2016-11-25 17:28:35_> @U2PFHNN3C: and, better, comply with these guidelines <http://python-future.org/compatible_idioms.html> (reactions: @U37GZRZU6)
* _2016-11-25 17:28:46_> @U2PFHNN3C: (using the `six` library etc.)
* _2016-11-25 17:59:20_> @U20C8CKTL: Good suggestion. The problem is about the availability of exotics library in python3
* _2016-11-25 17:59:30_> @U20C8CKTL: future is a good practice for compatibility
* _2016-11-25 18:13:48_> @U0B47KC3S: <@U04DFTZ7D> what do you think buying this plotter table ?
* _2016-11-26 17:44:45_> @U20C8CKTL: Hi. Does the hardware  support queuing ?
* _2016-11-26 18:10:47_> @U0B47KC3S: humm, <@U07UEJC2H> do you know that ?
* _2016-11-28 13:00:47_> @U34231VFH: Hi ! About high precision positioning devices in water there is water tanks used for radiation therapy linear accelerators calibration and quality control ( <http://www.ptw.de/water_tanks.html> for example) with 0.1 mm accuracy, remote control and queuing softwares. But they are quite expensive (far from plotter table + aquarium). 
* _2016-11-28 13:14:31_> @U0B47KC3S: <@U34231VFH> yes there is quite like a mystery on the cost :wink:
* _2016-11-28 13:33:29_> @U34231VFH: As any medical device :disappointed: 
* _2016-11-28 13:46:46_> @U07UEJC2H: <@U20C8CKTL>, the hardware support multiple connexion, but not queuing. But normally, the website that will interact with the kit support queuing
* _2016-11-28 14:02:48_> @U20C8CKTL: <@U07UEJC2H> thanks, Could you link me the  server  source code  please. I dont want do useless job.:D
* _2016-11-28 14:04:13_> @U20C8CKTL: We are just missing the ftp server ? And the software part will be ok.
* _2016-11-28 22:43:48_> @U38HVMZ6K: <@U38HVMZ6K> has joined the channel
* _2016-11-29 12:36:32_> @U07UEJC2H: <@U20C8CKTL>, I don't know where are the sources of the website, but <@U0B47KC3S> know it
* _2016-11-29 12:38:20_> @U07UEJC2H: <@U07UEJC2H>
* _2016-11-29 12:40:39_> @U07UEJC2H: <@U07UEJC2H>
* _2016-11-29 12:47:13_> @U2PFHNN3C: Classe :sunglasses: <@U07UEJC2H>
* _2016-11-29 12:49:52_> @U0B47KC3S: Bien trop bien <@U07UEJC2H> !!
* _2016-11-29 12:51:45_> @U0B47KC3S: [:muscle::clap::zap:] <@U20C8CKTL> <@U2PFHNN3C> <@U1PKXQVDW> <@U1PAGSKGU> <@U34N7NQNR> <@U36QEPF51> <@U37GZRZU6> + nourredine_elouze we are going to begin have fun with the platform !! (reactions: @U37GZRZU6,@U34N7NQNR)
* _2016-11-30 08:59:32_> @U20C8CKTL: Yeah !! Echopen ce soir ? <@U2PFHNN3C> <@U1PKXQVDW>  <@U1PAGSKGU>  <@U36QEPF51>  <@U37GZRZU6>  <@U0B47KC3S> <@U34N7NQNR>
* _2016-11-30 09:31:52_> @U0B47KC3S: sure !! it is on Wednesday now. See you later !
* _2016-11-30 09:53:31_> @U38JDLY2E: <@U38JDLY2E> has joined the channel
* _2016-11-30 12:00:00_> @USLACKBOT: Reminder: un memo pour la réunion du jeudi.
* _2016-11-30 12:13:31_> @U0B47KC3S: set up a reminder “:mega: a memo for our weekly meeting  on wednesday” in this channel at noon every Wednesday, Central European Time.
* _2016-11-30 12:14:23_> @U0B47KC3S: set up a reminder “:mega: a memo for our weekly meeting  on wednesday” in this channel at 12:30pm every Wednesday, Central European Time.
* _2016-11-30 12:30:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday. (reactions: @U37GZRZU6,@U20C8CKTL)
* _2016-11-30 19:27:54_> @U38TWKY9Y: <@U38TWKY9Y> has joined the channel
* _2016-11-30 19:29:17_> @U38TWKY9Y: Bonjour à tous, <@U2PFHNN3C> m'a invité !
* _2016-11-30 21:02:45_> @U04DFTZ7D: Welcome <@U38TWKY9Y> !! Nice to see you here ;)
* _2016-12-01 18:48:54_> @U0B47KC3S: hi there, a quasi report of the session of the SigProc team : <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo/edit#heading=h.xsjhfeqw1gz9>
* _2016-12-01 18:48:55_> @U0B47KC3S: <@U0B47KC3S>
* _2016-12-01 18:49:31_> @U0B47KC3S: <@U2PFHNN3C> <@U38TWKY9Y> if you want to complete, you’re welcome because I reported until I left
* _2016-12-02 10:34:50_> @U0KLG7CP8: <@U0KLG7CP8> has joined the channel
* _2016-12-05 16:01:44_> @U0B47KC3S: [:mega:] at last, we bought an ultrasound phantom, after scrutinizing for more than a year on ebay an affordable one. For the record, it is dreadfully costy :wink: (reactions: @U04DFTZ7D,@U20C8CKTL,@U37GZRZU6)
* _2016-12-05 16:02:17_> @U0B47KC3S: <@U0B47KC3S>
* _2016-12-05 16:02:20_> @U0B47KC3S: Practical consequence, All the stuffs for the challenge are ready, it only remains to hang up the wagons :grinning:
* _2016-12-06 08:48:12_> @U38HVMZ6K: :heart_eyes: great !!!
* _2016-12-07 04:08:32_> @U3ARRLDQ8: <@U3ARRLDQ8> has joined the channel
* _2016-12-07 10:31:56_> @U0B47KC3S: hey channel ! one word to say our weekly meeting will hold 30 minutes later than usual cc <@U20C8CKTL> <@U34N7NQNR> <@U2PFHNN3C> <@U37GZRZU6> <@U1PKXQVDW> <@U38TWKY9Y> <@U1PAGSKGU> (reactions: @U37GZRZU6,@U20C8CKTL)
* _2016-12-07 10:36:38_> @U20C8CKTL: Ok. ill be there at 18h30
* _2016-12-07 10:47:13_> @U0B47KC3S: <@U20C8CKTL>, you re welcome :wink: just to make sure I delivered a clear information, the meeting the meeting will begin 30mn later so at 19H00
* _2016-12-07 10:48:57_> @U20C8CKTL: Ahah. Ok ! 
* _2016-12-07 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2016-12-07 14:58:22_> @U3BN2NTFU: <@U3BN2NTFU> has joined the channel
* _2016-12-07 19:03:59_> @U1PKXQVDW: <@U1PKXQVDW> and commented: Article sur real time denoising
* _2016-12-07 19:24:19_> @U0B47KC3S: <@U0B47KC3S>
* _2016-12-07 19:28:57_> @U0B47KC3S: <@U0B47KC3S>
* _2016-12-07 19:30:52_> @U0B47KC3S: <@U0B47KC3S> and commented: an other thesis
* _2016-12-07 20:25:12_> @U0B47KC3S: web todos 4 <@U34N7NQNR> and <@U20C8CKTL> :
* _2016-12-07 20:25:47_> @U0B47KC3S: * Investigation Connection * mongondb-django * Creation of the data model * Metric Resource host: cpu / memory * Deployment scripts and update * Secure executions: -scripts SHA-1 -analysis of the source -capcha Improved graphical interface -Display detailed info by run -Displays images by run -Displaying the code for each run * Automation control of ultrasound * Production process * Clean source code
* _2016-12-07 23:02:26_> @U2PFHNN3C: <@U2PFHNN3C>
* _2016-12-07 23:31:26_> @U0B47KC3S: interesting <@U2PFHNN3C>, unfortunately there is no reference when it is said “a speckle  noise… is added”,  however, this goes in the sense that it is quite common
* _2016-12-08 09:04:36_> @U2PFHNN3C: <@U36QEPF51> as promised, here’s a great course on ConvNets, along with an introduction to NN in general <http://cs231n.github.io/>
* _2016-12-08 09:04:49_> @U2PFHNN3C: please let me know if you want to discuss it at some point
* _2016-12-08 10:19:01_> @U0B47KC3S: btw, here the report of yesterday’s session ! <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo/edit#>
* _2016-12-08 10:19:02_> @U0B47KC3S: <@U0B47KC3S>
* _2016-12-08 11:16:11_> @U2PFHNN3C: Merci <@U0B47KC3S> tu assures :slightly_smiling_face:
* _2016-12-08 16:59:58_> @U36QEPF51: Thank's <@U2PFHNN3C>  i'll start reading it and i'll tell you when I finish it
* _2016-12-08 17:00:10_> @U2PFHNN3C: awesome <@U36QEPF51>
* _2016-12-08 22:03:08_> @U3CDR25JP: <@U3CDR25JP> has joined the channel
* _2016-12-09 12:17:15_> @U0B47KC3S: <@U20C8CKTL> <@U34N7NQNR> <@U07UEJC2H> <@U04DFTZ7D> <@U0GMX7QUB> renaming of github’s repo are up and running. So we have, `PRJ-medtec_kit` for the all software kit related stuffs and `PRJ-medtec_sigproc` for the signal processing project !
* _2016-12-09 12:27:14_> @U20C8CKTL: Ok. The dev branch is ok ?
* _2016-12-09 12:28:04_> @U0B47KC3S: maintenant oui :wink:
* _2016-12-09 12:28:49_> @U20C8CKTL: A oui. Javais peur que tu zappes. Super ca sera plus propre.
* _2016-12-09 12:38:42_> @U0B47KC3S: Yes c up and running. And indeed I did not quite have that in mind. So we can take advantage of it to “ticket" our repo! :ok_hand:
* _2016-12-09 12:44:44_> @U20C8CKTL: Est ce que tu peux creer un ticket et m attribuer ? On verra si je suis notifié
* _2016-12-09 13:11:05_> @U0B47KC3S: I have just added you as a contributor
* _2016-12-09 13:16:08_> @U0B47KC3S: I created a project and issue but I couldn’t attach the issue to the project. Maybe a matter of time ?
* _2016-12-09 17:30:51_> @U3CV9P9NH: <@U3CV9P9NH> has joined the channel
* _2016-12-12 14:11:31_> @U2PFHNN3C: I’m at HD, <@U3CV9P9NH> just in case you’re around :slightly_smiling_face:
* _2016-12-13 09:30:00_> @U3D9HA0N4: <@U3D9HA0N4> has joined the channel
* _2016-12-13 16:30:24_> @U0B47KC3S: when we’ll be ready to denoise image through neural networks, we could submit a PR on this repo :wink:
* _2016-12-13 16:30:24_> @U0B47KC3S: <https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap?imm_mid=0ea317&amp;cmp=em-data-na-na-newsltr_20161102>
* _2016-12-13 20:28:56_> @U37GZRZU6: <@U37GZRZU6> and commented: here's a comparative evaluation of despeckle filters applied to ultrasound imaging of carotid arteries. the evaluations include image quality (PSNR and so on...) but also percentages of correct classifications (symptomatic vs. asymptomatic) obtained with a kNN classifier and form experts :wink:
* _2016-12-14 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2016-12-14 15:59:34_> @U0B47KC3S: tonight we have two visiting physicists in our sigproc meeting ! <@U2MF267L2> <@U3D9HA0N4> (reactions: @U37GZRZU6)
* _2016-12-14 16:00:06_> @U37GZRZU6: yeees physicists :hugging_face: (reactions: @U0AAL4W13)
* _2016-12-14 16:19:25_> @U0AAL4W13: <@U2MF267L2> oO you were in microflu, you may have met Eloise C. (who left last year?)
* _2016-12-14 16:19:31_> @U2MF267L2: <@U2MF267L2> has joined the channel
* _2016-12-14 20:20:34_> @U37GZRZU6: a thesis about GPU ultrasound simulation :  <http://campar.in.tum.de/twiki/pub/Main/AthanasiosKaramalis/Thesis.pdf>
* _2016-12-14 22:05:48_> @U2PFHNN3C: Awesome <@U37GZRZU6> Thankiess! (reactions: @U37GZRZU6)
* _2016-12-15 13:56:54_> @U0AAL4W13: Hey sigproc guys, a quick thought. Cheap, chinese wireless probes exist. The images are streamed over wifi. I'm confident it's feasible to hack the communication protocol and have a server up and running on a computer to capture images from this type of probe, and acquiring those, to get a feel of real images. What do you think?
* _2016-12-15 13:59:10_> @U38HVMZ6K: :+1::skin-tone-2: +1 for me depending on the price
* _2016-12-15 13:59:34_> @U38HVMZ6K: and I'm ready to reverse engineer and hack the gadget for testing
* _2016-12-15 14:00:39_> @U0AAL4W13: EBay is like 700$
* _2016-12-15 14:00:55_> @U0AAL4W13: Could be cheaper when asking for a sample from alibaba directly 
* _2016-12-15 14:01:20_> @U0AAL4W13: I'd be in to play with wireshark 
* _2016-12-15 14:02:30_> @U38HVMZ6K: OK. I already have to invest in 2 devkits (CPU and ADC) so this would make the bill a bit high for this year end (with Christmas gifts)
* _2016-12-15 14:02:42_> @U0AAL4W13: Haha
* _2016-12-15 14:02:48_> @U0AAL4W13: What have you ordered ?
* _2016-12-15 14:03:38_> @U38HVMZ6K: Board OMAP: <http://www.ti.com/tool/tmdslcdk138> 195$ Eval kit ADC: <http://www.ti.com/tool/ads6142evm> 299$
* _2016-12-15 14:34:27_> @U0AAL4W13: Nice !
* _2016-12-15 19:07:10_> @U3FE9KW4D: <@U3FE9KW4D> has joined the channel
* _2016-12-16 22:08:37_> @U0B47KC3S: hey <#C2MAANG0P>, one word to let you know that the node app for controlling the ultrasound probe from remote, is all set up ! we can now feed you with echOpen data. We will deploy it in the next few days :wink: (reactions: @U37GZRZU6,@U38HVMZ6K,@U20C8CKTL)
* _2016-12-16 22:09:09_> @U0B47KC3S: now going back to GPU stuffs #CapMed hackathon :wink:
* _2016-12-17 15:19:00_> @U3GQS8JTZ: <@U3GQS8JTZ> has joined the channel
* _2016-12-18 11:08:18_> @U0AAL4W13: Still about phantoms: mixing 3d printing and wax molding - <http://link.springer.com/article/10.1007%2Fs10439-016-1757-5>
* _2016-12-19 13:51:26_> @U3GHS132Q: <@U3GHS132Q> has joined the channel
* _2016-12-19 18:49:08_> @U0AAL4W13: Hey, got a question for you guys :) Say you have a ultrasound-like signal, centered around zero, but that you set all negative elements to zero. Would you find a way to rebuild the original signal?
* _2016-12-19 18:51:27_> @U0AAL4W13: Knowing that you miss half the signal, maybe half the information, may be a challenge - still, using the signal "physical" origin could help. Or not.
* _2016-12-21 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2016-12-21 15:09:51_> @U3HH0CEAW: <@U3HH0CEAW> has joined the channel
* _2016-12-22 14:13:43_> @U3J40RUDT: <@U3J40RUDT> has joined the channel
* _2016-12-22 15:14:07_> @U2PTWF6SX: <@U2PTWF6SX> has joined the channel
* _2016-12-22 15:14:07_> @U1N5Q9334: <@U1N5Q9334> has joined the channel
* _2016-12-22 15:14:07_> @U07SS18MT: <@U07SS18MT> has joined the channel
* _2016-12-22 15:14:07_> @U1DGN6S80: <@U1DGN6S80> has joined the channel
* _2016-12-22 15:14:08_> @U33KM85FA: <@U33KM85FA> has joined the channel
* _2016-12-22 15:14:08_> @U0LPTV0Q4: <@U0LPTV0Q4> has joined the channel
* _2016-12-22 15:14:08_> @U33389FRA: <@U33389FRA> has joined the channel
* _2016-12-22 15:14:08_> @U2NAWHM9N: <@U2NAWHM9N> has joined the channel
* _2016-12-22 15:14:08_> @U0GN7EB32: <@U0GN7EB32> has joined the channel
* _2016-12-22 15:14:09_> @U0HF2S3QX: <@U0HF2S3QX> has joined the channel
* _2016-12-22 15:14:09_> @U0DRKLMS4: <@U0DRKLMS4> has joined the channel
* _2016-12-22 15:14:09_> @U2Q4137LL: <@U2Q4137LL> has joined the channel
* _2016-12-22 15:14:09_> @U3B1RKVSP: <@U3B1RKVSP> has joined the channel
* _2016-12-22 15:14:09_> @U2V03QR8E: <@U2V03QR8E> has joined the channel
* _2016-12-22 15:14:09_> @U2UU194RZ: <@U2UU194RZ> has joined the channel
* _2016-12-22 15:14:09_> @U3BFTB7M4: <@U3BFTB7M4> has joined the channel
* _2016-12-22 15:14:09_> @U3BAH0X62: <@U3BAH0X62> has joined the channel
* _2016-12-22 15:14:09_> @U394HRZ1B: <@U394HRZ1B> has joined the channel
* _2016-12-22 15:14:10_> @U336DPZV4: <@U336DPZV4> has joined the channel
* _2016-12-22 15:14:10_> @U352MKG4V: <@U352MKG4V> has joined the channel
* _2016-12-22 15:14:10_> @U2X419KJS: <@U2X419KJS> has joined the channel
* _2016-12-22 15:14:10_> @U2YN8FREG: <@U2YN8FREG> has joined the channel
* _2016-12-22 15:14:10_> @U2Y7FPEUB: <@U2Y7FPEUB> has joined the channel
* _2016-12-22 15:14:10_> @U2XLJS5L0: <@U2XLJS5L0> has joined the channel
* _2016-12-22 15:14:11_> @U0FN1B8KD: <@U0FN1B8KD> has joined the channel
* _2016-12-22 15:14:11_> @U3FCS2UP3: <@U3FCS2UP3> has joined the channel
* _2016-12-22 15:14:11_> @U0JFW4XTQ: <@U0JFW4XTQ> has joined the channel
* _2016-12-23 17:31:12_> @U0B47KC3S: hi SigProc friends : here’s the bunch of data you required :open_file_folder: !
* _2016-12-23 17:31:20_> @U0B47KC3S: you ‘ll find here <https://drive.google.com/drive/u/0/folders/0B0V8htWBLPWBQ1l5aHdjSkdtVms>  datasets related to Jérôme’s hand, a sponge and a gel inside its box which provides several interfaces
* _2016-12-23 17:31:30_> @U0B47KC3S: You’ll find in the `readme` the main specs :balloon:
* _2016-12-23 17:31:35_> @U0B47KC3S: Here are the pics of the object we passed through ultrasound :camera:
* _2016-12-23 17:33:08_> @U0B47KC3S: <@U0B47KC3S>
* _2016-12-23 17:33:48_> @U0B47KC3S: <@U0B47KC3S>
* _2016-12-23 17:34:06_> @U0B47KC3S: <@U2PFHNN3C> <@U37GZRZU6> <@U1PKXQVDW> : hope you'll have fun !
* _2016-12-23 17:55:16_> @U37GZRZU6: thanks <@U0B47KC3S> and <@U07UEJC2H> :slightly_smiling_face:
* _2016-12-24 22:47:42_> @U2PFHNN3C: Thanks a lot folks!
* _2016-12-26 15:23:42_> @U0B47KC3S: oups, j’avis oublié de shooter le CR de la séance du 20.12.16 :wink: <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo/edit>
* _2016-12-26 15:23:43_> @U0B47KC3S: <@U0B47KC3S>
* _2016-12-28 11:18:30_> @U0B47KC3S: hi there, for people around in paris, the SigProc meeting is rescheduled for tomorrow 18H30, precise :wink:
* _2016-12-28 11:22:19_> @U0AAL4W13: Will try to join by curiosity, though it's really early :) (reactions: @U37GZRZU6)
* _2016-12-28 18:46:11_> @U0AAL4W13: I'm there, where are you guys?
* _2016-12-28 19:01:00_> @U0AAL4W13:  Ooops shoot that was tomorrow, my bad ;)
* _2016-12-28 19:03:28_> @U0AAL4W13: #boulay :squirrel:  (reactions: @U37GZRZU6)
* _2016-12-29 16:12:58_> @U37GZRZU6: <@U0AAL4W13> are you coming today ? actually I think I'm the only one from sigproc who will be there, but if you're available I'd like to benefit from your expertise in ultrasound images / data acquisition, just let me know :blush:
* _2016-12-29 16:45:03_> @U0AAL4W13: Sure  (reactions: @U37GZRZU6)
* _2016-12-29 16:45:40_> @U0AAL4W13: <@U0B47KC3S>: you there as well? By the way, team has rebuilt some images from the data ?
* _2016-12-29 16:57:18_> @U0B47KC3S: yes I’ll be there and I am going to check with <@U07UEJC2H> for the metadata
* _2016-12-29 16:58:26_> @U0AAL4W13: Wîiiiiii 
* _2016-12-29 23:25:48_> @U37GZRZU6: <@U37GZRZU6> made the assumption that it may come from some high-frequency noise... do you have any explanation ?
* _2016-12-30 08:14:20_> @U0AAL4W13: (or an enveloppe detection with a small characteristic time maybe  (reactions: @U37GZRZU6)
* _2016-12-30 10:29:30_> @U07UEJC2H: It's not noise, I think it's a trigger problem, we don't have exactly the same "0" on each line. It looks like there a shift of one point some times (RedPitaya issue)
* _2016-12-30 10:44:34_> @U37GZRZU6: <@U07UEJC2H> there's something else that surprises me : on a given line there are some discontinuities from one pixel to its neighbour. This can't be explained by a trigger problem, right ?
* _2016-12-30 11:30:45_> @U07UEJC2H: <@U37GZRZU6> Yes, it is the same issue but the shift is not of one point but many... It happen some times
* _2016-12-30 11:38:21_> @U0AAL4W13: Strange.. If the trigger was in cause it would not alter the content of the line itself, rather have a general offset of the line.
* _2016-12-30 11:39:10_> @U0AAL4W13: What was the sampling frequency? It'd be interesting to know the frequency of this "sponge-parasite"  :) 
* _2016-12-30 11:40:43_> @U37GZRZU6: <@U07UEJC2H> (we're talking about horizontal lines, i.e. discontinuities at a fixed angle)
* _2016-12-30 13:12:30_> @U07UEJC2H: We're talking about the same thing, if you look carefully you will see that the shift is on all contiguous lines. Does it happen often? Cause dynamically I didn't notice that
* _2016-12-30 14:02:40_> @U07UEJC2H: * all along some continuous lines, not all lines...
* _2016-12-30 14:05:14_> @U0AAL4W13: What was the sampling frequency ?
* _2016-12-30 14:27:26_> @U07UEJC2H: 125/8 MHz
* _2016-12-30 14:38:43_> @U37GZRZU6: <@U07UEJC2H> it happens in every image actually
* _2016-12-30 18:13:32_> @U07UEJC2H: It might come from an error in my C script I've just found. I have to check
* _2016-12-30 20:12:42_> @U0AAL4W13: <@U0AAL4W13>
* _2016-12-30 20:25:18_> @U0AAL4W13: c'est moins prononcé sur d'autres lignes, mais on voit dans tous les cas des patates à haute fréquence (vers 4MHz+) alors qu'on a un passe bas normalement (via la détection d'enveloppe). Strange.
* _2016-12-30 20:35:37_> @U0AAL4W13: <@U0AAL4W13>
* _2017-01-02 16:04:34_> @U0AAL4W13: <@U37GZRZU6> - si ca te tente, j'ai rajouté une scan conversion moche ( <https://github.com/kelu124/PRJ-medtec_sigproc/blob/master/dataquarium/explore.ipynb> ) (reactions: @U37GZRZU6)
* _2017-01-02 16:06:02_> @U0AAL4W13: I've tried as well to do some filtering in fourier, but I have sort of a bug (the three images, with different filtering, produce the same output). Anyhow, the basis is here to explore in jupyter the dataset produced by <@U07UEJC2H>
* _2017-01-02 16:17:15_> @U0AAL4W13: Corrected. The notebook can serve as a basis for exploration, including FFT hacking.
* _2017-01-04 10:19:01_> @U0B47KC3S: hi there, since there were some rescheduling on tuesday for our last session, let’s remind and confirm that the meeting will hold today at echOpen HD ! (reactions: @U37GZRZU6,@U0AAL4W13)
* _2017-01-04 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-01-04 16:20:52_> @U0AAL4W13: Still 18.30?
* _2017-01-04 16:26:53_> @U37GZRZU6: <@U0AAL4W13> yes! :slightly_smiling_face: (reactions: @U0AAL4W13)
* _2017-01-05 00:07:38_> @U0B47KC3S: hi there, here’s the report of today’s meeting : <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo/edit>
* _2017-01-05 00:07:38_> @U0B47KC3S: <@U0B47KC3S>
* _2017-01-05 00:15:27_> @U2PFHNN3C: Merci beaucoup <@U0B47KC3S> !
* _2017-01-05 00:46:41_> @U0AAL4W13: Done. A first draft of SigProc101 has been published. It also gives access to an artificial raw signal of a ultrasound phantom to play with in CSV, as well as a basic error function to assess the different signal-to-image transformation, at <https://github.com/kelu124/PRJ-medtec_sigproc/blob/master/SigProc_101/SigProc-101.ipynb> -- <@U37GZRZU6> , there's is something to play with in python at least. This would also enable the SigProc team to test different envelope detection algorithms. References to two papers have been added at the end of the notebook. (reactions: @U0B47KC3S,@U38HVMZ6K,@U37GZRZU6)
* _2017-01-05 00:47:52_> @U37GZRZU6: thaaanks <@U0AAL4W13> and  <@U0B47KC3S> :smiley:
* _2017-01-05 08:18:16_> @U38HVMZ6K: Great job <@U0AAL4W13>!
* _2017-01-05 09:54:02_> @U3BAH0X62: thanks <@U0AAL4W13>, <@U0B47KC3S> !
* _2017-01-05 11:36:00_> @U07UEJC2H: There is an echopen github for signal processing: <https://github.com/echopen/PRJ-medtec_sigproc> we must clean it a little but there is one
* _2017-01-05 11:37:36_> @U0AAL4W13: Indeed, that's the one I forked, but I don't have the rights to accept pull requests :) if I have those, I could push on it 
* _2017-01-05 11:37:50_> @U0AAL4W13: <@U0B47KC3S>  is it solvable ?
* _2017-01-05 11:39:40_> @U0B47KC3S: sure :wink:
* _2017-01-05 11:41:11_> @U0B47KC3S: you should receive an invitation soon
* _2017-01-05 11:43:09_> @U0AAL4W13: Thx! 
* _2017-01-05 11:43:33_> @U0AAL4W13: May I take this opportunity to ask for the meltec_kit one as well?
* _2017-01-05 11:54:57_> @U0AAL4W13: <@U07UEJC2H> : done! Merged on the echOpen repo :)
* _2017-01-05 12:22:57_> @U0B47KC3S: btw, a best practice is that the pull-requester should not merge his own PR :wink: (reactions: @U37GZRZU6)
* _2017-01-05 12:24:56_> @U0AAL4W13: Apologies :) I saw a PR accepted by the its author today, thought that wasn't an issue :/
* _2017-01-05 12:25:07_> @U0AAL4W13: Btw, who is the maintainer on this repo ?
* _2017-01-05 12:31:06_> @U0B47KC3S: yep my response was not complete : in fact, as a rule of thumb, I remember we suggested each other some times ago that beyond 48H of no reviewing, this could happen. Anyway, in our meeting yesterday, <@U38HVMZ6K> raised some questions related to the “how to manage a github repo”. With no emergency, we should begin to write some notes on a kinda of MetaGitBook
* _2017-01-05 12:37:38_> @U0AAL4W13: For the sake of memory (dunno where to post it on Slack), some first points were discussed earlier, at <https://github.com/echopen/echOpen_starterkit/issues/3> (reactions: @U38HVMZ6K,@U0B47KC3S)
* _2017-01-05 13:34:08_> @U38HVMZ6K: Thanks <@U0AAL4W13> for pulling out this old conversation. I think it raises several questions I also asked myself and on which we should discuss and agree. If we can put in place a general strategy applied to all repos the same way it will be easier for everyone to contribute than having different policies on different repos.
* _2017-01-05 13:37:50_> @U38HVMZ6K: The question is then how to organize the teams/repos... By experience, having a single maintainer per repo is often awkward an can lead to delay (holidays, business trips, temporary external load: job, family,...), overload for the maintainer and "democracy" issues where the maintainer is the only one deciding  to merge or not.
* _2017-01-05 13:46:20_> @U38HVMZ6K: On the other hand, opening the repos to many/all contributors may also be problematic.
* _2017-01-05 13:47:49_> @U38HVMZ6K: The approach we had on several projects I worked on was to work on a single repo with everyone working on his own branch (not a fork) with the golden rule that no one directly commit to the master branch. (reactions: @U0AAL4W13,@U37GZRZU6)
* _2017-01-05 13:49:15_> @U38HVMZ6K: This way we could work in a similar fashion as with fork+pull requests but with the "emergency" possibility of being able to merge on the master branch in case of necessity.
* _2017-01-05 15:56:26_> @U3ML4L01Z: <@U3ML4L01Z> has joined the channel
* _2017-01-05 23:13:45_> @U3GHS132Q: Sorry for sneeking in this channel but how does the master branch move forward if no one commit on it and everyone work on his own branch ?
* _2017-01-05 23:15:04_> @U37GZRZU6: <@U3GHS132Q> you can send some pull requests to merge your own branch on master then :slightly_smiling_face:
* _2017-01-05 23:15:25_> @U3GHS132Q: Ah ok all is clear now, thank you
* _2017-01-05 23:15:48_> @U3GHS132Q: I think it is a good idea !
* _2017-01-05 23:19:07_> @U37GZRZU6: So do I by the way! thanks <@U38HVMZ6K> and <@U0AAL4W13>, it's an important matter :slightly_smiling_face:
* _2017-01-07 17:36:34_> @U0AAL4W13: Some reading: (may be interesting to get a standard bibliography (bibtex ?) in the repo) both for signal and image processing. 
* _2017-01-07 17:36:37_> @U0AAL4W13: SigProc: Frequency Domain Compressive Sampling for Ultrasound Imaging: <https://www.researchgate.net/publication/258382829_Frequency_Domain_Compressive_Sampling_for_Ultrasound_Imaging>
* _2017-01-07 17:36:49_> @U0AAL4W13: Image processing: ML for fetal standard planes: <https://arxiv.org/abs/1612.05601>
* _2017-01-07 17:37:02_> @U0AAL4W13: The later is really neat 
* _2017-01-07 23:40:00_> @U38HVMZ6K:  I also thought about a general bibliography for the echOpen community and I would recommend Mendeley (<http://www.mendeley.com>) to keep this bibliography. It's not only a bibliography but a full-featured references/documents management. You can upload PDFs in your library and they will be accessible online from anywhere in "My Library". You can create groups or communities based on topics/project. With the desktop version all PDFs in your library are indexed to allow full-text search in them (very useful!). Authors, title,... are automatically resolved when you import the PDF. It can also easily export bibliographies from selected entries in your library in different formats (bibtex, word,...) This is a life-saver when you have 500+ entries in your library, select 20 of them for a publication, click generate bibliography and done, you have your bibtex :wink:  (reactions: @U37GZRZU6,@U0B47KC3S)
* _2017-01-07 23:41:13_> @U38HVMZ6K: It's also helpful to manage personal annotations on PDFs you can put while you are reading the document.
* _2017-01-08 00:42:44_> @U37GZRZU6: <@U38HVMZ6K>  Mendeley is pretty cool but when you exceed a certain amount of uploaded PDFs then you have to pay... I don't know what's the limit though, but we should be careful with that :wink:
* _2017-01-08 00:46:44_> @U37GZRZU6: Anyway we can still use Mendeley to share some references. It's possible to use it without PDF sync. But then we lose some of the magic of this tool actually :thinking_face:
* _2017-01-08 01:58:48_> @U0B47KC3S: <@U04DFTZ7D> what you think ? cc <@U2MF267L2> do you know that ?
* _2017-01-08 08:49:51_> @U38HVMZ6K: <@U37GZRZU6> free plan gives 2GB of storage. For more pricing is here: <https://www.mendeley.com/upgrade/storage/>
* _2017-01-08 08:50:17_> @U38HVMZ6K: 2GB of PDFs is already quite large...
* _2017-01-08 08:53:28_> @U38HVMZ6K: My bad... 2GB for personal library and 100MB for shared... That's a limit indeed.
* _2017-01-08 08:55:42_> @U38HVMZ6K: We may apply for an "Institutional Edition" <https://www.elsevier.com/solutions/mendeley/Mendeley-Institutional-Edition>
* _2017-01-08 08:56:36_> @U38HVMZ6K: It seems to be eligible for Society/Association... With 5GB of personal library and 20GB for shared... (reactions: @U37GZRZU6)
* _2017-01-08 13:19:49_> @U37GZRZU6: <@U38HVMZ6K> this rocks! have you an idea if that's free or not ?!
* _2017-01-08 13:30:02_> @U38HVMZ6K: No idea if this is free or if discount price is available for non-profit open source... We should ask
* _2017-01-08 13:30:58_> @U37GZRZU6: <@U0B47KC3S> <@U04DFTZ7D> what do you think? :hugging_face:
* _2017-01-08 13:58:13_> @U0AAL4W13: Fi I've also been using zotero, quite nice for collaborating.. In terms of functionalities seems similar to this one :)
* _2017-01-08 14:07:54_> @U37GZRZU6: <@U0AAL4W13> didn't know about zotero, but I really like the way it allows to organize documents into collections :slightly_smiling_face: seems really useful !
* _2017-01-08 14:28:55_> @U0AAL4W13: Yup, you can also tag them, annote them,..  It's also collaborative, so quite good. 
* _2017-01-08 15:17:51_> @U38HVMZ6K: <@U0AAL4W13> seems quite cool as well. Can you do a full-text search in your whole library with zotero? Never used it and I found this to be very useful in Mendeley
* _2017-01-08 15:33:28_> @U0B47KC3S: <@U37GZRZU6> seems nice ! but I think <@U04DFTZ7D>’s point of view can be interesting :wink:
* _2017-01-08 15:44:34_> @U0AAL4W13: <@U38HVMZ6K>  : yup, you can. (reactions: @U37GZRZU6)
* _2017-01-08 15:45:40_> @U37GZRZU6: <@U0AAL4W13> is it completely free without limitations ? :heart_eyes:
* _2017-01-08 16:23:02_> @U0AAL4W13: there are plans in terms of storage
* _2017-01-09 11:16:42_> @U2PFHNN3C: I’m trying to use Zotero but not quite satisfied AFAIK :slightly_smiling_face: so for now, I’m just using Bibdesk...
* _2017-01-09 11:17:28_> @U2PFHNN3C: coupled with Sublime Text and its latex plugin, it’s super easy to add references after a .bib lookup
* _2017-01-09 11:19:20_> @U2PFHNN3C: but lacks annotation, collaboration etc
* _2017-01-09 11:22:02_> @U04DFTZ7D: De mon côté, j'utilise <https://www.refme.com/> Que je trouve génial pour la bibliographie :wink:
* _2017-01-09 11:23:30_> @U38HVMZ6K: and I used JabRef (<http://www.jabref.org/>) in the past... seems to have evolved a lot since the last time I used it :slightly_smiling_face:
* _2017-01-09 11:24:47_> @U38HVMZ6K: I think we have plenty of tools and ideas to do this. We should then align on a common tool. All of them are good for personal/standalone use I think. The difference will be in the sharing/aggregating options and storage.
* _2017-01-09 11:25:06_> @U38HVMZ6K: we should collect info on all of them and decide after I would say
* _2017-01-09 11:38:59_> @U0B47KC3S: <@U04DFTZ7D> indeed `refme` is amazing and simple
* _2017-01-09 11:39:09_> @U2PFHNN3C: I’m gonna give RefMe a try! Thanks <@U04DFTZ7D>
* _2017-01-09 11:39:28_> @U2PFHNN3C: (or we can code one from scratch…)
* _2017-01-09 11:40:14_> @U38HVMZ6K: &gt;(or we can code one from scratch…) this is the last option I go for :joy:
* _2017-01-09 11:41:23_> @U38HVMZ6K: this often an issue in professional life... "let's code a bugtracker/documentation system/reference manager/editor/simulator/..." where thousands of good free tools exist
* _2017-01-09 11:41:55_> @U38HVMZ6K: at the end of the day you spend more time on the homegrown tools than on your effective project :slightly_smiling_face:
* _2017-01-09 11:44:37_> @U2PFHNN3C: <@U38HVMZ6K> I totally agree in fact :)) (it was even half-provocative). That said, in the present case, there is no “thousands of good free tools”, as for myself, I’m still looking for the right bib management tool
* _2017-01-09 11:53:12_> @U3NT8G2BC: <@U3NT8G2BC> has joined the channel
* _2017-01-09 11:58:16_> @U2PFHNN3C: “Highlighter is unavailable for PDF” in RefMe :disappointed: that’s was I was looking for
* _2017-01-11 00:18:07_> @U0AAL4W13: SigProbeBiblio.append ( UsimagTool: An Open source Freeware Software for Ultrasound Imaging and Elastography  @ <http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.98.4549> ) (reactions: @U0B47KC3S,@U38HVMZ6K)
* _2017-01-11 01:16:11_> @U0B47KC3S: nice tool indeed :wink: did you install it ?
* _2017-01-11 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-01-12 00:18:33_> @U3PLYAJPJ: <@U3PLYAJPJ> has joined the channel
* _2017-01-12 09:19:49_> @U0B47KC3S: here’s the report of 11.01.17 meeting + the report of 14.12.16 by <@U1PKXQVDW> <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo/edit#heading=h.xsjhfeqw1gz9> <@U2PFHNN3C> if you want to complete, go !
* _2017-01-12 09:19:49_> @U0B47KC3S: <@U0B47KC3S>
* _2017-01-12 09:20:27_> @U2PFHNN3C: I was thinking about that this morning :) thanks!
* _2017-01-12 09:38:57_> @U37GZRZU6: thanks !
* _2017-01-12 09:41:36_> @U2PFHNN3C: Btw guys (<@U0B47KC3S> and <@U20C8CKTL>), putting jupyter notebooks on the challenge platform is nice (awesome even IMO) but will it serve to generate a new submission?
* _2017-01-12 09:49:42_> @U0B47KC3S: <@U2PFHNN3C> you mean how to submit ? I think <@U37GZRZU6> wants to complete the doc of the challenge, <@U37GZRZU6> am I right ?
* _2017-01-12 09:50:55_> @U37GZRZU6: yes I will probably do that today in the lunchtime, but not sure if <@U2PFHNN3C>  is talking about this notebook :thinking_face:
* _2017-01-12 09:58:08_> @U2PFHNN3C: the thing is, if you want to use the notebooks as a way to make a submission to the server, you’ll need to parse it and execute with `nbconvert`
* _2017-01-12 10:00:33_> @U0B47KC3S: ah ok got it :wink:
* _2017-01-12 10:00:35_> @U37GZRZU6: for submission we could imagine submitting only the processed image, or the processing function, what would be the best practice ?
* _2017-01-12 10:01:04_> @U37GZRZU6: not sure if submitting a whole notebook is worth it
* _2017-01-12 10:05:15_> @U37GZRZU6: <@U2PFHNN3C> I'm thinking about the RAMPS where we had some ready-to-use notebooks which were really useful for explaining the challenge, but then we only submitted a .py implementing the classifier function, right ?
* _2017-01-12 10:05:17_> @U0B47KC3S: yes I agree, perhaps it is the simplest
* _2017-01-12 11:24:31_> @U2PFHNN3C: yep, the notebooks serve as a starting-kit, with some basic code and the explanation of the problem and the metric. Now whether submitting the code or the image is subject to a couple of questions:  - do you want the participants to see (and potentially reuse) others’ submission? if yes, you’ll need to send the code - what’s the size of the predictions made by the algorithm? if it’s a binary classification it’s just a boolean, so it’s lightweight, but if it’s about denoising, then the whole image needs to be sent. In this case, you’d better send the python algorithm instead. (reactions: @U37GZRZU6,@U0AAL4W13)
* _2017-01-12 11:24:49_> @U2PFHNN3C: both approaches have their use cases as well as their pros and cons
* _2017-01-12 11:31:50_> @U37GZRZU6: ok so I think we have the answer : the best approach here is to submit the code implementing the envelope detection function, in the form of a .py script, as it might be interesting for people to see other challengers' ideas. I'll work on that by the end of the week.  :slightly_smiling_face: (reactions: @U2PFHNN3C,@U0B47KC3S,@U0AAL4W13)
* _2017-01-12 23:44:46_> @U0AAL4W13: <@U37GZRZU6> count on me to finish the signal processing (not image though, I leave this to you guys ^^) (reactions: @U37GZRZU6)
* _2017-01-14 11:30:46_> @U0AAL4W13: A sweet repo for ultrasound : <https://kitwaremedical.github.io/SlicerITKUltrasoundDoc/Modules/ScanConversion/index.html>
* _2017-01-14 11:31:21_> @U0AAL4W13: "A 3D Slicer [Fedorov2012] extension for ultrasound image formation, processing, and analysis. Interfaces are built off the ITKUltrasound library [McCormick2014]. The modules available in this extension are useful for both 2D and 3D image generation for traditional B-mode imaging [McCormick2010], but also next-generation ultrasound image modalities like ultrasound spectroscopy [Aylward2016], acoustic radiation force imaging (ARFI) [Palmeri2016], acoustic radiation force shear wave imaging (ARFI-SWEI), and others."
* _2017-01-17 15:45:10_> @U3T7KBEMV: <@U3T7KBEMV> has joined the channel
* _2017-01-18 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-01-19 15:14:11_> @U20C8CKTL: Hi, does the notebook have to be used as a documentation page or for submission plateform ?
* _2017-01-19 15:16:18_> @U37GZRZU6: <@U20C8CKTL> the notebook is a doc / starting kit but is not supposed to be submitted
* _2017-01-19 15:16:37_> @U20C8CKTL: Aaaaaah ok.
* _2017-01-19 15:17:41_> @U37GZRZU6: the submit_function.py is an example of what should be submitted to the leaderboard
* _2017-01-19 15:25:34_> @U20C8CKTL: Right. I just need to investigate further because the leaderboard is under bootstrap and the notebook have  to fit  with bootstrap
* _2017-01-19 15:56:29_> @U0AAL4W13: We could do everything in python
* _2017-01-19 15:56:41_> @U0AAL4W13: The notebook is only here for understanding 
* _2017-01-19 16:05:16_> @U20C8CKTL: Ok. I will probably need help to add some new features on the leaderboard to do something cooler 
* _2017-01-19 16:05:54_> @U20C8CKTL: Its a mix of django, bootsrap(javascript), html.
* _2017-01-19 20:17:51_> @U3TUWV3SQ: <@U3TUWV3SQ> has joined the channel
* _2017-01-19 22:39:29_> @U3PLYAJPJ: Hi everybody I browsed the history of this channel a bit.  Is there any specific task needs to be done now? I try to participate in the next week meeting.
* _2017-01-19 22:55:06_> @U0B47KC3S: <@U20C8CKTL> <@U37GZRZU6> <@U0AAL4W13>, do you have some fancy tasks to boot it up :wink: or perhaps <@U3PLYAJPJ>   you have in mind next saturday’s meeting on the android app ?
* _2017-01-19 22:57:44_> @U0AAL4W13: what would be great for a "hands-on" approach is this enveloppe detection challenge
* _2017-01-19 22:58:14_> @U0AAL4W13: We have reconstructed a raw signal file, would be interesting to know how you would approach the challenge of enveloppe detection :smiley:
* _2017-01-19 22:58:57_> @U0AAL4W13: see <https://github.com/echopen/PRJ-medtec_sigproc/blob/master/SigProc_101/SigProc-101.ipynb> (reactions: @U37GZRZU6)
* _2017-01-19 22:59:33_> @U3PLYAJPJ: Thanks, I start playing with it
* _2017-01-19 23:14:23_> @U37GZRZU6: <@U3PLYAJPJ> don't hesitate to tell us if something's not clear enough in the explanations provided in the notebook :slightly_smiling_face:
* _2017-01-19 23:15:59_> @U3PLYAJPJ: Thanks <@U37GZRZU6>, sure  I'll do. (reactions: @U0AAL4W13)
* _2017-01-20 20:45:39_> @U0AAL4W13: <https://news.ycombinator.com/item?id=13446086> -- A software solution to ultrasound blood flow monitoring ^^ (direct link: <http://bigwww.epfl.ch/algorithms/blood-flow-monitoring/#outline> ) (reactions: @U37GZRZU6)
* _2017-01-20 20:56:02_> @U38HVMZ6K: Great! And nice to see top-level scientists publishing source code together with their publication and adding a "disclaimer":  &gt; 'We are seeking to develop this solution further, as we feel it has potential for continuous monitoring applications. We would be happy to discuss potential applications and technology transfers with any interested institution or company.'
* _2017-01-20 20:57:33_> @U38HVMZ6K: This lab is located at EPFL in Lausanne, I'll try to get in contact with them. (reactions: @U37GZRZU6,@U0B47KC3S)
* _2017-01-20 20:58:00_> @U0AAL4W13: Sweet!
* _2017-01-21 18:26:15_> @U0FN1B8KD: Phantom :
* _2017-01-21 18:36:36_> @U0B47KC3S: <@U0FN1B8KD> love it :wink:
* _2017-01-25 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-01-25 16:30:51_> @U0B47KC3S: <@U3QGT3Q74> <@U1PKXQVDW> in the flow of our conversations, check this <http://www.sciencedirect.com/science/article/pii/S0923596514001854> it is about JPEG2000 compression optimizing with wavelets, the implementation is related to, among other, ultrasound images
* _2017-01-25 16:54:27_> @U38HVMZ6K: Please keep in mind that this kind of operations are intensive in terms of computing resources and that hardware accelerators/decoders are often used to minimize CPU load of algorithms implemented in software.
* _2017-01-25 16:56:30_> @U38HVMZ6K: Before going to JPEG2000 check that we have hardware support for it or we will waste a lot of processing time just for that. (reactions: @U0AAL4W13,@U37GZRZU6,@U37GZRZU6)
* _2017-01-25 16:57:24_> @U38HVMZ6K: Or check that we have really optimized software implementations.
* _2017-01-25 17:14:34_> @U0B47KC3S: <@U38HVMZ6K> :nerd_face: shared thoughts about benchmark explorations - btw, this article is mainly aimed at screening more in depth wavelets approaches #SigProc team, especially <@U1PKXQVDW>. So this is perfect example of how 11th february CapMeth can bring some concrete way to share infos between teams in a more accurate way (reactions: @U37GZRZU6,@U20C8CKTL)
* _2017-01-26 01:08:50_> @U0B47KC3S: hi again, here is the report of tonight sig session :wink: <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo/edit#>
* _2017-01-26 01:08:51_> @U0B47KC3S: <@U0B47KC3S>
* _2017-01-26 01:31:46_> @U37GZRZU6: Thanks a lot <@U0B47KC3S> :slightly_smiling_face:  (reactions: @U0B47KC3S)
* _2017-01-26 13:45:42_> @U2PFHNN3C: Awesome <@U0B47KC3S> !
* _2017-01-26 17:16:30_> @U3WRNP30B: <@U3WRNP30B> has joined the channel
* _2017-01-30 11:54:17_> @U3Y2FPGBV: <@U3Y2FPGBV> has joined the channel
* _2017-01-30 16:49:01_> @U3XHSAQHE: <@U3XHSAQHE> has joined the channel
* _2017-02-01 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-02-01 12:09:44_> @U0AAL4W13: I have a diner at 8 but will try to stay till 7:30 :) (reactions: @U37GZRZU6)
* _2017-02-01 20:27:40_> @U0B47KC3S: hi there here’s the report of the SigProc session !
* _2017-02-01 20:27:40_> @U0B47KC3S: <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo/edit#heading=h.s1gxxl6n2mxl>
* _2017-02-02 13:34:12_> @U07UEJC2H: Hey, so yesterday I have solve the jitter problem (the shift of +- one pixel between contiguous line). This was due to non synchronise clock between RedPitaya and Arduino. Now the image are regular.
* _2017-02-02 13:39:54_> @U07UEJC2H: <@U07UEJC2H> we have made some test to check if we have linearity between time and distance, hopefully it is true and we find a speed of sound in water about 1450 m.s^{-1}. We also tried to determined the "envelope" of the focal of the transducer, it seems that the amplitude is constance versus distance. But we need calibrated stuff to do proper measurement. If it is truly flat it might means that the transducer is not focalised...
* _2017-02-02 13:41:39_> @U07UEJC2H: Not that in the file I put points for 2 cm because when the target move 1 cm, the acoustic echo have 2 cm more to do due to back and forth
* _2017-02-02 14:42:06_> @U3QGT3Q74: <@U3QGT3Q74> has joined the channel
* _2017-02-02 21:33:50_> @U37GZRZU6: Great Jerome thanks!! Is there a way we could get some images ? :grinning: 
* _2017-02-04 13:50:08_> @U41049CQ2: <@U41049CQ2> has joined the channel
* _2017-02-04 20:52:41_> @U0AAL4W13: btw, it that helps, some doc on sig/img processing : <http://www.ti.com/lit/wp/sprab12/sprab12.pdf> (reactions: @U37GZRZU6)
* _2017-02-07 15:53:42_> @U42P4AT7Z: <@U42P4AT7Z> has joined the channel
* _2017-02-08 11:22:08_> @U1PAGSKGU: <@U07UEJC2H>, <@U38TWKY9Y> and <@U1PAGSKGU> meeting today at 1430 for probe tests. (reactions: @U37GZRZU6,@U0B47KC3S)
* _2017-02-08 11:22:59_> @U37GZRZU6: great!! :smiley:
* _2017-02-08 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-02-08 17:17:14_> @U0AAL4W13: excellent !
* _2017-02-08 17:18:14_> @U37GZRZU6: luc: <http://giphy.com/gifs/the-simpsons-excellent-IeLOBZb7ZdQ1G> (reactions: @U0AAL4W13)
* _2017-02-08 18:17:07_> @U3QGT3Q74: I'm in for the evening meeting (reactions: @U0B47KC3S)
* _2017-02-08 18:43:07_> @U0AAL4W13: slacking from Algiers tonight :) (reactions: @U0B47KC3S,@U38HVMZ6K,@U37GZRZU6)
* _2017-02-08 22:08:43_> @U2PFHNN3C: Cool <@U0AAL4W13> where are you exactly :slightly_smiling_face: ?
* _2017-02-08 22:13:08_> @U0AAL4W13: Algiers centre, I was at the center for renewable energy today - superb view :) (reactions: @U2PFHNN3C)
* _2017-02-08 22:13:37_> @U1PAGSKGU: soobash [11:22 AM]  <@U07UEJC2H>, <@U38TWKY9Y> and <@U1PAGSKGU> did test of rotating probe. Replaced faulty transducer with old one. Tested rotating probe on stationary target in water tank. System can do one image per second. System can show target image even without envelope detection. Bottle neck is digital envelope detection. Need to speed up the enveloppe detection code to reach 15 frame per second to have a real-time system. Discussed the signal processing chain and the need to have an onboard DSP.
* _2017-02-08 22:15:02_> @U0AAL4W13: what is the bottleneck for framerate? enveloppe détection?
* _2017-02-08 22:16:06_> @U0AAL4W13: it would be interesting to see analog enveloppe detection too - at least compared to dsp
* _2017-02-08 22:17:42_> @U0AAL4W13: ie, if the aim is an image (no dialer, pure b-mode) - wouldn't it be possible to do with a cheaper adc + no dsp, vs having a dsp+rapid adc ?
* _2017-02-08 22:17:48_> @U0AAL4W13: just challenging ;)
* _2017-02-08 23:08:09_> @U1PAGSKGU: It would be interesting to compare the analog v/s digital envelope detection in view of the lightening of the load on the onboard system. Whether the reduction in flexibibility can be offset by the gain in slower (lower cost) ADC  and lower DSP requirement.
* _2017-02-09 13:56:42_> @U0AAL4W13: it's easily done :)
* _2017-02-09 13:57:31_> @U0AAL4W13: I have a all integrated board which includes input -&gt; tgc -&gt; envelope detection and a "slow adc"
* _2017-02-09 13:57:42_> @U0AAL4W13: one can get all the intermediary signals
* _2017-02-09 14:00:31_> @U0AAL4W13: see
* _2017-02-09 14:00:33_> @U0AAL4W13: <https://kelu124.gitbooks.io/echomods/content/Chapter2/goblin.html>
* _2017-02-09 14:06:38_> @U0AAL4W13: <https://raw.githubusercontent.com/kelu124/echomods/master/goblin/images/slide_principle.png>
* _2017-02-09 14:27:39_> @U1PAGSKGU: Thanks. I would like to do a calculation of the size of  input/output signals and processing times using the two configurations discussed in the previous message. Back of the envelope calculations only (pun intended).
* _2017-02-09 15:23:50_> @U07UEJC2H: <@U1PAGSKGU>, data of the image of screen with raw data and analogic envelope data can be found in <https://github.com/echopen/PRJ-medtec_sigproc>, dataquarium/screen Informations about number of points, lines... are written on the header of each file
* _2017-02-09 15:25:38_> @U1PAGSKGU: <@U07UEJC2H>  Thanks
* _2017-02-09 16:28:10_> @U0AAL4W13: <@U1PAGSKGU> two points you may be interested in: 1 is using a waveform generator to qualify the processed image: it's easier to quantify the image -- with a well known input form. 2 there's also a discussion about the sampling rate necessary on the adc end with or without the analog detection - we may need to understand what we need in terms of adc in both cases :)
* _2017-02-09 18:17:44_> @U0AAL4W13: <@U0AAL4W13>
* _2017-02-09 22:43:31_> @U1PAGSKGU: <@U0AAL4W13> Thanks
* _2017-02-10 08:22:03_> @U20C8CKTL: hi everybody. the leaderboard is in beta test phase, could you try it please for last improvment before release. <http://37.187.117.106:8888/>
* _2017-02-10 08:26:36_> @U20C8CKTL: here is the envelloppe extraction code to submit  : <https://github.com/echopen/PRJ-medtec_sigproc/blob/master/echopen-leaderboard/processor_node/uploaded_custom.py>
* _2017-02-10 08:27:41_> @U20C8CKTL: you can submit something else to test, stress it following the model. (reactions: @U0AAL4W13)
* _2017-02-10 08:29:47_> @U20C8CKTL: a  job can take sometime to be processed so be patient if you want your rank.
* _2017-02-10 08:34:54_> @U37GZRZU6: Yeees thanks <@U20C8CKTL> :smiley: 
* _2017-02-10 08:38:45_> @U20C8CKTL: :wink:
* _2017-02-10 09:50:20_> @U0B47KC3S: hey, thanks so much <@U20C8CKTL>
* _2017-02-10 09:52:53_> @U0B47KC3S: btw <@U42P4AT7Z> you sign in the site to get a taste of the upcoming css homogenisation work :wink:
* _2017-02-10 10:22:04_> @U0B47KC3S: here’s the 08.02.17 last meeting report (reactions: @U37GZRZU6)
* _2017-02-10 10:22:04_> @U0B47KC3S: <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo>
* _2017-02-10 12:11:22_> @U20C8CKTL: maybe he can work on docker images and deployment too
* _2017-02-10 12:12:18_> @U0B47KC3S: ok we ll have a meeting with us both cc <@U42P4AT7Z>
* _2017-02-10 12:15:08_> @U20C8CKTL: ya. and i think on more server will be required
* _2017-02-10 12:16:03_> @U20C8CKTL: for processing, because process images on the web server will be hazardous
* _2017-02-10 12:22:17_> @U0B47KC3S: <@U20C8CKTL> we increased the size of the actual server. We have 15 more Go. Is it not enough ?
* _2017-02-10 12:28:46_> @U20C8CKTL: The problem : we need to isolate image processing  from wordpress/django leaderboard . For safety and  Performance consistency. for Safety we can use docker, but for Performance consistency i don't have solution. (reactions: @U0AAL4W13,@U37GZRZU6)
* _2017-02-10 12:31:01_> @U0B47KC3S: ah ok I understand the schema you have in mind
* _2017-02-10 12:44:33_> @U20C8CKTL: what we can do is to use my 'kimsufi vm', but the load will be to heavy
* _2017-02-10 13:52:04_> @U37GZRZU6: <@U20C8CKTL> I'm not sure if the submission is reaaaally long or if it doesn't work... But I uploaded a file 10 minutes ago and still no answer from the server :thinking_face:
* _2017-02-10 13:52:27_> @U20C8CKTL: it's broken
* _2017-02-10 13:52:30_> @U20C8CKTL: XD
* _2017-02-10 13:52:39_> @U37GZRZU6: ah :sweat_smile:
* _2017-02-10 13:52:44_> @U20C8CKTL: shame on you hacker (reactions: @U37GZRZU6)
* _2017-02-10 13:52:45_> @U20C8CKTL: lol
* _2017-02-10 13:53:24_> @U20C8CKTL: did you use the example code ?
* _2017-02-10 13:53:46_> @U37GZRZU6: yes ^^
* _2017-02-10 13:53:49_> @U20C8CKTL: or did you modify something. i even don't have ssh access
* _2017-02-10 13:54:04_> @U37GZRZU6: no i just tried to upload_custom.py
* _2017-02-10 13:54:22_> @U20C8CKTL: the response don't excess 30 seconds, most of the time
* _2017-02-10 13:54:27_> @U20C8CKTL: ok
* _2017-02-10 13:56:26_> @U37GZRZU6: haha I know what happened
* _2017-02-10 13:56:51_> @U37GZRZU6: I submitted a former version of uploaded_custom.py
* _2017-02-10 13:57:01_> @U20C8CKTL: with numpy ?
* _2017-02-10 13:57:24_> @U20C8CKTL: could you send me the code ? (reactions: @U20C8CKTL)
* _2017-02-10 13:58:17_> @U37GZRZU6: ```def install_packages():     import pip     pip.main(['install', 'aesop'])  def run():     print('toto')     import io     import os     import sys     import argparse     from skimage import io     from skimage import filter     from skimage import restoration     from skimage import measure      kidney_image = io.imread('manu.jpg')     # estimate the noise in the image     # do a test denosing using a total variation filter     kidney_image_denoised_tv = restoration.denoise_tv_chambolle( kidney_image, weight=0.1)     io.imsave('denoise_image.jpg', kidney_image_denoised_tv)```
* _2017-02-10 13:59:41_> @U20C8CKTL: i don't see problem with that. :c, i think ythe problem come from  ovh
* _2017-02-10 14:00:28_> @U37GZRZU6: maybe to the fact that the run() function takes no argument in this case?
* _2017-02-10 14:02:06_> @U20C8CKTL: this is something with ovh,  hardware, infra ...  because i don't have ssh access, nor access to the website. I sent a ticket to ovh. (reactions: @U37GZRZU6)
* _2017-02-15 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-02-15 12:03:28_> @U1PAGSKGU: <@U07UEJC2H>, <@U38TWKY9Y> and <@U1PAGSKGU> to test imaging wit the probe today at Echopen from 1430. (reactions: @U0AAL4W13,@U37GZRZU6,@U0B47KC3S)
* _2017-02-15 12:04:42_> @U37GZRZU6: thaaanks <@U07UEJC2H> <@U1PAGSKGU> <@U38TWKY9Y> you rock !! see you tonight !
* _2017-02-15 18:38:56_> @U38HVMZ6K: A bit late...
* _2017-02-15 18:39:17_> @U38HVMZ6K: We are joining with <@U3PLYAJPJ> in 5 minutes
* _2017-02-15 18:40:30_> @U38HVMZ6K: Where are we joining online? Skype, jitsi?
* _2017-02-15 18:53:40_> @U38HVMZ6K: est-ce que qqn prend des minutes ?
* _2017-02-15 19:05:21_> @U2PFHNN3C: Hello! Any link?
* _2017-02-16 00:10:47_> @U0B47KC3S: hi all <@U2PFHNN3C> <@U3GHS132Q> took the report, we are going to share it with you :wink: (reactions: @U2PFHNN3C,@U37GZRZU6)
* _2017-02-16 01:14:58_> @U1PAGSKGU: <@U07UEJC2H>, <@U38TWKY9Y> and <@U1PAGSKGU> tested probe setup today for imaging. With analog front-end system able to do lagless imaging of moving screen. Tested sampling rate for detected envelope. Found envelope to be contaminated with high frequency carrier wave. Fine-tuned envelope detector to supprress carrier. This test continues this coming Monday to fine-tune and validate analog envelope detector. (reactions: @U0AAL4W13)
* _2017-02-17 11:22:26_> @U2PFHNN3C: Hi All,
* _2017-02-17 11:23:52_> @U2PFHNN3C: From last SigProc meeting report, "Tous les calculs (traitement du signal) doivent se faire sur le dispositif. Il faut réduire au possible l'exécution sur le téléphone." So is the strategy changed now? Previously we aimed at making the most of software so remote updates become easy.
* _2017-02-17 11:26:29_> @U0AAL4W13: idea: can't you imagine the smartphone doing an upgrade Ota to the probe internal software?
* _2017-02-17 11:26:58_> @U2PFHNN3C: ok
* _2017-02-17 11:27:01_> @U2PFHNN3C: thanks <@U0AAL4W13>
* _2017-02-17 11:28:05_> @U0AAL4W13: (not sure if that was discussed, just an idea like that)
* _2017-02-17 11:28:28_> @U2PFHNN3C: ah I thought it was the plan :slightly_smiling_face:
* _2017-02-17 11:28:38_> @U38HVMZ6K: processing separation (what's done on the embedded platform and what's done on the smartphone/app) has been a question I asked myself and the team at the very beginning
* _2017-02-17 11:29:00_> @U38HVMZ6K: and the answer I got was that most of the processing would be done on the phone...
* _2017-02-17 11:29:12_> @U38HVMZ6K: this is then also a question of capability...
* _2017-02-17 11:29:27_> @U0AAL4W13: there are two types of processing -  signal and image
* _2017-02-17 11:29:52_> @U0AAL4W13: plus a bottleneck to be considered : data speed between phone and probe ;)
* _2017-02-17 11:30:24_> @U38HVMZ6K: if we go with a low-end CPU/DSP in the probe then we should defer most of the processing to the phone (taking into account point mentioned right above by <@U0AAL4W13> :slightly_smiling_face: )
* _2017-02-17 11:31:28_> @U38HVMZ6K: if we have a powerful CPU on target we can perform most of the processing signal+image on the probe and only send a lightweight video stream for display to the smartphone
* _2017-02-17 11:32:01_> @U38HVMZ6K: but this is not the direction taken up to now with the processing in the Android App...
* _2017-02-17 11:32:31_> @U38HVMZ6K: &gt; doing an upgrade Ota to the probe internal software? keep in mind that we are on a medical device...
* _2017-02-17 11:33:36_> @U38HVMZ6K: software updates OTA or by wire are not seen well by regulators (many device recalls have been induced by software updates not well managed)
* _2017-02-17 11:34:26_> @U38HVMZ6K: depending on the changes you apply to the new software you want to download to the probe you may have to go through a lot of testing and potentially new certification! (reactions: @U37GZRZU6,@U0AAL4W13)
* _2017-02-17 11:35:48_> @U38HVMZ6K: see <https://fcw.com/articles/2016/08/08/gunter-fda-software.aspx> for example
* _2017-02-17 11:37:07_> @U38HVMZ6K: with the official guidance from FDA
* _2017-02-17 11:37:10_> @U38HVMZ6K: <http://www.fda.gov/downloads/MedicalDevices/DeviceRegulationandGuidance/GuidanceDocuments/UCM514737.pdf>
* _2017-02-17 11:39:22_> @U0AAL4W13: yeah having an update transforming a probe into a sonic screwdriver may not be great for patients ;)
* _2017-02-17 11:40:58_> @U38HVMZ6K: sure... but the distinction between "small updates" with no impact and more intrusive updates (subject to approval) is not always easy to establish and justify
* _2017-02-17 11:41:38_> @U38HVMZ6K: sometimes small changes have unexpected/unwanted side effects
* _2017-02-17 11:42:06_> @U38HVMZ6K: I'm right in this process now on my project and this is a nightmare
* _2017-02-17 11:42:55_> @U38HVMZ6K: as a connected device we should roll out frequent updates to keep the device safe
* _2017-02-17 11:43:45_> @U38HVMZ6K: but on the other side, it's difficult to be sure that such "small changes" won't have impact on the rest of the system without going through intensive testing
* _2017-02-17 11:44:25_> @U38HVMZ6K: timings and concurrency are always points to take into account
* _2017-02-17 11:50:37_> @U2PFHNN3C: (BTW, it doesn’t have to be OTA, but just a soft(ware) update)
* _2017-02-17 11:51:41_> @U38HVMZ6K: the same applies for OTA, USB, ... updates
* _2017-02-17 11:51:43_> @U37GZRZU6: <@U2PFHNN3C> actually as regards the signal processing, we mainly talked about the envelope detection for which we have no choice : it has to be done in the probe, otherwise we won't be able to reach 15frames/sec because of the data transmission speed between the device and the phone. we discussed the idea of performing envelope detection on the phone and compressing the raw signal before sending it to the phone, but <@U3QGT3Q74> made us realize that medical norms may be quite strict as regards compression, so we should avoid compression (or any transformation of the signal that would lead to a deterioration / loss of information). Now, if you're thinking about denoising for example, where we would perform this operation is not clear right now :wink:  <@U38HVMZ6K> very interesting remarks, thanks! Those discussions are very constructive, I think we should find a way to keep a track of this somewhere else (because on slack it will end forgotten :disappointed: ) (reactions: @U0AAL4W13)
* _2017-02-17 11:52:22_> @U37GZRZU6: Besides, this points the importance of keeping the medical certification in mind while discussing those kind of technical issues
* _2017-02-17 11:57:25_> @U37GZRZU6: ping <@U04DFTZ7D> we should brainstorm about that tonight :wink:
* _2017-02-17 12:06:54_> @U07UEJC2H: <@U37GZRZU6>, you have many possible stage of denoising: - an electronic analogical denoising  - a numerical denoising in probe (during 1D signal processing)
* _2017-02-17 12:07:17_> @U07UEJC2H: - a numerical denoising in the phone (image processing)
* _2017-02-17 12:08:17_> @U07UEJC2H: We have to work in all of them, all can be done for one image, they are not exclusive (reactions: @U37GZRZU6,@U0AAL4W13)
* _2017-02-17 12:09:55_> @U2PFHNN3C: Interesting <@U07UEJC2H> ! Can we somehow decompose everything and look more closely on the individual contribution of each part?
* _2017-02-17 12:12:04_> @U07UEJC2H: Sure <@U2PFHNN3C>, when you whant (reactions: @U2PFHNN3C)
* _2017-02-17 17:52:31_> @U07UEJC2H: <@U1PAGSKGU>, <@U38TWKY9Y>, I don't think I will have time on Monday to play with the envelope detection, must prepare Wednesday meeting
* _2017-02-17 18:21:42_> @U1PAGSKGU: <@U07UEJC2H> <@U38TWKY9Y> OK.
* _2017-02-17 19:21:18_> @U3GHS132Q: About compression, during a class I met the founder of the CIRA society which develop (with LIP6, UPMC and others) the Waaves compression algorithm. You can find some information here <http://ysitcom.com/page/447/Waaves-Le-codec-concu-pour-l-imagerie-industrielle>  If you want more information or find that this solution is interesting I can get in touch with the founder or someone which work on this at LIP6 (easier solution) (reactions: @U38HVMZ6K,@U0B47KC3S)
* _2017-02-17 19:21:58_> @U3GHS132Q: More information here <http://www.systematic-paris-region.org/en/node/24000> and here <http://www.lemondeinformatique.fr/actualites/lire-cira-de-la-compression-d-images-au-bracelet-medical-connecte-58785.html>
* _2017-02-17 19:34:29_> @U0B47KC3S: hello <@U1PKXQVDW> should be interesting for you’re doing !
* _2017-02-17 19:42:00_> @U38HVMZ6K: <@U3GHS132Q> thanks for sharing! Seems very interesting.
* _2017-02-17 19:45:56_> @U38HVMZ6K: For me, just reading through the specs and description... Facts I :heart_eyes: :  "Waaves est conforme aux normes des Dispositifs Médicaux ISO14971 et UTE62304" --&gt; no need to verify, document and mitigate its use in a medical application! It was developed using a process and under a quality system which are compliant with medical devices regulations
* _2017-02-17 19:48:42_> @U38HVMZ6K: And also available as hardware IP easily integrated in FPGA or Hybrid-SoC
* _2017-02-17 20:18:42_> @U38HVMZ6K: Facts I :triumph: : Proprietary codec (not open source/community friendly) Only viewer is free, SDK and libs come at cost. 
* _2017-02-18 18:22:42_> @U37GZRZU6: <@U20C8CKTL> did you fix the leaderboard? I just tried to submit a .py, it looks like the upload is ok but then nothing appears in the leaderboard :disappointed:
* _2017-02-18 18:24:26_> @U37GZRZU6: <@U20C8CKTL> btw we should change "Submit your code for image denoising" to "Submit your code for envelope detection" :wink:
* _2017-02-19 12:46:46_> @U20C8CKTL: yes i have to change it
* _2017-02-20 17:48:25_> @U07UEJC2H: <@U07UEJC2H> and commented: A pool of files with last raw data can be found on PRJ-medtec_sigproc github repo (/dataquarium/raw_hand). We have now interesting images
* _2017-02-20 17:48:37_> @U07UEJC2H: <@U07UEJC2H>
* _2017-02-21 21:24:24_> @U20C8CKTL: hi, guys, you can investigate C embedded in python with this tutorial : <http://sametmax.com/appeler-du-code-c-depuis-python-avec-ctypes/>. (reactions: @U0AAL4W13)
* _2017-02-22 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-02-23 00:51:10_> @U20C8CKTL: hey, the leaderboard description and enhancement issues can be found here : <https://hackpad.com/Unti-fJao8eB2HPJ> feel free to improve the doc (in french) .
* _2017-02-23 01:14:11_> @U0B47KC3S: thanks <@U20C8CKTL> :wink:
* _2017-02-23 13:27:34_> @U1PAGSKGU: <@U1PAGSKGU> and commented: This is the first of a series of flowcharts where I detail the echograph.
* _2017-02-23 13:29:44_> @U1PAGSKGU: This is a buildup to our coming Wednesday meeting where we document the existing system.
* _2017-02-24 11:23:12_> @U492PCSE9: <@U492PCSE9> has joined the channel
* _2017-02-25 00:05:00_> @U3GHS132Q: <@U38HVMZ6K> about waaves it is not open source :s but I think that I can avoid or reduce the cost if I speak withh one of my prof which worked on this :slightly_smiling_face:
* _2017-02-26 16:39:13_> @U37GZRZU6: Nice slides gathering essential measurements for performance assessment of ultrasound imaging systems :wink:  <https://www.aapm.org/meetings/03AM/pdf/9905-9858.pdf> (reactions: @U0B47KC3S,@U38HVMZ6K)
* _2017-02-26 19:39:20_> @U38HVMZ6K: For performance and minimum requirements, many criteria are already defined in norms and standards: <https://www.fda.gov/Radiation-EmittingProducts/RadiationEmittingProductsandProcedures/MedicalImaging/ucm115357.htm> contains a huge amount of information for manufacturers, patients, physicians,... (reactions: @U37GZRZU6)
* _2017-02-26 19:42:56_> @U38HVMZ6K: <https://www.fda.gov/downloads/MedicalDevices/DeviceRegulationandGuidance/GuidanceDocuments/UCM070911.pdf> linked on that page contains detailed information on what should be submitted for pre-market clearance. This covers testing, performance, important figures to document, risks to consider,...
* _2017-02-26 19:46:20_> @U38HVMZ6K: By chance, ultrasound probes are now widely available and very precise guidances exist. For some other device kinds, requirements are not so precise and norms and standards need much more interpretation which is not always easy.
* _2017-02-27 20:07:40_> @U0AAL4W13: <@U37GZRZU6> I'm challenging your Hilbert approach with the <@U0GMX7QUB>  "track and hold" approach :smiley: <http://37.187.117.106:8888/feeds/48/> .
* _2017-02-27 20:08:01_> @U0AAL4W13: Ranked first - beat this :wink:
* _2017-02-28 00:50:20_> @U0B47KC3S: <@U0AAL4W13>, tried to go to the link but there is some issue with the web app
* _2017-02-28 10:13:11_> @U37GZRZU6: <@U0B47KC3S> I think you have to log in <http://37.187.117.106:8888/> (reactions: @U0B47KC3S)
* _2017-02-28 10:35:59_> @U0B47KC3S: <@U37GZRZU6> thanks !
* _2017-02-28 12:40:41_> @U20C8CKTL: <@U0AAL4W13>   <@U37GZRZU6> luc, really ? :smile: great !
* _2017-02-28 19:44:32_> @U0AAL4W13: A seemingly excellent paper : <http://home.ustc.edu.cn/~zhanghan/cs/Candes%20et%20al.06.pdf> - and my discovery of the "famous" Shepp–Logan phantom. <@U37GZRZU6> : a phantom to add to the test? :wink: (reactions: @U0B47KC3S,@U37GZRZU6)
* _2017-02-28 19:45:36_> @U0AAL4W13: ping <@U0B47KC3S> as you are the one studying this type of functions :smiley:
* _2017-02-28 20:12:34_> @U0B47KC3S: wouaou in fact radon transform and fourier transform are tigtly bound. my subject of interest is to reconstruct objects from an other type of partial knowledge. Btw, seing the authors, it should be major, candès + tao (infinite erdös number) = אzero  if I can help for the maths part, I am in :grinning: (reactions: @U37GZRZU6)
* _2017-02-28 21:19:12_> @U1PAGSKGU: This is now called compressive sensing. Relevant to us as we look into ways to reduce the sampling rate at the front end.
* _2017-02-28 21:19:53_> @U1PAGSKGU: It is already being used in MRI imaging (reactions: @U0B47KC3S,@U37GZRZU6)
* _2017-03-01 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-03-01 14:41:20_> @U1PAGSKGU: <@U07UEJC2H> <@U38TWKY9Y> <@U1PAGSKGU> testing probe at Echopen today as from 2:30 pm (reactions: @U37GZRZU6,@U20C8CKTL,@U0B47KC3S,@U37GZRZU6,@U37GZRZU6)
* _2017-03-01 16:58:39_> @U37GZRZU6: <@U20C8CKTL> I can't log in the leaderboard, is it down ? :sob:
* _2017-03-01 16:59:23_> @U20C8CKTL: nan
* _2017-03-01 17:00:21_> @U37GZRZU6: When I log in with my usual account, I get :  ```DoesNotExist at /login Site matching query does not exist. Request Method: POST Request URL: <http://37.187.117.106:8888/login> Django Version: 1.9.8 Exception Type: DoesNotExist Exception Value:  Site matching query does not exist. Exception Location: /usr/local/lib/python2.7/dist-packages/django/db/models/query.py in get, line 387 Python Executable: /usr/bin/python Python Version: 2.7.12 Python Path:  ['/root/echopen-leaderboard-1',  '/usr/lib/python2.7',  '/usr/lib/python2.7/plat-x86_64-linux-gnu',  '/usr/lib/python2.7/lib-tk',  '/usr/lib/python2.7/lib-old',  '/usr/lib/python2.7/lib-dynload',  '/usr/local/lib/python2.7/dist-packages',  '/usr/lib/python2.7/dist-packages']```
* _2017-03-01 17:01:01_> @U20C8CKTL: this is the debug option, it means, wrong password or something else.
* _2017-03-01 17:01:41_> @U20C8CKTL: i guess you try to broke someone else password (reactions: @U37GZRZU6)
* _2017-03-01 17:01:42_> @U20C8CKTL: XD
* _2017-03-01 17:02:07_> @U37GZRZU6: <@U20C8CKTL> stop calling me a hacker !! (reactions: @U20C8CKTL)
* _2017-03-01 18:50:41_> @U0B47KC3S: meeting is begining !
* _2017-03-01 18:54:16_> @U1PAGSKGU: <@U1PAGSKGU> and commented: Block diagram of signal transmission in the probe
* _2017-03-01 18:56:50_> @U1PAGSKGU: <@U1PAGSKGU> and commented: Block diagram of reception in the probe
* _2017-03-01 18:58:29_> @U1PAGSKGU: <@U1PAGSKGU> and commented: Block diagram of envelope detector
* _2017-03-01 19:01:48_> @U1PAGSKGU: <@U1PAGSKGU> and commented: Block diagram of image formation
* _2017-03-01 20:05:10_> @U0AAL4W13: <@U1PAGSKGU> found some interesting papers on compressive sensing : <http://asa.scitation.org/doi/abs/10.1121/1.4919302?journalCode=jas> by <https://www.researchgate.net/profile/Guillaume_David>
* _2017-03-02 12:17:19_> @U37GZRZU6: minutes of yesterday's meeting are available here : <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo/> <@U1PAGSKGU> <@U20C8CKTL>  <@U3QGT3Q74> <@U0B47KC3S> don't hesitate to modify it :wink:
* _2017-03-02 12:17:20_> @U37GZRZU6: <@U37GZRZU6>
* _2017-03-02 12:19:08_> @U1PAGSKGU: <@U0AAL4W13> Thanks. Looking to apply compressive sensing to solve the problem of high sampling rate and enveloppe detection at the front end.
* _2017-03-02 12:24:10_> @U0AAL4W13: <@U1PAGSKGU> cool! BTW, I'm using a adl5511 for enveloppe détection ( and did some tests with it) which seems to do a log compression -- which enable slower ADCs :) it could be tested as a benchmark / alternative to qualify the advantages of dsp enveloppe detection vs analog one. what do you think?
* _2017-03-02 23:58:22_> @U4DFR8RN3: <@U4DFR8RN3> has joined the channel
* _2017-03-03 00:59:23_> @U4CAG5ZFW: <@U4CAG5ZFW> has joined the channel
* _2017-03-03 17:14:15_> @U0AAL4W13: <@U0GMX7QUB>  did you get a chance to check your algo for enveloppe détection - the track and hold?
* _2017-03-03 17:14:49_> @U0AAL4W13: and to submit one of your tries ?
* _2017-03-03 18:57:18_> @U1PAGSKGU: <@U0AAL4W13> This seems to a board for doing enveloppe detection in the GSM RF ranges. A bit of an overkill, but if it is handy and low-cost then why not. If one can characterise its operation in a notebook, it will be handy to compare with the digital enveloppe detection in term of quality of the image we can get.
* _2017-03-03 19:04:20_> @U0AAL4W13: <@U1PAGSKGU> no that expensive - but I'm happy to pay for the reliability. I adjusted it to work at around 3.5MHz  and it seems to work.
* _2017-03-03 19:04:20_> @U0AAL4W13: 
* _2017-03-03 19:10:25_> @U1PAGSKGU: <@U0AAL4W13>  how to characterise its performance in a python notebook ?
* _2017-03-03 19:11:17_> @U0AAL4W13: <@U1PAGSKGU>  id be keen on doing the measurements would you have any tips
* _2017-03-03 19:13:21_> @U1PAGSKGU: <@U0AAL4W13> I think a mathematical description of its operation from the litterature should be the starting place to build a python notebook of performance.
* _2017-03-03 19:56:26_> @U0AAL4W13: <@U1PAGSKGU> the datasheet should have this
* _2017-03-03 20:39:08_> @U0AAL4W13: <@U0AAL4W13>
* _2017-03-03 20:39:24_> @U0AAL4W13: <@U1PAGSKGU> here's what the adl5511 does in practice
* _2017-03-06 09:46:57_> @U1PAGSKGU: <@U0AAL4W13> It is cool that this card does the enveloppe detection. What kind of image it produces is the question.
* _2017-03-06 12:25:56_> @U0AAL4W13: <@U1PAGSKGU> sure - this is the kind :) <https://raw.githubusercontent.com/kelu124/echomods/master/include/20160814/sonde3V_1-4.csv-SC.png> it's tough to quantify as this includes tgc, enveloppe detection and amp
* _2017-03-06 12:25:56_> @U0AAL4W13: 
* _2017-03-06 12:33:45_> @U0AAL4W13: <@U1PAGSKGU> it would be worth it sending a know signal and record (at v high speed) both input and output to quantify the perfs of the overall board
* _2017-03-06 12:57:55_> @U0AAL4W13: will do a modélisation though using the specs
* _2017-03-06 14:49:36_> @U0AAL4W13: tricky, the specs just mention envelope detection - not possible to extract a python friendly model 
* _2017-03-06 15:18:53_> @U1PAGSKGU: <@U0AAL4W13> maybe if you record the raw data before enveloppe detection and then do an enveloppe detection offline. Compare the offline digital enveloppe detection with the online analog detection. That should be a way to compare and contrast.
* _2017-03-06 15:35:55_> @U0AAL4W13: the issue is I don't have the tool to do this :/ anyhow, will try! do you think 10msps at acquisition could be enough ? that's the max I could do :/
* _2017-03-06 15:36:24_> @U0AAL4W13: with a long enough acquisition I could also get the transfer function
* _2017-03-06 20:34:18_> @U0AAL4W13: <@U1PAGSKGU> managed to try a significant acquisition with the prudaq, the results are here: <https://github.com/kelu124/echomods/tree/master/toadkiller/data/test_enveloppe>
* _2017-03-06 20:34:40_> @U0AAL4W13: I can't really do a diff between the two because of the gain which is a bit high between the two signals
* _2017-03-06 20:54:38_> @U0AAL4W13: <@U1PAGSKGU> managed to try a significant acquisition with the prudaq, the results are here: <https://github.com/kelu124/echomods/tree/master/toadkiller/data/test_enveloppe> . The diff does not work as there is a significant gain between input and output.  Data file is also available, and the code to show how the signal were images is at <https://github.com/kelu124/echomods/blob/master/toadkiller/data/test_enveloppe/In-Out.ipynb>
* _2017-03-06 22:38:44_> @U37GZRZU6: <@U0AAL4W13> what am I looking at? Is this what is achieved with the adl5511?  BTW <@U0AAL4W13> <@U1PAGSKGU> it's a really good idea to challenge analog vs. digital envelope detection :wink: however I think the performances of one or the other depends : 1. on the device that is used for analog envelope detection (so the question is : is this adl5511 supposed to be tested on the echopen kit? if not, I'm not sure we'll get any re-usable information from your tests) 2. on the quality of the raw signal : if it's more or less noisy, the digital/analog envelope detection might not be impacted in the same way --&gt; even if the adl5511 could be used on the echopen kit, I doubt that doing such tests on a raw signal which is out of a different acquisition chain will be informative…  What do you think guys? Question : could we plan that kind of tests with the echopen kit (which by the way has been discussed not a long time ago --&gt; it's one of our next steps actually :wink: )
* _2017-03-06 22:49:42_> @U0AAL4W13: <@U37GZRZU6> it's the input of the board (TGC,ADL5511,AOP), not the ADL5511 only. It's definitely usable with the kit - for example plugging the board which hosts the ADL5511 on the same line coming from the transducer :smiley: . BTW, as said, it does not exist to replace a DSP+60Msps ADC, rather to give a benchmark for a analog option, which could  give insights to estimate the complexity vs quality balance.
* _2017-03-06 22:50:03_> @U0AAL4W13: so 1. yup, sure.
* _2017-03-06 22:51:04_> @U0AAL4W13: 2. Having a "standard" signal on which the different processing solutions can be used can be useful to determine the quality of each processing chain. If you dont' have a repeatable input, it may be difficult to standardize the tests :smiley:
* _2017-03-06 22:51:43_> @U0AAL4W13: -&gt; Tests are most doable with the kit (i could leave one board at the HD for example)
* _2017-03-07 11:20:21_> @U1PAGSKGU: <@U0AAL4W13> how do i copy this directory to my laptop ? The clone command is not working for this directory
* _2017-03-07 11:30:44_> @U07UEJC2H: <@U37GZRZU6>, <@U0AAL4W13>, @ soobash, Hilbert transform don't have to be challenged because Hilbert transform give true envelope (following mathematical definition) so you can't do better (envelope). ADL5511 is an overkill (bandwidth), expensive and can not be solder with our tools. It can be tested to see the performances, but it not match with low cost constraint.
* _2017-03-07 11:37:31_> @U0AAL4W13: It's true it's expensive (12$) - still can be used to benchmark. Moreover, with analog envelope detection you may not need high speed adc + dsp, which in turn are also expensive (and tough to program, not to mention solder too!).
* _2017-03-07 11:38:16_> @U0AAL4W13: After, it's true the performance of this chip can't beat a very high speed adc + dsp .
* _2017-03-07 11:39:24_> @U0AAL4W13: Hey <@U1PAGSKGU> - the bin file, as well as either the python file or the jupyter notebook are sufficient 
* _2017-03-07 11:39:56_> @U0AAL4W13: However, if you want to clone this, you may need to clone the full repo (echomods)
* _2017-03-07 11:51:33_> @U1PAGSKGU: Thanks.
* _2017-03-07 11:59:24_> @U1PAGSKGU: <@U07UEJC2H> It's true the Hilbert Transform in DSP cannot be challenged in term of quality. Can we get a high speed adc + dsp within the same cost constaint ? (reactions: @U0AAL4W13)
* _2017-03-07 13:31:26_> @U0AAL4W13: <@U1PAGSKGU> à piece of info: the input signal is at 2mhz since I had no faster dac.
* _2017-03-07 13:37:03_> @U0AAL4W13: The capas used on the adl5511 to set it up are adjusted for 3.5MHz - hence the jiggling enveloppe is due to the input frequency that is lower than the target carrier
* _2017-03-07 14:15:44_> @U07UEJC2H: <@U0AAL4W13>, don't put words in my mouth, I didn't say that we must not make analogical envelope detection (which can reduce cost), just that adl5511 don't fit with low cost. <@U1PAGSKGU>, we have to search what we can obtain,  image quality is the priority target
* _2017-03-07 15:39:47_> @U38HVMZ6K: I'm a bit lost again regarding the direction we want to take... Do we want to develop a medical device or another maker kit ? We need to find some compromises because all the constraints specified for the device cannot all be fullfilled... If 12$ is too expensive and the fact that the chip cannot be easily soldered by a maker is a hard requirement then we should directly forget the idea of building a compact and performant device and build "yet another Ultramark".
* _2017-03-07 15:43:05_> @U38HVMZ6K: Putting all requirements I heard about in a very simple and exagerated way we would like: - to do high speed acquisition (50-100MHz) - handle 15 fps - keep costs at the lowest - use only hacker-friendly chips and components - fit everything in a housing which can be held with only one hand
* _2017-03-07 15:54:48_> @U0B47KC3S: hi there, sorry <@U38HVMZ6K> it can be quite misleading
* _2017-03-07 15:54:55_> @U0B47KC3S: First, the aim of echOpen is to build a medical device, we can stress the fact that it is the core objective of echOpen
* _2017-03-07 15:55:02_> @U0B47KC3S: Second, we are working hard with <@U04DFTZ7D> and <@U37GZRZU6> and anybody that wants to join to implement concretely all the decisions that we took in the CapMeth meeting. In about 3 weeks, we will have deployed the main methodologies and global technical config informations, and from next week, we will begin to structure the meetings conformally with these methodologies
* _2017-03-07 15:55:08_> @U0B47KC3S: So, for the moment we still have some divergent informations which is quite normal since the working groups don’t already have the right materials to focus on the medical device. Besides, as soon as the methods will be implemented in groups, we'll program a global CapTech to harmonise and fix the main trimestrial objectives, this would be the perfect time for the discussions we have just had in this feed  :wink: !
* _2017-03-07 16:14:05_> @U0AAL4W13: Don't forget to include the overall, multi-year plan ;)
* _2017-03-07 16:29:25_> @U0B47KC3S: sure, just talking about the very next steps
* _2017-03-07 22:19:00_> @U0AAL4W13: Always great to see how the small steps pave the way to the bigger picture ;)
* _2017-03-08 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-03-08 18:52:22_> @U2PFHNN3C: Hey guys, to meet or not to meet? That is the question: …
* _2017-03-08 18:54:29_> @U20C8CKTL: will be there in 45mn
* _2017-03-08 18:59:53_> @U0AAL4W13: In da bus, here in 15 mins
* _2017-03-09 00:22:19_> @U0B47KC3S: here’s the report of the <#C1G7T0PNX>
* _2017-03-09 00:22:21_> @U0B47KC3S: <@U0B47KC3S>
* _2017-03-10 14:03:53_> @U1PAGSKGU: <@U0AAL4W13> 2 Mhz is too low to have a usable signal for the hilbert transform.
* _2017-03-10 14:28:27_> @U1PAGSKGU: Assuming you have a 50% bandwidth, that gives 1.75 MHz bandwidth centered on 3.5 MHz. Nyquist abndpass sampling is ta a rate of 3.5 MHz. If you are using 2 MHz sampling you will have aliasing.  If your adc is fied at 2 MHz , one solution would be to reduce your bandwidth further by bandbass filtering to something at or below 1 MHz.
* _2017-03-10 14:33:48_> @U0AAL4W13: <@U1PAGSKGU> : well noted! the adc I have is at 10msps when capturing raw signal (the bin file)
* _2017-03-10 14:34:11_> @U0AAL4W13: The 2mhz is for the digital to analog tool I'm using, I have no better :/
* _2017-03-10 14:34:34_> @U0AAL4W13: Soon the signal recorded is at 10msps (edit: so there should be no aliasing / signal folding)
* _2017-03-10 14:35:10_> @U0AAL4W13: I'm acquiring at 2msps only on the post enveloppe detection stage
* _2017-03-10 14:35:20_> @U0AAL4W13: Hope that clarifies
* _2017-03-10 14:40:53_> @U0AAL4W13: So to come back to hilbert - I'm not doing any, but, knowing the sampling frequency on the binary file, one could possibly try
* _2017-03-14 15:56:36_> @U4J138ZTL: <@U4J138ZTL> has joined the channel
* _2017-03-15 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-03-15 18:29:27_> @U2PFHNN3C: So what time guys?
* _2017-03-15 19:51:01_> @U2PFHNN3C: ???
* _2017-03-15 20:39:22_> @U0AAL4W13: yup?
* _2017-03-15 21:21:56_> @U2PFHNN3C: nothing :slightly_smiling_face: was just waiting for the meeting to start
* _2017-03-16 09:24:39_> @U0B47KC3S: 15.03.17 SigProc report <https://docs.google.com/document/d/1kn_oJnskOg4OONO4MK5Ft724OLPkn4NYzj-qJHVMMXo/edit>
* _2017-03-16 09:24:39_> @U0B47KC3S: <@U0B47KC3S>
* _2017-03-16 13:57:24_> @U4J138ZTL: <@U4J138ZTL> and commented: Found a great article on envelope detection for DSP processing
* _2017-03-16 14:18:27_> @U0B47KC3S: <@U4J138ZTL> seems to be nice article, do they provide some code ?
* _2017-03-16 18:01:52_> @U4J138ZTL: <@U4J138ZTL> and commented: Et Voilà !
* _2017-03-16 18:11:58_> @U4J138ZTL: can you read this ? I can also send python code/jupiter Notebook.
* _2017-03-22 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-03-22 19:48:49_> @U37GZRZU6: Hey guys, we're about to launch the envelope detection challenge, but we need some backup to finalize the score assessment on the leaderboard (python+django), it might not need more than 1hour of development... Would someone have some spare time this week to help us?? ping <@U2PFHNN3C> <@U3GHS132Q> <@U0AAL4W13> :hatching_chick: :blush: :heart_eyes: :smiley_cat: :wink:
* _2017-03-22 20:02:47_> @U2PFHNN3C: Just became available. Is it late for the meeting?
* _2017-03-22 20:03:21_> @U2PFHNN3C: aurelie: can you please elaborate on the task at stake​?
* _2017-03-22 20:40:51_> @U0B47KC3S: sorry <@U2PFHNN3C> I have just seen your post ! we finished 30mn ago and we are going to finish the <#C3F765DT7> meeting !
* _2017-03-22 20:41:13_> @U2PFHNN3C: :disappointed: sorry, I was with a colleague and didn’t look at the clock
* _2017-03-22 20:54:49_> @U37GZRZU6: Ping <@U20C8CKTL> :D by now the score is computed on the same image that is used in the notebook, we want to replace it by a loop that allows to evaluate the score on several images and then compute the average... Not that difficult to implement though, we just don't have time :/
* _2017-03-23 00:27:01_> @U0B47KC3S: no worry <@U2PFHNN3C> :wink:
* _2017-03-23 00:27:22_> @U0B47KC3S: Here’s the report of 22.03.17 SigProc meeting <https://echopen.gitbooks.io/echopen_prototyping/content/followup/meetings_sigproc.html> (reactions: @U2PFHNN3C,@U3QGT3Q74,@U37GZRZU6)
* _2017-03-23 13:18:14_> @U20C8CKTL: Aurelie i suggest you to create a github issues. in github.
* _2017-03-23 15:09:10_> @U3GHS132Q: I do not know python so I do not think that I will be useful... But I can try do it next week :slightly_smiling_face:
* _2017-03-23 15:18:40_> @U20C8CKTL: <@U3GHS132Q> i can share the python basics and django basics with you next week. 1 april. :smile: it can be an open stuff with other people too. (reactions: @U37GZRZU6)
* _2017-03-23 16:10:49_> @U2PFHNN3C: The Github issue is a good idea <@U20C8CKTL>. It provides clarity and allows to keep track of the changes. If the 1st of April is not late, let’s work on that then
* _2017-03-23 16:12:59_> @U20C8CKTL: <@U2PFHNN3C>  ok !!! good !
* _2017-03-24 10:20:22_> @U3GHS132Q: <@U20C8CKTL> I know a bit of python (basic scripting and object programming) but I never used django.
* _2017-03-24 11:15:50_> @U20C8CKTL: <@U3GHS132Q> i think it's enought to understand django basics
* _2017-03-24 12:33:28_> @U20C8CKTL: bon, on est tous français dans le thread :slightly_smiling_face:, je vais vous envoyer une petite note ce week end avec les grandes lignes du principe de django et des concepts à connaitre. ça reste du web quand même. ça peut plaire comme ça peut ne pas plaire. :smile:
* _2017-03-26 19:36:45_> @U0AAL4W13: About the enveloppe detector, someone had earlier spoken about the LTC5507ES6 -- that's easier to solder, that's 3.6$, and in a TSOT-23-6  package
* _2017-03-27 12:51:09_> @U3GQS8JTZ: <@U3GQS8JTZ> has left the channel
* _2017-03-27 22:09:46_> @U0AAL4W13: Interesting read at <http://www.rochester.edu/newscenter/new-needle-pulse-beam-pattern-packs-a-punch-212412/> :smiley:
* _2017-03-29 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-04-05 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-04-05 15:09:43_> @U0AAL4W13: <@U37GZRZU6> sigproc maintained?
* _2017-04-05 15:11:38_> @U37GZRZU6: <@U0AAL4W13> yes :+1: on the agenda : documentation, yeeees :smile:
* _2017-04-05 23:20:32_> @U20C8CKTL: it would be interesting to compare udp to tcp or bluetooth speed and redpitaya or other soc load. we don't all the anticollision stuff as the discussion is between probe  and redpitaya. IMHO
* _2017-04-05 23:22:50_> @U3GHS132Q: Energy matters too
* _2017-04-05 23:22:58_> @U0AAL4W13: Unsure if that's really a bottleneck.. and doesn't really compare as there's no integrity check
* _2017-04-05 23:23:29_> @U20C8CKTL: <@U0AAL4W13> <@U3GHS132Q> ok
* _2017-04-05 23:29:52_> @U3GHS132Q: Moreover the formula for bandwith bottleneck is simple : We have to send `lines * samples * sizeof_bit(sample) * fps`  In our case :  * lines = 64, * samples = 1024, * samples are 2 bytes so 16 bits * fps = 15 because we want to show 15 frames per second  So the bandwith of the communication medium have to be greater than : 15 728 640 bits per second (we can approximate to 16 Mbps).
* _2017-04-05 23:33:37_> @U0AAL4W13: That's FAAT
* _2017-04-06 12:12:24_> @U38HVMZ6K: <@U3GHS132Q> `lines * samples * sizeof_bit(sample) * fps` is the size of raw useful payload data you want to transmit! Don't forget the overhead introduced by: - Link layer (MAC for WiFi or Ethernet, Bluetooth headers for BT) - Network layer (IP headers) - Transport layer /TCP or UDP)
* _2017-04-06 12:12:59_> @U38HVMZ6K: by experience, UDP is always the best choice for soft real-time applications (video, imaging,...)
* _2017-04-06 12:15:25_> @U38HVMZ6K: TCP not only has more overhead (bigger headers) but typically also more latency (ACK packets, higher bufferization, packets reordering, back-off times,...)
* _2017-04-06 12:16:49_> @U38HVMZ6K: Real-time data are then best transmitted over UDP but UDP offers far less functionalities and needs either a custom protocol on top of it to be able to detect lost packets, handle synchronization and re-synchronization after a lost packet,...)
* _2017-04-06 12:18:36_> @U38HVMZ6K: There are also standardized protocols like RTP (<https://en.wikipedia.org/wiki/Real-time_Transport_Protocol>) which specifies and implements a standard on top of UDP to handles all these issues.
* _2017-04-06 12:19:06_> @U38HVMZ6K: RTP is used a lot in Voice/Video over IP and other video streaming protocols/applications
* _2017-04-06 12:22:19_> @U38HVMZ6K: Moreover, RTP is used as the transport layer for WebRTC (<https://en.wikipedia.org/wiki/WebRTC>) which could be of interest in the long term.
* _2017-04-06 12:23:56_> @U38HVMZ6K: For a medical application, SRTP (the secured/encrypted version of RTP) has to be used: <https://en.wikipedia.org/wiki/Secure_Real-time_Transport_Protocol> (reactions: @U0AAL4W13,@U3GHS132Q)
* _2017-04-06 13:38:06_> @U3GHS132Q: <@U38HVMZ6K> Of course but if we can not provide the bandwith defined by the formula we are in deep trouble and have to think to other medium. SRTP seems interesting, it seems that Cisco provides an open source implementation <https://github.com/cisco/libsrtp> ?
* _2017-04-06 13:43:42_> @U3GHS132Q: And it is available on Ubuntu through apt <https://launchpad.net/ubuntu/+source/srtp> :smile: :smile: :smile:
* _2017-04-06 17:20:13_> @U38HVMZ6K: <@U3GHS132Q> &gt; if we can not provide the bandwith defined by the formula we are in deep trouble and have to think to other medium. sure, the base formula says us that we would need a datalink with a bandwidth &gt;=20Mbps (acounting for headers overhead, underuse of packet size,...)
* _2017-04-06 17:24:34_> @U38HVMZ6K: this tell us right away that Bluetooth is not an option (max 3Mbps in very very best case) and that WiFi should fit but not 802.11b (11Mbps) only 802.11g (54Mbps) or 802.11n (150-600 Mbps)
* _2017-04-06 17:43:03_> @U0AAL4W13: Or using a USB cable maybe? ;)
* _2017-04-06 17:44:04_> @U3QGT3Q74: Also don't forget we can use encoding that can divide by 10 bandwidth requirements
* _2017-04-06 17:45:09_> @U0AAL4W13: Soon many options, implications, and checks for compliance to do !
* _2017-04-06 17:46:30_> @U38HVMZ6K: yep. encoding/compression is an option. And I'm not sure that we need to transmit the raw acquired data or if processing is done on the probe and we only send a video stream...
* _2017-04-06 17:47:05_> @U38HVMZ6K: I'm not up to date with the latest discussions/decisions on where processing is done (on the probe vs on the smartphone)
* _2017-04-06 17:47:34_> @U38HVMZ6K: if done on the probe we can drastically reduce the bandwidth as well
* _2017-04-06 17:48:17_> @U3QGT3Q74: 'envelop detection' is currently done on mobile app but it will be definitely done on embed part in the end. I let <@U37GZRZU6>  confirm (reactions: @U37GZRZU6)
* _2017-04-06 17:49:12_> @U38HVMZ6K: compression/encoding is often tricky and needs a good deal experimentation on size gain vs compression/encoding time to avoid too big latencies or bad quality images
* _2017-04-06 17:51:18_> @U38HVMZ6K: realtime/on-the-go encoding is difficult whenever possible without hardware support
* _2017-04-06 17:52:17_> @U38HVMZ6K: the embedded processor on the probe should then have an hardware codec for encoding in real-time without impacting (too much) CPU load
* _2017-04-06 18:29:49_> @U3GHS132Q: What is the difference between encoding and compressing ? Moreover is we compress the data we have to decompress it when received and the cost for uncompressing can not be neglected.
* _2017-04-06 20:32:30_> @U38HVMZ6K: Encoding and compression achieve the same goal (reduce data size or bandwidth) but they do it in different ways.
* _2017-04-06 20:36:19_> @U38HVMZ6K: Compression like zip, gzip, lzma,... are used to compress data independently of the payload being compressed. You can compress anything (images, sound files, text files,...) with a compression algorithm/tool. Compression algorithms are most of the time lossless (you can retrieve an exact copy of the original file after decompression).
* _2017-04-06 20:38:32_> @U38HVMZ6K: Encoding is most often "aware" of the content, its format, its semantics,... The encoding algorithm then uses some specificities of the format to derive a smaller file but this is often with some loss in quality.
* _2017-04-06 20:43:04_> @U38HVMZ6K: For example, MP3 audio encoding, among others tricks, removes some audio frequencies (not hearable frequencies by most humans) of the original file to reduce its size. In this case encoding is not lossless (you definitely lost some information you will never be able to retrieve again).  (reactions: @U20C8CKTL,@U2PFHNN3C)
* _2017-04-06 21:06:47_> @U37GZRZU6: :clap: thanks <@U38HVMZ6K> for this very interesting lecture :smiley:  (reactions: @U2PFHNN3C)
* _2017-04-06 22:01:08_> @U3GHS132Q: Thank you for the reminding.
* _2017-04-06 22:02:41_> @U3GHS132Q: Sometimes I should do work the coffeepot which serves me as a head before asking something &gt;&lt;
* _2017-04-07 10:36:05_> @U07UEJC2H: <@U3QGT3Q74>, yes for the moment the envelope detection is made by the app, but in the future it will be done in the device and we "resampling" at a smaller frequency each line to reduce data amount to sent (and/or compression/encoding)
* _2017-04-07 21:09:25_> @U20C8CKTL: <@U2PFHNN3C> <@U37GZRZU6> i work for a customer on object detection, and i have on trivial question for you : do you consider haar training a good method for object detection ?
* _2017-04-07 21:25:52_> @U37GZRZU6: I don't know this one :D I'm not an expert at all in object detection, but usually we try different models and find a way to compare the performances! I let master <@U2PFHNN3C> give his holy advice ;) (reactions: @U20C8CKTL)
* _2017-04-09 15:00:34_> @U2PFHNN3C: Hey guys, dunno why, Slack was not notifying me, so I just saw your messages :disappointed:. Haar filters + AdaBoost was the state of the art in real-time detection, especially combined with cascaded architecture (cf. Viola-Jones cascade and the 100 papers that followed that up :slightly_smiling_face: ). I think today, you should simply go by a ConvNet :slightly_smiling_face: depending on your other constraints (reactions: @U37GZRZU6,@U20C8CKTL)
* _2017-04-10 08:45:48_> @U0AAL4W13: <@U0AAL4W13> and commented: luc 8:44 AM if some unprocessed images are needed (or videos) one can use this as a benchmark from the chinese single element probe  :smiley:
* _2017-04-10 11:27:32_> @U0B47KC3S: you mean it is non scan converted image ?
* _2017-04-10 11:36:53_> @U0AAL4W13: Yup
* _2017-04-10 11:40:55_> @U0B47KC3S: what image this corresponds to ?
* _2017-04-10 12:48:57_> @U0AAL4W13: Pebble like potatoes (1cm dia) in a glass of water. Did not have the time to scan convert it though. Images are 128x512
* _2017-04-11 21:56:07_> @U0AAL4W13: (viewable as well as a DICOM at <http://www.dicomlibrary.com/meddream/?study=1.2.826.0.1.3680043.8.1055.1.20170411215409237.878569250.8160869> :smiley: )
* _2017-04-12 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-04-12 13:30:20_> @U20C8CKTL: the git-flow branching model. very usefull for software developpement : <http://nvie.com/posts/a-successful-git-branching-model/>
* _2017-04-12 13:31:29_> @U38HVMZ6K: <@U20C8CKTL>: yep very useful. I talked about it in the <#C0KP6DWSG> channel when discussing git work flows we could use
* _2017-04-12 13:31:53_> @U38HVMZ6K: I used this flow on several projects and it was nice and clear
* _2017-04-12 13:32:05_> @U20C8CKTL: <@U38HVMZ6K>  ok. i missed that.
* _2017-04-12 13:34:47_> @U38HVMZ6K: the issue for us is that the flow is based on branches and not on forks+pull requests which was chosen for echopen
* _2017-04-12 13:35:32_> @U38HVMZ6K: it can be adapted but the philosophy is a bit different
* _2017-04-12 13:37:17_> @U20C8CKTL: a yes, i guess theses fork could be integrated  with the pink side of the tree, in features.
* _2017-04-12 13:39:02_> @U38HVMZ6K: yep and merges from pink to yellow are done through pull requests and not git merges between branches
* _2017-04-12 13:39:31_> @U20C8CKTL: yes
* _2017-04-12 14:18:06_> @U3GHS132Q: &gt; the issue for us is that the flow is based on branches and not on forks+pull requests which was chosen for echopen I am not sure but I do no think that fork/pull request has to be the workflow for all team. I remember that <@U37GZRZU6> said that each team can organize like they want (while it is working of course)
* _2017-04-12 14:21:27_> @U38HVMZ6K: Yes but not using fork+pull request implies that you have to give write access to anyone wanting to contribute which is also not necessarily a good idea.
* _2017-04-12 14:24:06_> @U37GZRZU6: (why is this discussion happening in the sigproc channel? I think it would interest all medtec contributors :wink: )
* _2017-04-12 14:25:00_> @U38HVMZ6K: <@U37GZRZU6>, it's a natural deviation from <@U20C8CKTL> initial post on git-flow :slightly_smiling_face:
* _2017-04-12 14:31:52_> @U37GZRZU6: Indeed I proposed that each team organizes as they want, but I agree with <@U38HVMZ6K> as regards write access. Actually the team structure we adopted is naturally suited for fork+PR workflow (with at least one maintainer per team who's in charge of reviewing PRs) and this is the workflow I described in our prototyping notebook <https://echopen.gitbooks.io/echopen_prototyping/content/howto/method.html>  That being said, I think you guys are more used to github workflows than I am, for this reason nothing is written in stone and we might change workflows depending on your needs/opinions in the future :wink: (reactions: @U38HVMZ6K,@U0AAL4W13)
* _2017-04-12 14:37:49_> @U3GHS132Q: Ok, I change the workflow for embsys team to use the same as Linux kernel ! What ? Are you saying that me it is approximately the same as the one we use but instead of pull request they send patch through mailing list ? --&gt;[]
* _2017-04-12 14:39:27_> @U0AAL4W13: aurelie: hum sometimes I see you pushing straight to main répo ? ... ;)
* _2017-04-12 14:39:44_> @U20C8CKTL: LOOOOOL, délatiooooon ! :smile:
* _2017-04-12 14:45:14_> @U38HVMZ6K: well, the Linux work flow is not as simple as sending patches (~=pull-requests) to a mailing-list. It's a whole hierarchical infrastructure with many subsystems, many maintainers, many mailing-lists and git trees organized in a very structured way. The holy grail is Linus mainline repository (<https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git>) but to get your code there you first have to go through several layers of mailing-lists, reviews, patches iterations,...
* _2017-04-12 14:46:38_> @U37GZRZU6: yes indeed <@U0AAL4W13> , only for the prototyping gitbook, not for contributing repos! this is to avoid sending a PR at the least correction I do, but if you want I can make you maintainer of the prototyping gitbook and send you a PR each time I write a character in the gitbook?  :slightly_smiling_face:
* _2017-04-12 14:46:44_> @U38HVMZ6K: <https://git.kernel.org/> gives the full list of parallel git trees used for Linux kernel and tools development
* _2017-04-12 14:47:32_> @U38HVMZ6K: amazing how such a jungle of repositories can lead to state-of-the-art software! The only reason it works is: discipline and clear processes
* _2017-04-12 14:49:59_> @U20C8CKTL: <@U37GZRZU6>  maybe be it can be possible to use an automatic pr merging. because by doing master commit  you lose the automatic issus closing when you comment your pr with #issus_number (reactions: @U37GZRZU6)
* _2017-04-12 14:50:06_> @U0AAL4W13: Humppf let's discuss it tonight ? ;)
* _2017-04-12 14:52:03_> @U3GHS132Q: I do not need you to explain me something that I already know lol
* _2017-04-12 14:53:59_> @U37GZRZU6: <@U20C8CKTL> if you know how to do that I'd go for that :wink: however now I find the idea funny of ringing <@U0AAL4W13> each time I write a new sentence in the gitbook, hope he will applaude :stuck_out_tongue: (reactions: @U3GHS132Q,@U20C8CKTL,@U20C8CKTL)
* _2017-04-12 20:10:19_> @U4YCKBDR8: <@U4YCKBDR8> has joined the channel
* _2017-04-12 23:34:03_> @U0AAL4W13: Code to create this DICOM comes from <https://github.com/kelu124/kina/blob/master/20170411-DICOM.ipynb> . The previous notebook was showing what is in the arrays. ping <@U20C8CKTL> <@U1PAGSKGU> <@U37GZRZU6> when it comes storing images / raw data -&gt; DICOM may very well be the place to be.
* _2017-04-14 02:42:19_> @U4YF0KAJU: <@U4YF0KAJU> has joined the channel
* _2017-04-19 09:50:22_> @U0AAL4W13: Last week we were discussing data format, considering dicom  as a format . Here are some notes of quite some time ago too :  <http://wiki.echopen.org/index.php/Challenge:_Data_format#Solution:_Common_rules_for_structuring_raw_data>
* _2017-04-19 09:50:42_> @U0AAL4W13: I believe this may well still be a challenge today, agreeing on a data format
* _2017-04-19 09:54:39_> @U0AAL4W13: (BTW dicom can store both raw signal or raw image as it just encapsulate data)
* _2017-04-19 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-04-22 16:17:09_> @U4J138ZTL: I did my first pull request !!! <@U37GZRZU6> <@U37GZRZU6> <@U37GZRZU6> (reactions: @U0AAL4W13,@U0B47KC3S,@U37GZRZU6,@U37GZRZU6)
* _2017-04-22 16:17:49_> @U4J138ZTL: :tada:
* _2017-04-26 12:00:00_> @USLACKBOT: Reminder: :mega: a memo for our weekly meeting  on wednesday.
* _2017-04-26 12:13:34_> @U0AAL4W13: Some remarks on image metrics for tonight at <https://github.com/kelu124/echopen_prototyping/blob/master/inprogress/IMGQ_metrics.md> ( pull request en progress)
* _2017-05-01 18:09:07_> @U0AAL4W13: for some images datasets: <ftp://medical.nema.org/medical/dicom/DataSets/WG12/> :wink:
* _2017-05-01 18:26:01_> @U0AAL4W13: <@U0AAL4W13> and commented: With the same ADC, getting the signal, and comparing digital solutions (Hilbert and BiVi transform) vs analog solutions.
* _2017-05-01 18:29:12_> @Hyacinthe: <@U0AAL4W13>: Getting the amplified signal, and comparing the digital vs analog envelope detection. Signal and envelope have been acquired by the same device.
* _2017-05-01 21:31:29_> @U0AAL4W13: <@U37GZRZU6> I'm using Aeskulap on Linux btw for viewing the DICOMs
* _2017-05-02 12:18:35_> @U20C8CKTL: hi , after some discussion with <@U3QGT3Q74>  and <@U0AAL4W13> i think we need some data aqcuisition and storage strategy. for instance we need ultrasonic raw images, without annotation, and this task is not easy.
* _2017-05-02 12:19:17_> @U20C8CKTL: i will open an issues(projet?), on it if <@U37GZRZU6> is agree and i will take the lead on this topic. (reactions: @U0AAL4W13)
* _2017-05-02 12:37:49_> @U0AAL4W13: <@U20C8CKTL> do you think dicom would be the good format?
* _2017-05-02 12:39:35_> @U38HVMZ6K: Data acquisition and storage on the device or in the backend to store data from experiments in a "library" ?
* _2017-05-02 12:42:18_> @U20C8CKTL: <@U38HVMZ6K>, <@U0AAL4W13> 1- ultrasonic images from our protoype and from outside build in the dicom format (best), or at least bmp images, in a ftp. The dicom library in python is outdated.
* _2017-05-02 12:44:45_> @U3GHS132Q: &gt; storage on the device For me storage as to be on the smartphone/tablet/whatever_which_is_used_to_see_the_pictures
