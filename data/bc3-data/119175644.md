#  Fréquence d'échantillonnage

Hyacinthe posted this May 03, 2016 at 3:58 PM

Suite à la réunion d'hier et de la discussion sur les fréquences
d'échantillonnages minimales envisageable, j'ai une petite simulation pour
comparer sur une même mesure (simulée) ce qu'on pourrait obtenir à 1, 2, 5 et
10 MHz de fréquence d'échantillonnage.  
Les résultats sont présentés dans ce document :  
<https://docs.google.com/document/d/104kDzqOb0_KzRr_Bt8KVuewdHG0HHP8LoOVddI_69Kk/edit>  
Ici on ne considère que l'enveloppe du signal pas le signal complet (sinon on
serait vraiment en sous-échantillonnage). Et on considère un système parfait :
pas de bruits et pleine échelle de l'ADC.  
  
Conclusions rapides :  
\- 1 MHz clairement insuffisant  
\- 10 MHz largement bon  
  
Pour moi le mieux est 5 MHz.

### **Hyacinthe Lacenne** - May 03, 2016 at 4:38 PM

Excellent modèle, intéressant! Pour clarifier, est ce que le signal (en vert)
correspond bien à l'enveloppe? A ce signal s'ajoute les déformations liées
transducteur et celle également du détecteur d'enveloppe?  
  
Pour compléter, purement en termes de physique, en termes de vitesse on est
bien à du c/2 -&gt; pour résoudre 1mm spatialement, l'onde doit parcourir 2mm
(1 AR).  
\- A cette fréquence, on a donc 1us (sampling a 1MHz) = 0.75mm d'image.  
\- A l'autre extrémité de l'échelle, on peut résoudre à la profondeur de la
focale à la louche .25mm, ce qui donne en termes de sampling du 3MHz.  
Tu me corriges si faux?  
  
Donc, peut on postuler que, dans le cadre de la détection d'enveloppe
analogique :  
\- 1MHz est trop juste (tout juste à 1.333 pts / mm, ce qui est trop
borderline mais dans les specs aujourd'hui)  
\- à 2MHz tu es à 2.66 pts / mm ce qui n'est pas top mais te permet de voir
les grosses structures, à une resolution dans les specs  
\- a 5MHz, le signal est pas mal (6.7px/mm)  
\- a 10MHz, 3 fois la fréquence de la porteuse, il y a un bon fit, et a cette
fréquence, le besoin d'une détection d'enveloppe analogique commence a
s'estomper.  
  
Bref, différentes fréquences, différents usages.  
  
Avec ce script, est il possible de quantifier l'erreur de mesure sur le signal
en termes d'erreur / signal sur la longueur de la ligne ?  
  
Ceci ne prend bien sur en compte que l'aspect enveloppe : à ces fréquences on
ne parle bien sur pas de traitement du signal =)  
  
J'essaye assez vite de faire un petit comparatif sur les images acquises à
5MHz, histoire de comparer les images à 1, 2 et 5 Msps =)

### **Hyacinthe Lacenne** - May 03, 2016 at 7:43 PM

En image : <https://github.com/hyacinthe124/murgen-dev-
kit/blob/master/worklog/Session_8.md>  
  
A 1Msps on a très peu de finesse, et 2.5Msps est clairement plus proche de
5Msps que de 1Msps =)

### **Hyacinthe,** - May 04, 2016 at 9:27 AM

Je ne présente que l'enveloppe dans le document, basé sur la réponse
impulsionnelle du transducteur. Le détecteur d'enveloppe est supposé parfait
(c'est une simulation très basique donc tout est supposé parfait).  
  
Le fait que l'onde fasse un aller et retour n'a rien à voir avec la fréquence
d'échantillonnage, c'est son enveloppe (ici) qui joue uniquement. Tu confond
taille de pixel et fréquence d'échantillonnage. La taille d'un pixel peu être
donné par la fréquence d'échantillonnage ou non. La fréquence
d'échantillonnage donne la précision temporelle afin de voir tous (et plus
important entièrement) les echos. La taille d'un pixel donne la précision de
taille qui tient en compte de l'aller retour et qui peut recouvrir plusieurs
échantillons (il faut alors intégrer les points).  
  
Il est très facile avec mon script de mesure l'erreur, c'est codé pour pouvoir
comparer les situations.  
  
Quand à tes images, je ne sais pas ce que tu as fait dessus, mais tout ce que
je vois c'est un effet de moyennage.

### **Hyacinthe Lacenne** - May 04, 2016 at 9:48 AM

Désolé de ne pas avoir été clair =)  
  
On est bien alignés que ce qui joue ici c'est l'enveloppe du signal, pas le
signal. D'autre part, dans mon message 1 pixel = 1 point acquis, l'image ne
venant qu'après (surtout si on induit les déformations de l'image liées à la
scan conversion). Effectivement dans ce qui était évoqué, les deux sont bien
liés. Au niveau temporel, on est quand même OK que les echos venant de deux
interfaces separées de d seront dans le temps séparés de 2*d/v?  
  
Pour les images, l'image à 5Msps (la moins floue) a été décimé d'un facteur 2
puis 5 pour simuler la perte d'information due au sous echantillonage, puis
ces images mises à l'échelle pour avoir la meme taille d'image. On devrait
avoir un output plus pixélisé, mais l'output en JPG "floute" ces différences.
Pour être rigoureux, faudrait faire ce test avec une image acquise à bien plus
haute vitesse, et voir l'effet du sous-echantillonage sur l'image finale.  
  
Désolé, pas vu de lien pour le code, ca m'aurait évité de poser une question
con au sujet de la réponse du tranducteur - et des dimensions de la tache
focale du piezo =)

### **Hyacinthe,** - May 04, 2016 at 10:06 AM

Je n'ai pas mis le lien de mon code effectivement.  
  
En ce qui concerne le temps d'arrivé d'échos venant de deux interfaces, on est
d'accord c'est bien 2d/v.  
  
En ce qui concerne tes images, j'ai trouvé ça comme code pour le changement de
fréquence d'échantillonnage j'ai l'impression (je ne pipe rien au python) :  
  

    
    
    # Creation d'une image non scan-converted
     for i in range(size[0]): # les lignes
     for j in range(size[1]):
      pix[i,j]=128
      value = 0
     for k in range(DECIMATION):
      value = value + SortedTable[i][j*DECIMATION+k]*(1.9*(j*DECIMATION+k)**(0.6)/(Depth**(0.6)))
      value = int(value/DECIMATION)
      ImagePoints[i][j] = (int)(value/64)
      pix[i,j] = (ImagePoints[i][j],ImagePoints[i][j],ImagePoints[i][j])

  

Si j'interprète bien la boucle sur k, tu dis que la valeur d'un pixel est
égale à la moyenne des points sur le nombre décimation, c'est ça? D'où l'effet
de moyennage que je vois sur l'image?

### **Hyacinthe Lacenne** - May 04, 2016 at 10:18 AM

L'effet de moyenne est surtout (je pense) du au redimensionnement de l'image :
à 1Msps, l'image sans redimensionnement (normalization) fait cette taille :
<https://github.com/hyacinthe124/murgen-dev-
kit/blob/master/worklog/Images/Session_8/source_files/2c10128b362d2e1652c1b97111ba0ae2
.data-DEC5-SC-4T.png>  
  
Effectivement, c'est la bonne boucle dans le bon script. Jpeux rajouter un
comparatif de l'image a 1Msps avec un point choisi au pif parmis les DEC
points, ca sera plus rigoureux =) A vue de nez, ca introduira une image plus
"piquée", mais le redimensionnement ultérieur va de toutes facons "lisser" ces
pics.  
  
A voir donc avec cet effet de randomization des points de l'image, bien vu!

### **Hyacinthe,** - May 04, 2016 at 10:35 AM

Par contre tu n'as pas répondu à ma question, la boucle sur k :  
  
  

    
    
    for k in range(DECIMATION):
      value = value + SortedTable[i][j*DECIMATION+k]*(1.9*(j*DECIMATION+k)**(0.6)/(Depth**(0.6)))
      value = int(value/DECIMATION)

  
  
ça fait la moyenne sur les n points?

### **Hyacinthe Lacenne** - May 04, 2016 at 10:39 AM

Effectivement, il faisait la moyenne =) D'où l'idée de refaire le comparatif
en choppant 1 point choisi au pif parmi les DEC disponible, pour être plus
rigoureux.

### **Hyacinthe VINCENT,** - May 04, 2016 at 11:02 AM

Et pour simuler le "peak&amp;hold" on pourrait aussi retenir le max des points
;-)

### **Hyacinthe,** - May 04, 2016 at 12:00 PM

Oui donc en faisant un moyennage tu n'as pas fait une décimation mais changé
la taille du pixel. Pour faire une décimation il faut effectivement ne garder
qu'un des points.

### **Hyacinthe Lacenne** - May 04, 2016 at 6:06 PM

Comparatif done at : <https://github.com/hyacinthe124/murgen-dev-
kit/blob/master/worklog/Session_8.md> et les sources (en quick and dirty :
<https://github.com/hyacinthe124/murgen-dev-
kit/tree/master/worklog/Images/Session_8/source_files> ) en particulier le
makeTest.sh Hope that helps!  
  
(edit : Session_8bis -&gt; Session_8 updated)

### **Hyacinthe VINCENT,** - May 09, 2016 at 8:23 AM

Pas mal, on voit bien qu'on a  moins d'érosion des détails avec le max qu'avec
la moyenne. On voit aussi que le random pourrait avoir du sens car il s'agit
d'une image animée et l'oeil ferait le reste du travail d'identification en
traitant l'empilage de plusieurs frames successives. Par contre le random ne
serait pas si facile à réaliser en analogique en amont de l'ADC.  
Par ailleurs, si on arrive à atteindre 10-15 fps, il y a aussi un coup à jouer
en faisant un traitement glissant sur 2-3 frames successives.

